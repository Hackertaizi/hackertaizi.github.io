<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hackertaizi.gitee.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.1","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="太子的个人博客">
<meta property="og:url" content="https://hackertaizi.gitee.io/page/5/index.html">
<meta property="og:site_name" content="太子的个人博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Taizi">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://hackertaizi.gitee.io/page/5/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/5/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>太子的个人博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">太子的个人博客</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Have a nice day !</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Taizi</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">50</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/Hadoop/Hive/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E8%AF%AD%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E8%AF%AD%E6%B3%95/" class="post-title-link" itemprop="url">Hive基本语法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:27:55" itemprop="dateModified" datetime="2023-09-27T18:27:55+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>25 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive-基本语法"><a href="#Hive-基本语法" class="headerlink" title="Hive 基本语法"></a>Hive 基本语法</h1><h2 id="一、DDL"><a href="#一、DDL" class="headerlink" title="一、DDL"></a>一、DDL</h2><h3 id="1-数据库操作"><a href="#1-数据库操作" class="headerlink" title="1. 数据库操作"></a>1. 数据库操作</h3><h4 id="1-1-创建数据库"><a href="#1-1-创建数据库" class="headerlink" title="1.1 创建数据库"></a>1.1 创建数据库</h4><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [REMOTE] (DATABASE<span class="operator">|</span>SCHEMA) [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] database_name</span><br><span class="line">  [COMMENT database_comment]<span class="comment">-- 数据库注释信息</span></span><br><span class="line">  [LOCATION hdfs_path] <span class="comment">-- 内部表数据存储路径 在hive4.0版本一下内外部表都用此命令设置存储路径</span></span><br><span class="line">  [MANAGEDLOCATION hdfs_path] <span class="comment">-- 外部表存储路径 hive4.0版本后可用</span></span><br><span class="line">  [<span class="keyword">WITH</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]; <span class="comment">-- 指派自定义属性</span></span><br></pre></td></tr></table></figure>

<p><strong>自己指定的的位置的话,在hdfs上面生成的数据库路径文件夹是没有.db,使用默认路径生成的数据库路径文件夹有.db</strong></p>
<p>具体实例如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> shopping</span><br><span class="line">COMMENT `stores <span class="keyword">all</span> shopping basket data`</span><br><span class="line">LOCATION `<span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>retail<span class="operator">/</span>hive<span class="operator">/</span>SHOPPING.db`</span><br><span class="line"><span class="keyword">WITH</span> PROPERTIES (<span class="string">&#x27;purpose&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testing&#x27;</span>);</span><br></pre></td></tr></table></figure>

<h4 id="1-2-删除数据库"><a href="#1-2-删除数据库" class="headerlink" title="1.2 删除数据库"></a>1.2 删除数据库</h4><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> (DATABASE<span class="operator">|</span>SCHEMA) [IF <span class="keyword">EXISTS</span>] database_name [RESTRICT<span class="operator">|</span>CASCADE];</span><br></pre></td></tr></table></figure>

<blockquote>
<p>若选择RESTRICT，该表的删除是有限制条件的。该表不能被其他表的约束所引用（如CHECK，FOREIGN KEY等约束），不能有触发器，不能有视图，不能有函数和存储过程等。如果该表存在这些依赖的对象，此表不能删除。	</p>
<p>若选择CASCADE，该表的删除没有限制条件。在删除基本表的同时，相关的依赖对象将会被一起删除。<br>​</p>
<p>默认是RESTRICT</p>
</blockquote>
<h4 id="1-3-修改数据库"><a href="#1-3-修改数据库" class="headerlink" title="1.3 修改数据库"></a>1.3 修改数据库</h4><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...);   <span class="comment">-- (<span class="doctag">Note:</span> SCHEMA added in Hive 0.14.0) 修改元数据属性</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> OWNER [<span class="keyword">USER</span><span class="operator">|</span>ROLE] user_or_role;   <span class="comment">-- (<span class="doctag">Note:</span> Hive 0.13.0 and later; SCHEMA added in Hive 0.14.0) 修改所有者</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> LOCATION hdfs_path; <span class="comment">-- (<span class="doctag">Note:</span> Hive 2.2.1, 2.4.0 and later) 修改数据存储路径</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> MANAGEDLOCATION hdfs_path; <span class="comment">-- (<span class="doctag">Note:</span> Hive 4.0.0 and later) </span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>DATABASE|SCHEMA (数据库|架构)，创建时二选一即可，这里它们是同义的。</p>
</blockquote>
<h4 id="1-4-选择数据库"><a href="#1-4-选择数据库" class="headerlink" title="1.4 选择数据库"></a>1.4 选择数据库</h4><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">USE database_name;</span><br><span class="line">USE <span class="keyword">DEFAULT</span>;</span><br></pre></td></tr></table></figure>



<h3 id="2-数据表操作"><a href="#2-数据表操作" class="headerlink" title="2. 数据表操作"></a>2. 数据表操作</h3><h4 id="2-1-创建表"><a href="#2-1-创建表" class="headerlink" title="2.1 创建表"></a>2.1 创建表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [TEMPORARY] [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name    <span class="comment">-- (<span class="doctag">Note:</span> TEMPORARY available in Hive 0.14.0 and later)</span></span><br><span class="line">  [(col_name data_type [column_constraint_specification] [COMMENT col_comment], ... [constraint_specification])]</span><br><span class="line">  [COMMENT table_comment]</span><br><span class="line">  [PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">  [CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) [SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] </span><br><span class="line">   <span class="keyword">INTO</span> num_buckets BUCKETS]</span><br><span class="line">  [SKEWED <span class="keyword">BY</span> (col_name, col_name, ...) ]<span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.10.0 and later)</span></span><br><span class="line">   <span class="keyword">ON</span> ((col_value, col_value, ...), (col_value, col_value, ...), ...) </span><br><span class="line">  [STORED <span class="keyword">AS</span> DIRECTORIES]</span><br><span class="line">  [</span><br><span class="line">   [<span class="type">ROW</span> FORMAT row_format] </span><br><span class="line">   [STORED <span class="keyword">AS</span> file_format]</span><br><span class="line">     <span class="operator">|</span> STORED <span class="keyword">BY</span> <span class="string">&#x27;storage.handler.class.name&#x27;</span> [<span class="keyword">WITH</span> SERDEPROPERTIES (...)]  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.6.0 and later)</span></span><br><span class="line">  ]</span><br><span class="line">  [LOCATION hdfs_path]</span><br><span class="line">  [TBLPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.6.0 and later)</span></span><br><span class="line">  [<span class="keyword">AS</span> select_statement];   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.5.0 and later; not supported for external tables)</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">CREATE</span> [TEMPORARY] [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name</span><br><span class="line">  <span class="keyword">LIKE</span> existing_table_or_view_name</span><br><span class="line">  [LOCATION hdfs_path];</span><br><span class="line"> </span><br><span class="line">data_type</span><br><span class="line">  : primitive_type</span><br><span class="line">  <span class="operator">|</span> array_type</span><br><span class="line">  <span class="operator">|</span> map_type</span><br><span class="line">  <span class="operator">|</span> struct_type</span><br><span class="line">  <span class="operator">|</span> union_type  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.7.0 and later)</span></span><br><span class="line"> </span><br><span class="line">primitive_type</span><br><span class="line">  : TINYINT</span><br><span class="line">  <span class="operator">|</span> <span class="type">SMALLINT</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">INT</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">BIGINT</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">BOOLEAN</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">FLOAT</span></span><br><span class="line">  <span class="operator">|</span> <span class="keyword">DOUBLE</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">DOUBLE PRECISION</span> <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 2.2.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> STRING</span><br><span class="line">  <span class="operator">|</span> <span class="type">BINARY</span>      <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.8.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">TIMESTAMP</span>   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.8.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">DECIMAL</span>     <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.11.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">DECIMAL</span>(<span class="keyword">precision</span>, scale)  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">DATE</span>        <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.12.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">VARCHAR</span>     <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.12.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">CHAR</span>        <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13.0 and later)</span></span><br><span class="line"> </span><br><span class="line">array_type</span><br><span class="line">  : <span class="keyword">ARRAY</span> <span class="operator">&lt;</span> data_type <span class="operator">&gt;</span></span><br><span class="line"> </span><br><span class="line">map_type</span><br><span class="line">  : MAP <span class="operator">&lt;</span> primitive_type, data_type <span class="operator">&gt;</span></span><br><span class="line"> </span><br><span class="line">struct_type</span><br><span class="line">  : STRUCT <span class="operator">&lt;</span> col_name : data_type [COMMENT col_comment], ...<span class="operator">&gt;</span></span><br><span class="line"> </span><br><span class="line">union_type</span><br><span class="line">   : UNIONTYPE <span class="operator">&lt;</span> data_type, data_type, ... <span class="operator">&gt;</span>  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.7.0 and later)</span></span><br><span class="line"> </span><br><span class="line">row_format</span><br><span class="line">  : DELIMITED [FIELDS TERMINATED <span class="keyword">BY</span> <span class="type">char</span> [ESCAPED <span class="keyword">BY</span> <span class="type">char</span>]] [COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>]</span><br><span class="line">        [MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] [LINES TERMINATED <span class="keyword">BY</span> <span class="type">char</span>]</span><br><span class="line">        [<span class="keyword">NULL</span> DEFINED <span class="keyword">AS</span> <span class="type">char</span>]   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13 and later)</span></span><br><span class="line">  <span class="operator">|</span> SERDE serde_name [<span class="keyword">WITH</span> SERDEPROPERTIES (property_name<span class="operator">=</span>property_value, property_name<span class="operator">=</span>property_value, ...)]</span><br><span class="line"> </span><br><span class="line">file_format:</span><br><span class="line">  : SEQUENCEFILE</span><br><span class="line">  <span class="operator">|</span> TEXTFILE    <span class="comment">-- (Default, depending on hive.default.fileformat configuration)</span></span><br><span class="line">  <span class="operator">|</span> RCFILE      <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.6.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> ORC         <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.11.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> PARQUET     <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> AVRO        <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.14.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> JSONFILE    <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 4.0.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname</span><br><span class="line"> </span><br><span class="line">column_constraint_specification:</span><br><span class="line">  : [ <span class="keyword">PRIMARY</span> KEY<span class="operator">|</span><span class="keyword">UNIQUE</span><span class="operator">|</span><span class="keyword">NOT</span> <span class="keyword">NULL</span><span class="operator">|</span><span class="keyword">DEFAULT</span> [default_value]<span class="operator">|</span><span class="keyword">CHECK</span>  [check_expression] ENABLE<span class="operator">|</span>DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br><span class="line"> </span><br><span class="line">default_value:</span><br><span class="line">  : [ LITERAL<span class="operator">|</span><span class="built_in">CURRENT_USER</span>()<span class="operator">|</span><span class="built_in">CURRENT_DATE</span>()<span class="operator">|</span><span class="built_in">CURRENT_TIMESTAMP</span>()<span class="operator">|</span><span class="keyword">NULL</span> ] </span><br><span class="line"> </span><br><span class="line">constraint_specification:</span><br><span class="line">  : [, <span class="keyword">PRIMARY</span> KEY (col_name, ...) DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br><span class="line">    [, <span class="keyword">PRIMARY</span> KEY (col_name, ...) DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br><span class="line">    [, <span class="keyword">CONSTRAINT</span> constraint_name <span class="keyword">FOREIGN</span> KEY (col_name, ...) <span class="keyword">REFERENCES</span> table_name(col_name, ...) DISABLE NOVALIDATE </span><br><span class="line">    [, <span class="keyword">CONSTRAINT</span> constraint_name <span class="keyword">UNIQUE</span> (col_name, ...) DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br><span class="line">    [, <span class="keyword">CONSTRAINT</span> constraint_name <span class="keyword">CHECK</span> [check_expression] ENABLE<span class="operator">|</span>DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>对几个关键点说明</strong><br>a) temporary 创建临时表，只在本次回话生效<br>b) external关键字，加上这个关键字建的表是外部表，不加这个关键字建的表就是内部表<br>    内部表和外部表的区别：<br>    (1）概念本质上<br>    内部表数据自己的管理的在进行表删除时数据和元数据一并删除。<br>    外部表只是对HDFS的一个目录的数据进行关联，外部表在进行删除时只删除元数据，原始数据是不会被删除的。<br>    (2）应用场景上<br>    外部表一般用于存储原始数据、公共数据，内部表一般用于存储某一个模块的中间结果数据。<br>    (3）存储目录上<br>    外部表：一般在进行建表时候需要手动指定表的数据目录为共享资源目录，用lication关键字指定。<br>    内部表：无严格的要求，一般使用的默认目录。<br>c) partitioned by 指定分区字段<br>    partitioned by（分区字段名 分区字段类型 COMMENT 字段描述信息）<br>    注意：分区字段一定不能存在于建表字段中。<br>d) [row format row_format] 指定分割符的<br>    fields terminated by 列分割符<br>    lines terminated by 行分割符<br>    map keys terminated by<br>e) [stored as AS file_format] 指定原始数据的存储格式<br>    textfile 文本格式 默认的方式<br>    cfile 行列格式， 在行的方向切分数据的存储的块 保证一行数据在一个数据块中，每列个块中存储的时候 进行划分存储的。<br>    SequenceFile 二进制存储格式</p>
</blockquote>
<h4 id="2-2-删除表"><a href="#2-2-删除表" class="headerlink" title="2.2 删除表"></a>2.2 删除表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> [IF <span class="keyword">EXISTS</span>] table_name [PURGE];     <span class="comment">-- (<span class="doctag">Note:</span> PURGE available in Hive 0.14.0 and later)</span></span><br></pre></td></tr></table></figure>

<h4 id="2-3-截断表（删除表的所有行，即清空表）"><a href="#2-3-截断表（删除表的所有行，即清空表）" class="headerlink" title="2.3 截断表（删除表的所有行，即清空表）"></a>2.3 截断表（删除表的所有行，即清空表）</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">TRUNCATE</span> [<span class="keyword">TABLE</span>] table_name [<span class="keyword">PARTITION</span> partition_spec];</span><br><span class="line"> </span><br><span class="line">partition_spec:</span><br><span class="line">  : (partition_column <span class="operator">=</span> partition_col_value, partition_column <span class="operator">=</span> partition_col_value, ...)</span><br></pre></td></tr></table></figure>

<h4 id="2-4-修改表"><a href="#2-4-修改表" class="headerlink" title="2.4 修改表"></a>2.4 修改表</h4><h5 id="2-4-1-重命名"><a href="#2-4-1-重命名" class="headerlink" title="2.4.1 重命名"></a>2.4.1 重命名</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name RENAME <span class="keyword">TO</span> new_table_name;</span><br></pre></td></tr></table></figure>

<h5 id="2-4-2-修改表属性"><a href="#2-4-2-修改表属性" class="headerlink" title="2.4.2 修改表属性"></a>2.4.2 修改表属性</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">SET</span> TBLPROPERTIES table_properties;</span><br><span class="line"> </span><br><span class="line">table_properties:</span><br><span class="line">  : (property_name <span class="operator">=</span> property_value, property_name <span class="operator">=</span> property_value, ... )</span><br></pre></td></tr></table></figure>

<h5 id="2-4-3-修改表注释"><a href="#2-4-3-修改表注释" class="headerlink" title="2.4.3 修改表注释"></a>2.4.3 修改表注释</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">SET</span> TBLPROPERTIES (<span class="string">&#x27;comment&#x27;</span> <span class="operator">=</span> new_comment);</span><br></pre></td></tr></table></figure>

<h5 id="2-4-4-添加正则表达式过滤属性"><a href="#2-4-4-添加正则表达式过滤属性" class="headerlink" title="2.4.4 添加正则表达式过滤属性"></a>2.4.4 添加正则表达式过滤属性</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> partition_spec] <span class="keyword">SET</span> SERDE serde_class_name [<span class="keyword">WITH</span> SERDEPROPERTIES serde_properties];</span><br><span class="line"> </span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> partition_spec] <span class="keyword">SET</span> SERDEPROPERTIES serde_properties;</span><br><span class="line"> </span><br><span class="line">serde_properties:</span><br><span class="line">  : (property_name <span class="operator">=</span> property_value, property_name <span class="operator">=</span> property_value, ... )</span><br></pre></td></tr></table></figure>

<h5 id="2-4-5-删除正则表达式过滤属性"><a href="#2-4-5-删除正则表达式过滤属性" class="headerlink" title="2.4.5 删除正则表达式过滤属性"></a>2.4.5 删除正则表达式过滤属性</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> partition_spec] UNSET SERDEPROPERTIES (property_name, ... );</span><br></pre></td></tr></table></figure>



<h2 id="二、DML"><a href="#二、DML" class="headerlink" title="二、DML"></a>二、DML</h2><h3 id="1-将文件导入数据表"><a href="#1-将文件导入数据表" class="headerlink" title="1. 将文件导入数据表"></a>1. 将文件导入数据表</h3><p>语法格式:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)]</span><br><span class="line"> </span><br><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] [INPUTFORMAT <span class="string">&#x27;inputformat&#x27;</span> SERDE <span class="string">&#x27;serde&#x27;</span>] (<span class="number">3.0</span> <span class="keyword">or</span> later)</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li><p>LOAD DATA ：数据导入关键字</p>
</li>
<li><p>关于LOCAL关键字</p>
</li>
</ul>
<blockquote>
<p>LOCAL 关键字：如果指定了 LOCAL， LOAD 命令会去查找本地文件系统中的 filepath。如果没有指定 LOCAL 关键字，则根据 inpath 中的 uri 查找文件。<br>注意：uri 是指 hdfs 上的路径，分简单模式和完整模式两种，例如：</p>
<ul>
<li>简单模式：&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
<li>完整模式：hdfs:&#x2F;&#x2F;namenode_host:9000&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
</ul>
</blockquote>
<ul>
<li>关于文件路径 filepath</li>
</ul>
<blockquote>
<p>在hive3.0之前，文件导入操作是通过单纯的复制&#x2F;移动的方式来将数据文件导入路径下的数据表中，其中，文件路径可以是以下几种形式：</p>
<ul>
<li><p>相对路径，如<code>project/data1</code></p>
</li>
<li><p>绝对路径，如<code>/user/hive/project/data1</code></p>
</li>
<li><p>带有模式和权限(可选)的完整URI，如<code>hdfs://namenode:9000/user/hive/project/data1</code></p>
</li>
</ul>
<p>文件路径可以具体到某个要导入的文件，也可以是某个目录(文件夹)，如果是目录，hive会将目录下的所有文件导入表中。</p>
</blockquote>
<ul>
<li>关于导入表的类型</li>
</ul>
<blockquote>
<p>接收导入数据的表可以是一个已有表或者分区表，如果表是分区表，则必须指定分区字段内所有属性(列)的值。也可以使用 </p>
<p>CREATE TABLE 在导入时创建导入表。</p>
</blockquote>
<ul>
<li>输入格式控制(Hive 3.0之后可用)</li>
</ul>
<blockquote>
<p>输入格式(inputformat)可以是hive 的任何输入格式，如text、ORC等。</p>
<p>serde可以是关联的配置单元serde。</p>
<p>inputformat和serde都区分大小写</p>
</blockquote>
<ul>
<li>其他加载操作</li>
</ul>
<blockquote>
<p>Hive 3.0及更高版本中，除了移动复制操作之外，还支持其他加载操作，因为Hive在内部在某些场合下会将加载重写为<strong>INSERT AS SELECT</strong>。<br>比如，如果表具有分区，而load命令没有指定分区，则将load转换为INSERT AS SELECT，并假定最后一组列为分区列。如果文件不符合预期的架构，它将引发错误。</p>
</blockquote>
<p>注意：</p>
<ul>
<li><p>文件路径下不能包含有子目录，即如果指定的文件路径是一个目录，该目录下不能包含子目录。</p>
</li>
<li><p>如果没有指定LOCAL关键字，则导入的文件必须与表在同一个文件系统下</p>
</li>
</ul>
<h3 id="2-通过查询语句将数据插入数据表（常用）"><a href="#2-通过查询语句将数据插入数据表（常用）" class="headerlink" title="2. 通过查询语句将数据插入数据表（常用）"></a>2. 通过查询语句将数据插入数据表（常用）</h3><h4 id="2-1-普通表和静态分区表的插入"><a href="#2-1-普通表和静态分区表的插入" class="headerlink" title="2.1 普通表和静态分区表的插入"></a>2.1 普通表和静态分区表的插入</h4><p>使用这种方式可以将查询结果插入数据表。</p>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Standard syntax:<span class="comment">-- 标准语法格式</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...) [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement1 <span class="keyword">FROM</span> from_statement;<span class="comment">-- 覆盖插入</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] select_statement1 <span class="keyword">FROM</span> from_statement; <span class="comment">-- 增量插入</span></span><br><span class="line"> </span><br><span class="line">Hive extension (multiple inserts):<span class="comment">-- hive拓展，多表插入</span></span><br><span class="line"><span class="keyword">FROM</span> from_statement</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...) [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement1</span><br><span class="line">[<span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ... [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement2]</span><br><span class="line">[<span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ...] select_statement2] ...;</span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> from_statement</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] select_statement1</span><br><span class="line">[<span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ...] select_statement2]</span><br><span class="line">[<span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ... [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement2] ...;</span><br><span class="line"> </span><br><span class="line">Hive extension (<span class="keyword">dynamic</span> <span class="keyword">partition</span> inserts): <span class="comment">-- hive拓展，动态分区插入</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename <span class="keyword">PARTITION</span> (partcol1[<span class="operator">=</span>val1], partcol2[<span class="operator">=</span>val2] ...) select_statement <span class="keyword">FROM</span> from_statement;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename <span class="keyword">PARTITION</span> (partcol1[<span class="operator">=</span>val1], partcol2[<span class="operator">=</span>val2] ...) select_statement <span class="keyword">FROM</span> from_statement;</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li>两种插入方式概述</li>
</ul>
<blockquote>
<p>INSERT OVERWRITE 方式插入数据会将表或者分区表中的信息清空覆盖，具体实现是先查找到要插入的数据，然后将表清空，最后插入数据</p>
<p>INSERT INTO 方式插入数据会在表或者分区表中添加增量信息，即不改变表中的原有数据，而是在后面添加。</p>
<p>在Hive 0.13.0之后，创建数据表时可以指定表属性TBLPROPERTIES(“immutable”&#x3D;”true”)，(immutable默认为false),这样表就是不可变的，如果一个不可变的表上有任何数据的话，INSERT INTO 方式插入数据不能在不可变的表上操作。但如果不可变的表是空的，则仍然可以通过INSERT INTO 方式插入数据。INSERT OVERWRITE 插入方式不受表的immutable属性限制。</p>
</blockquote>
<ul>
<li>IF NOT EXISTS 关键字</li>
</ul>
<blockquote>
<p>如果使用了该关键字，当数据插入时如果表不存在，会创建一个表；如果没有使用改关键字，当数据插入时如果表不存在，指令会执行失败。</p>
</blockquote>
<ul>
<li>分区表插入注意事项</li>
</ul>
<blockquote>
<p>可以向表或者分区表中插入数据，如果是分区表，插入时则必须指定所有分区字段的值，如果<code>hive.typecheck.on.insert</code>被设置为true,则hive会校验、转化、规范化这些值使它们符合列的类型。(Hive 0.12.0以后)</p>
</blockquote>
<ul>
<li>多表插入</li>
</ul>
<blockquote>
<p>多表插入的意思是可以在一个查询中指定多个INSERT语句，只需要扫描一遍源表。如果要使用覆盖的方法插入，OVERWRITE关键字是必须的，不是可选的。多表插入可最大限度地减少所需的数据扫描次数。Hive只需扫描输入数据一次（并对输入数据应用不同的查询运算符），即可将数据插入多个表中。</p>
<p><strong>多表插入时，如果目标表是普通表，则不能插入相同的表。</strong></p>
<p><strong>多表插入时，如果目标表是分区表，则插入的表不能是相同表的相同分区，可以是相同表的不通分区。</strong></p>
</blockquote>
<ul>
<li>输出格式</li>
</ul>
<blockquote>
<p>输出格式由表的元数据定义。</p>
</blockquote>
<blockquote>
<p>自Hive 0.14起，如果一个表的OutputFormat实现了AcidOutputFormat，并且系统配置为使用实现ACID的事务管理器，则该表的插入覆盖将被禁用。这是为了避免用户无意中覆盖事务历史记录。同样的功能也可以通过使用TRUNCATE TABLE（对于非分区表）或DROP PARTITION，然后INSERT INTO来实现。</p>
</blockquote>
<ul>
<li>其他</li>
</ul>
<blockquote>
<p>自Hive1.1.0开始，关键字TABLE 变成了可选的而不是必需的。</p>
</blockquote>
<blockquote>
<p>自Hive3.1.0起，不允许从数据源中使用UNION ALL对完整CRUD ACID表进行插入覆盖。</p>
</blockquote>
<h4 id="2-2-动态分区表的插入"><a href="#2-2-动态分区表的插入" class="headerlink" title="2.2 动态分区表的插入"></a>2.2 动态分区表的插入</h4><p>动态分区表插入时，动态分区列必须在select语句的最后进行指定，且指定顺序必须与partition中指定的先后顺序相同。从Hive3.0.0起，不需要指定动态分区列。</p>
<p>在Hive0.9.0之前，动态分区是默认不可用的，在Hive0.9.0之后，动态分区是默认可用的，以下是有关动态分区表的插入的一些属性配置：</p>
<table>
<thead>
<tr>
<th>配置属性</th>
<th>默认值</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>hive.exec.dynamic.partition</td>
<td>true</td>
<td>当动态分区表插入时需要被设置为true</td>
</tr>
<tr>
<td>hive.exec.dynamic.partition.mode</td>
<td>strict</td>
<td>在严格模式下，使用者必须确定至少一个静态分区来防止所有分区被意外覆盖，而在非严格模式下，所有分区都可以是动态的。</td>
</tr>
<tr>
<td>hive.exec.max.dynamic.partitions.pernode</td>
<td>100</td>
<td>在一个mapper&#x2F;reducer节点中允许创建的最大动态分区数</td>
</tr>
<tr>
<td>hive.exec.max.dynamic.partitions</td>
<td>1000</td>
<td>允许创建的最大动态分区总数</td>
</tr>
<tr>
<td>hive.exec.max.created.files</td>
<td>100000</td>
<td>在一个MapReduce任务中所有mappers&#x2F;reducers可以创建的最大HDFS文件数量总数</td>
</tr>
<tr>
<td>hive.error.on.empty.partition</td>
<td>false</td>
<td>如果动态分区插入结果为空是否抛出异常</td>
</tr>
</tbody></table>
<h3 id="3-通过查询将数据写入文件系统"><a href="#3-通过查询将数据写入文件系统" class="headerlink" title="3. 通过查询将数据写入文件系统"></a>3. 通过查询将数据写入文件系统</h3><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Standard syntax: <span class="comment">-- 标准语法</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory1</span><br><span class="line">  [<span class="type">ROW</span> FORMAT row_format] [STORED <span class="keyword">AS</span> file_format] (Note: <span class="keyword">Only</span> available starting <span class="keyword">with</span> Hive <span class="number">0.11</span><span class="number">.0</span>)</span><br><span class="line">  <span class="keyword">SELECT</span> ... <span class="keyword">FROM</span> ...</span><br><span class="line"> </span><br><span class="line">Hive extension (multiple inserts): <span class="comment">-- hive拓展，多插入</span></span><br><span class="line"><span class="keyword">FROM</span> from_statement</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory1 select_statement1</span><br><span class="line">[<span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory2 select_statement2] ...</span><br><span class="line"> </span><br><span class="line">  </span><br><span class="line">row_format</span><br><span class="line">  : DELIMITED [FIELDS TERMINATED <span class="keyword">BY</span> <span class="type">char</span> [ESCAPED <span class="keyword">BY</span> <span class="type">char</span>]] [COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>]</span><br><span class="line">        [MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] [LINES TERMINATED <span class="keyword">BY</span> <span class="type">char</span>]</span><br><span class="line">        [<span class="keyword">NULL</span> DEFINED <span class="keyword">AS</span> <span class="type">char</span>] (Note: <span class="keyword">Only</span> available starting <span class="keyword">with</span> Hive <span class="number">0.13</span>)</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li>INSERT OVERWRITE :插入语法关键字</li>
<li>LOCAL关键字</li>
</ul>
<blockquote>
<p>LOCAL 关键字：如果指定了 LOCAL， Hive会将数据写入到本次文件系统中。如果没有指定 LOCAL 关键字，则根据 DIRECTORY 中的 uri 查找文件。<br>注意：uri 是指 hdfs 上的路径，分简单模式和完整模式两种，例如：</p>
<ul>
<li>简单模式：&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
<li>完整模式：hdfs:&#x2F;&#x2F;namenode_host:9000&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
</ul>
</blockquote>
<ul>
<li>DIRECTORY 要写入的文件目录</li>
</ul>
<blockquote>
<p>目录可以是一个完整的URI，当标识和权限不确定时，Hive将会从hadoop配置变量fs.default.name中确定URI。</p>
</blockquote>
<ul>
<li>写入格式</li>
</ul>
<blockquote>
<p>数据在写入文件系统时会被序列化成text文本，列之间使用<code>^A</code>分隔符分隔，行之间使用换行分隔，如果任何列不是基本类型，那么这些列将会被序列化为JSON格式。</p>
</blockquote>
<ul>
<li>注意</li>
</ul>
<blockquote>
<p>INSERT OVERWRITE语句写入目录、本地目录，表（或分区表）可以写在一个查询中。</p>
<p>当有大量数据时，使用Hive将数据写入HDFS文件系统的目录中是最好的处理方式，因为Hive可以在一个MapReduce中将数据并行地写入HDFS目录中。</p>
<p>指定的目录如果存在，则写入操作会将目录中原来的数据覆盖，即会先将原有的数据删除，然后插入查询到的数据。</p>
<p>从Hive 0.11.0开始，可以指定使用的分隔符；在早期版本中，它始终是^A字符（\ 001）。但是，在Hive0.11.0至1.1.0中，仅支持自定义分隔符用于本地写入–此错误在版本1.2.0中得到修复。</p>
<p>在Hive 0.14中，插入到符合ACID的表中将在选择和插入期间停用矢量化。这将自动完成。插入数据的ACID表仍然可以使用矢量化进行查询。</p>
</blockquote>
<h3 id="4-使用SQL将数据插入表"><a href="#4-使用SQL将数据插入表" class="headerlink" title="4. 使用SQL将数据插入表"></a>4. 使用SQL将数据插入表</h3><p>使用INSERT……VALUES 通过SQL可以直接将数据插入表。</p>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Standard Syntax: <span class="comment">-- 标准语法</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1[<span class="operator">=</span>val1], partcol2[<span class="operator">=</span>val2] ...)] <span class="keyword">VALUES</span> values_row [, values_row ...]</span><br><span class="line">  </span><br><span class="line"><span class="keyword">Where</span> values_row <span class="keyword">is</span>:</span><br><span class="line">( <span class="keyword">value</span> [, <span class="keyword">value</span> ...] )</span><br><span class="line"><span class="keyword">where</span> a <span class="keyword">value</span> <span class="keyword">is</span> either <span class="keyword">null</span> <span class="keyword">or</span> <span class="keyword">any</span> valid <span class="keyword">SQL</span> literal<span class="comment">-- 值可以是null或有效的SQL语句</span></span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li><p>VALUES子句中列出的每一行都会插入到tablename表中。 </p>
</li>
<li><p>VALUES字句必须提供表中的所有列的值，不允许只提供某些列的值，为了模拟标注sql，使用者可以用null填充那些不需要赋值的列。</p>
</li>
<li><p>动态分区表的插入方式同<code>INSERT...SELECT </code>语法一样。</p>
</li>
<li><p>如果插入到的表支持ACID，并且正在使用支持ACID的事务管理器，则此操作将在成功完成后自动提交。 </p>
</li>
<li><p><strong>Hive不支持复杂类型(array, map, struct, union)文本，所以在INSERT……VALUES也不支持这些复杂类型，这意味着使用者不能通过INSERT……VALUES将数据插入复杂类型的列中。</strong></p>
</li>
</ul>
<h3 id="5-表更新（UPDATE）"><a href="#5-表更新（UPDATE）" class="headerlink" title="5. 表更新（UPDATE）"></a>5. 表更新（UPDATE）</h3><p>UPDATE语法在Hive0.14开始使用。</p>
<p><strong>UPDATE只能在支持ACID的表中使用。</strong></p>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Standard Syntax:</span><br><span class="line"><span class="keyword">UPDATE</span> tablename <span class="keyword">SET</span> <span class="keyword">column</span> <span class="operator">=</span> <span class="keyword">value</span> [, <span class="keyword">column</span> <span class="operator">=</span> <span class="keyword">value</span> ...] [<span class="keyword">WHERE</span> expression]</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li>引用的列必须是要更新的表的列。</li>
<li>分配的值必须是Hive select子句中支持的表达式。因此，支持算术运算符、UDF、强制转换、文字等。不支持子查询。</li>
<li>分区列和分桶列不能被更新。</li>
<li>在Hive0.14 中，操作成功后更改会自动提交。</li>
</ul>
<p>注意：</p>
<ul>
<li>更新操作会关闭矢量化，这是自动执行的，不需要使用者下发指令。没更新过的表不会收影响，更新后的表也仍然可以使用矢量化查询。</li>
<li>在0.14 版本,更新时建议配置 <code>hive.optimize.sort.dynamic.partition = fasle</code>,因为会更高效。</li>
</ul>
<h2 id="6-表删除（DELETE）"><a href="#6-表删除（DELETE）" class="headerlink" title="6. 表删除（DELETE）"></a>6. 表删除（DELETE）</h2><p>DELETE语法在Hive0.14开始使用。</p>
<p><strong>DELETE只能在支持ACID的表中使用。</strong></p>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Standard Syntax:</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> tablename [<span class="keyword">WHERE</span> expression]</span><br></pre></td></tr></table></figure>

<p>注意:</p>
<ul>
<li><p>在Hive0.14 中，操作成功后更改会自动提交。</p>
</li>
<li><p>删除操作会关闭矢量化，这是自动执行的，不需要使用者下发指令。没删除过的表不会收影响，删除操作完成后的表也仍然可以使用矢量化查询。</p>
</li>
<li><p>在0.14 版本,删除时建议配置 <code>hive.optimize.sort.dynamic.partition = fasle</code>,因为会更高效。</p>
</li>
</ul>
<h3 id="7-MERGE"><a href="#7-MERGE" class="headerlink" title="7. MERGE"></a>7. MERGE</h3><p>Merge简介：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MERGE语句是SQL语句的一种。在SQL Server、Oracle数据库中可用，MySQL、PostgreSQL中不可用。MERGE是Oracle9i新增的语法，用来合并UPDATE和INSERT语句。通过MERGE语句，根据一张表（原数据表，source table）或子查询的连接条件对另外一张（目标表，target table）表进行查询，连接条件匹配上的进行UPDATE，无法匹配的执行INSERT。这个语法仅需要一次全表扫描就完成了全部工作，执行效率要高于INSERT+UPDATE。</span><br></pre></td></tr></table></figure>

<p>版本信息：</p>
<ul>
<li>MERGE在Hive 2.2中开始使用。</li>
<li><strong>MERGE只能在支持ACID的表中使用。</strong></li>
</ul>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Standard Syntax:</span><br><span class="line"><span class="keyword">MERGE</span> <span class="keyword">INTO</span> <span class="operator">&lt;</span>target <span class="keyword">table</span><span class="operator">&gt;</span> <span class="keyword">AS</span> T <span class="keyword">USING</span> <span class="operator">&lt;</span>source expression<span class="operator">/</span><span class="keyword">table</span><span class="operator">&gt;</span> <span class="keyword">AS</span> S</span><br><span class="line"><span class="keyword">ON</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression1<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">WHEN</span> MATCHED [<span class="keyword">AND</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression2<span class="operator">&gt;</span>] <span class="keyword">THEN</span> <span class="keyword">UPDATE</span> <span class="keyword">SET</span> <span class="operator">&lt;</span><span class="keyword">set</span> clause list<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">WHEN</span> MATCHED [<span class="keyword">AND</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression3<span class="operator">&gt;</span>] <span class="keyword">THEN</span> <span class="keyword">DELETE</span></span><br><span class="line"><span class="keyword">WHEN</span> <span class="keyword">NOT</span> MATCHED [<span class="keyword">AND</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression4<span class="operator">&gt;</span>] <span class="keyword">THEN</span> <span class="keyword">INSERT</span> <span class="keyword">VALUES</span><span class="operator">&lt;</span><span class="keyword">value</span> list<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li><p>Merge允许基于与源表的联接结果对目标表执行操作。</p>
</li>
<li><p>自Hive2.2起，merge操作成功后会自动提交事务。</p>
</li>
</ul>
<p>注意：</p>
<ul>
<li>WHEN条件子句中，INSERT&#x2F;UPDATE&#x2F;DELETE中的每个语句最多只有一个，例如不能同时有两个insert子句。</li>
<li>WHEN NOT MATCHED必须放在多个WHEN子句的最后。</li>
<li>如果同时存在UPDATE和DELETE子句，则放在前面的哪一个字句中必须包含<code>AND &lt;boolean expression&gt;</code></li>
</ul>
<p>t条件。</p>
<ul>
<li>Merge操作会关闭矢量化，这是自动执行的，不需要使用者下发指令。没Merge过的表不会收影响，Merge操作完成后的表也仍然可以使用矢量化查询。</li>
</ul>
<h3 id="8-集群间数据迁移-IMPORT-x2F-EXPORT（这部分知识待补充）"><a href="#8-集群间数据迁移-IMPORT-x2F-EXPORT（这部分知识待补充）" class="headerlink" title="8. 集群间数据迁移 IMPORT&#x2F;EXPORT（这部分知识待补充）"></a>8. 集群间数据迁移 IMPORT&#x2F;EXPORT（这部分知识待补充）</h3><p>版本信息：</p>
<p>IMPORT&#x2F;EXPORT命令在Hive 0.8.0版本添加。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/Hadoop/Hive/Hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/" class="post-title-link" itemprop="url">Hive数据类型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:33:03" itemprop="dateModified" datetime="2023-09-27T18:33:03+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>8.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive数据类型"><a href="#Hive数据类型" class="headerlink" title="Hive数据类型"></a>Hive数据类型</h1><h2 id="一、数字类型"><a href="#一、数字类型" class="headerlink" title="一、数字类型"></a>一、数字类型</h2><ul>
<li><p>TINYINT  (1字节有符号整数，范围从-128到127)</p>
</li>
<li><p>SMALLINT  (2字节有符号整数，范围从-32,768到32,767)</p>
</li>
<li><p>INT &#x2F; INTEGER  (4字节有符号整数，范围从 -2,147,483,648 到 2,147,483,647)</p>
</li>
<li><p>BIGINT  (8字节有符号整数，范围从-9,223,372,036,854,775,808到9,223,372,036,854,775,807)</p>
</li>
<li><p>FLOAT  (4字节单精度浮点数)</p>
</li>
<li><p>DOUBLE  (8字节双精度浮点数)</p>
</li>
<li><p>DOUBLE PRECISION  (DOUBLE的别名，自Hive2.2.0起可用)</p>
</li>
<li><p>DECIMAL</p>
<ul>
<li>Hive0.11.0起引入，38位精度</li>
<li>Hive0.13.0起支持用于自定义精度和比例</li>
</ul>
</li>
<li><p>NUMBERIC  (同DECIMAL，Hive3.0.0起可用)</p>
</li>
</ul>
<h2 id="二、日期-x2F-时间类型"><a href="#二、日期-x2F-时间类型" class="headerlink" title="二、日期&#x2F;时间类型"></a>二、日期&#x2F;时间类型</h2><ul>
<li>TIMESTAMP  (Hive 0.8.0起可用)</li>
<li>DATE  (Hive 0.12.0起可用)</li>
<li>INTERVAL  (Hive 1.2.0起可用)</li>
</ul>
<h2 id="三、字符串类型"><a href="#三、字符串类型" class="headerlink" title="三、字符串类型"></a>三、字符串类型</h2><ul>
<li>STRING</li>
<li>VARCHAR  (Hive 0.12.0起可用)</li>
<li>CHAR  (Hive 0.13.0起可用)</li>
</ul>
<h2 id="四、其他类型"><a href="#四、其他类型" class="headerlink" title="四、其他类型"></a>四、其他类型</h2><ul>
<li>BOOLEAN</li>
<li>BINARY  (Hive 0.8.0起可用)</li>
</ul>
<h2 id="五-、复杂类型"><a href="#五-、复杂类型" class="headerlink" title="五 、复杂类型"></a>五 、复杂类型</h2><ul>
<li>arrays : ARRAY<data_type>  (Hive 0.14起可用)</data_type></li>
<li>maps : MAP&lt;primitive_type,data_type&gt;  (Hive 0.14起可用)</li>
<li>structs : STRUCT&lt;col_name : data_type [COMMENT col_comment], …&gt;</li>
<li>union : UNIONTYPE&lt;data_type, data_type, …&gt; (Hive 0.7.0起可用)</li>
</ul>
<h2 id="六、列类型"><a href="#六、列类型" class="headerlink" title="六、列类型"></a>六、列类型</h2><h3 id="6-1-整形类型（TINYINT-SMALLINT-INT-INTEGER-BIGINT）"><a href="#6-1-整形类型（TINYINT-SMALLINT-INT-INTEGER-BIGINT）" class="headerlink" title="6.1 整形类型（TINYINT, SMALLINT, INT/INTEGER, BIGINT）"></a>6.1 整形类型（<code>TINYINT</code>, <code>SMALLINT</code>, <code>INT/INTEGER</code>, <code>BIGINT</code>）</h3><p>在默认情况下，整形类型被设定为<code>INT</code>,如果数字超过了INT的范围，这时列类型将会被转换为<code>BIGINT</code>，或者可以使用下载后缀的方式指定整形类型：</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Postfix</th>
<th>Example</th>
</tr>
</thead>
<tbody><tr>
<td>TINYINT</td>
<td>Y</td>
<td>100Y</td>
</tr>
<tr>
<td>SMALLINT</td>
<td>S</td>
<td>100S</td>
</tr>
<tr>
<td>BIGINT</td>
<td>L</td>
<td>100L</td>
</tr>
</tbody></table>
<p>版本信息：INTEGER在Hive 2.2.0中作为INT 的同义词引入。</p>
<h3 id="6-2-String类型"><a href="#6-2-String类型" class="headerlink" title="6.2 String类型"></a>6.2 String类型</h3><p>字符串型类型值可以使用单引号或双引号表示，Hive将使用C风格在字符串中转义。</p>
<h3 id="6-3-Varchar类型"><a href="#6-3-Varchar类型" class="headerlink" title="6.3 Varchar类型"></a>6.3 Varchar类型</h3><p>varchar类型在创建时需要指定长度（范围1~65535），即定义允许存放的最大字符数。如果要转换&#x2F;分配给varchar类型的字符串超过了指定的长度，字符串会被自动截断。 字符长度由字符串包含的代码点数决定。 </p>
<p>和string一样，尾随在varchar最后的空格很重要，会影响比较的结果。</p>
<p>版本信息：</p>
<blockquote>
<p>varchar 在Hive 0.12.0之后起可用</p>
</blockquote>
<h3 id="6-4-Char-类型"><a href="#6-4-Char-类型" class="headerlink" title="6.4 Char 类型"></a>6.4 Char 类型</h3><p>Char类型与Varchar类型相似，但是Char类型的字符串是固定长度的，没有达到固定长度的部分会使用空格填充，这也意味着在Char类型在比较时尾部的空格没有那么重要，Char的最大长度固定为255。</p>
<p>版本信息：</p>
<blockquote>
<p>Char 类型在Hive 0.13.0后可用</p>
</blockquote>
<h3 id="6-5-Timestamp类型"><a href="#6-5-Timestamp类型" class="headerlink" title="6.5 Timestamp类型"></a>6.5 Timestamp类型</h3><p>支持具有可选纳秒精度的传统UNIX时间戳。</p>
<p>支持的转换：</p>
<ul>
<li><p>整数数字类型：以秒为单位解释为UNIX时间戳</p>
</li>
<li><p>浮点数字类型：以秒为单位，以十进制精度解释为UNIX时间戳</p>
</li>
<li><p>字符串：符合JDBC的java、sql。时间戳格式“YYYY-MM-DD HH:MM:SS.FFFFFFF”（小数点后9位精度）</p>
</li>
</ul>
<p>时间戳被解释为无时区的，并存储为UNIX历元的偏移量。提供了方便的自定义项（to_utc_timestamp, from_utc_timestamp）用于时区之间的转换。</p>
<p>所有现有的datetime UDF（月、日、年、小时等）都使用时间戳数据类型。</p>
<p>文本文件中的时间戳必须使用格式yyyy-mm-dd hh:mm:ss[.f…]。如果它们是另一种格式，请将其声明为适当的类型（INT、FLOAT、STRING等），并使用UDF将其转换为时间戳。</p>
<p>通过设置<code>hive.parquet.write.int64.timestamp=true</code>和<code>hive.parquet.timestamp.time.unit</code>为默认的存储时间单位 (“nanos”纳秒, “micros”微秒, “millis毫秒”; default: “micros”)，Parquet 文件中的时间戳可以存储为int64（而不是int96）。请注意，由于仅存储了64位，如果超出1677-09-21T00:12:43.15和2262-04-11T23:47:16.8的范围，则存储时间单位为“nanos”的int64时间戳将存储为NULL。</p>
<p>在表级别上，可以通过向SerDe属性“timestamp.formats”提供格式（从HIVE1.2.0开始），来支持其他时间戳格式。例如，yyyy-MM-dd’T’HH:MM:ss。SSS，yyyy-MM-dd’T’HH:MM:ss。</p>
<p>版本信息:</p>
<blockquote>
<p>Timestamp在Hive 0.8.0起可用。</p>
</blockquote>
<h3 id="6-6-Dates-类型"><a href="#6-6-Dates-类型" class="headerlink" title="6.6 Dates 类型"></a>6.6 Dates 类型</h3><p>Date类型：</p>
<p>Date 值主要用来描述年月日信息，使用形式YYYY-MM-DD,例如，Date ‘2022-05-30’。Date类型中没有时间组件。Date类型支持的值的范围为0000-01-01到9999-12-31，取决于原Java提供的日期类型的支持。</p>
<p>版本信息：</p>
<blockquote>
<p>Dates 在Hive 0.12.0之后可用。</p>
</blockquote>
<p>类型转换：</p>
<p>Date类型可以转换&#x2F;被转换为Date，Timestamp，或者String类型。也可以按使用者指定的格式转换（<strong>知识暂未深入研究</strong>）</p>
<p>以下是一些有关Date类型转换的说明：</p>
<table>
<thead>
<tr>
<th>转换为Date&#x2F; Date转换为其他时间类型</th>
<th>转换结果</th>
</tr>
</thead>
<tbody><tr>
<td>Date 转换为 Date</td>
<td>结果相同</td>
</tr>
<tr>
<td>Timestamp 转换为 Date</td>
<td>年、月、日在timestamp中是定好的，基于当地的时区将其转换为Date类型</td>
</tr>
<tr>
<td>String 转换为 Date</td>
<td>如果string 的格式为”YYYY-MM-DD”，将会按此年月日来转换成Date，如果String不是这种格式，则转换结果为NULL</td>
</tr>
<tr>
<td>Date 转换为Timestamp</td>
<td>基于本地时区，生成与日期值的年&#x2F;月&#x2F;日的午夜相对应的时间戳值。</td>
</tr>
<tr>
<td>Date 转换为 String</td>
<td>Date的年月日将以”YYYY-MM-DD”的格式转换为String</td>
</tr>
</tbody></table>
<p><strong>Interval类型：暂未研究</strong></p>
<h3 id="6-7-Decimal类型"><a href="#6-7-Decimal类型" class="headerlink" title="6.7 Decimal类型"></a>6.7 Decimal类型</h3><p>版本信息：</p>
<blockquote>
<p>Decimal数据类型在Hive 0.11.0引入，在Hive 0.13.0修正。在Hive 3.0.0中，	NUMERIC与Decimal类型作为同义词引入。</p>
</blockquote>
<p>介绍：</p>
<blockquote>
<p>Hive中的Decimal 类型是基于Java中用来表示不可变的任意精度的十进制数的BigDecimal类型而产生的。所有常规的数字运算（如加减乘除）和自定义项（如 Floor, Ceil, Round等）都可以用来处理Decimal类型。可以按照自己的想法将Decimal转换为其他类型，或将其他类型转换为Decimal。Decimal类型的持久性使得它支持科学和非科学计数法。</p>
</blockquote>
<p>使用：</p>
<blockquote>
<ul>
<li>Hive 0.11 和 0.12 版本Decimal类型的精度固定为38位</li>
<li>从Hive 0.13起，使用者可以自定义精度(字段长度）和范围（小数位数），创建表时，对于Decimal类型只需使用DECIMAL(precision, scale)的语法格式即可。如果小数位数没有确定，则其默认值为0；如果精度没有确定，其默认值为10。</li>
</ul>
</blockquote>
<p>以下是一个建表时指定Decimal类型属性的例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> foo (</span><br><span class="line">  a <span class="type">DECIMAL</span>, <span class="comment">-- Defaults to decimal(10,0)</span></span><br><span class="line">  b <span class="type">DECIMAL</span>(<span class="number">9</span>, <span class="number">7</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>Decimal 文本：</p>
<blockquote>
<p>大于BIGINT的整型文本必须使用Decimal(38,0)来处理，且’BD’后缀是必须携带的，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">CAST</span>(<span class="number">18446744073709001000</span>BD <span class="keyword">AS</span> <span class="type">DECIMAL</span>(<span class="number">38</span>,<span class="number">0</span>)) </span><br><span class="line"><span class="keyword">from</span> my_table limit <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>Hive 0.12.0 和 Hive 0.13.0版本间的Decimal类型是不兼容的。</strong></p>
<blockquote>
<p>由于Hive 0.13.0中Decimal类型的变化，Hive 0.13.0 之前版本的Decimal类型的列，在Hive 0.13.0版本后将被视为decimal(10,0),这意味着写入或写出这张表的整形值都会被转换为10位长度，所以从0.12.0版本获取的表最好升级到0.13.0版本后。</p>
</blockquote>
<p>更新Hive 0.13.0版本之前的表的Decimal类型列：</p>
<blockquote>
<ol>
<li>确定要对Decimal类型设置的的精度和范围。</li>
<li>对于表中的每一个Decimal类型的列，使用ALTER TABLE 命令将其修改为想要的精度和范围，如：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE foo CHANGE COLUMN dec_column_name dec_column_name DECIMAL(38,18);</span><br></pre></td></tr></table></figure>

<p>​	如果不是分区表，更新到此已经完成了，如果是分区表，还需要继续下面的第三步。</p>
<ol start="3">
<li><p>如果表是分区表，先查询表的分区列列表，如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SHOW PARTITIONS foo;</span><br><span class="line">  </span><br><span class="line">ds=2008-04-08/hr=11</span><br><span class="line">ds=2008-04-08/hr=12</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
<li><p>表中现有的每个分区必须修改其Decimal列，以添加所需的精度和范围。可以通过动态分区的ALTER TABLE CHANGE COLUMN(Hive 0.14.0后可用)来实现，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> hive.exec.dynamic.partition <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">     </span><br><span class="line"><span class="comment">-- hive.exec.dynamic.partition needs to be set to true to enable dynamic partitioning with ALTER PARTITION</span></span><br><span class="line"><span class="comment">-- This will alter all existing partitions of the table - be sure you know what you are doing!</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> foo <span class="keyword">PARTITION</span> (ds, hr) CHANGE <span class="keyword">COLUMN</span> dec_column_name dec_column_name <span class="type">DECIMAL</span>(<span class="number">38</span>,<span class="number">18</span>);</span><br></pre></td></tr></table></figure>

<p>或者，可以使用ALTER TABLE CHANGE COLUMN一次指定一个分区，通过为每个语句指定一个分区来完成，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> foo <span class="keyword">PARTITION</span> (ds<span class="operator">=</span><span class="string">&#x27;2008-04-08&#x27;</span>, hr<span class="operator">=</span><span class="number">11</span>) CHANGE <span class="keyword">COLUMN</span> dec_column_name dec_column_name <span class="type">DECIMAL</span>(<span class="number">38</span>,<span class="number">18</span>);</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> foo <span class="keyword">PARTITION</span> (ds<span class="operator">=</span><span class="string">&#x27;2008-04-08&#x27;</span>, hr<span class="operator">=</span><span class="number">12</span>) CHANGE <span class="keyword">COLUMN</span> dec_column_name dec_column_name <span class="type">DECIMAL</span>(<span class="number">38</span>,<span class="number">18</span>);</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
</ol>
</blockquote>
<h3 id="6-8-UNION类型"><a href="#6-8-UNION类型" class="headerlink" title="6.8 UNION类型"></a>6.8 UNION类型</h3><p> <strong>UNIONTYPE支持不完整</strong> ：</p>
<blockquote>
<p> 在Hive 0.7.0（Hive-537）中引入了UNIONTYPE数据类型，但在Hive中对该类型的完全支持仍不完整。在JOIN（HIVE-2508）、WHERE和GROUP BY子句中引用UNIONTYPE字段的查询将失败，并且HIVE没有定义提取UNIONTYPE的标记或值字段的语法。这意味着UNIONTYPEs只能有效地传递。 </p>
</blockquote>
<p>使用：</p>
<blockquote>
<p>联合类型可以在任意一点保存它们指定的数据类型之一。你可以使用create_union UDF创建该类型的实例:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> union_test(foo UNIONTYPE<span class="operator">&lt;</span><span class="type">int</span>, <span class="keyword">double</span>, <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>, struct<span class="operator">&lt;</span>a:<span class="type">int</span>,b:string<span class="operator">&gt;&gt;</span>);</span><br><span class="line"><span class="keyword">SELECT</span> foo <span class="keyword">FROM</span> union_test;</span><br><span class="line"></span><br><span class="line">&#123;<span class="number">0</span>:<span class="number">1</span>&#125;</span><br><span class="line">&#123;<span class="number">1</span>:<span class="number">2.0</span>&#125;</span><br><span class="line">&#123;<span class="number">2</span>:[&quot;three&quot;,&quot;four&quot;]&#125;</span><br><span class="line">&#123;<span class="number">3</span>:&#123;&quot;a&quot;:<span class="number">5</span>,&quot;b&quot;:&quot;five&quot;&#125;&#125;</span><br><span class="line">&#123;<span class="number">2</span>:[&quot;six&quot;,&quot;seven&quot;]&#125;</span><br><span class="line">&#123;<span class="number">3</span>:&#123;&quot;a&quot;:<span class="number">8</span>,&quot;b&quot;:&quot;eight&quot;&#125;&#125;</span><br><span class="line">&#123;<span class="number">0</span>:<span class="number">9</span>&#125;</span><br><span class="line">&#123;<span class="number">1</span>:<span class="number">10.0</span>&#125;</span><br></pre></td></tr></table></figure>

<p>反序列化的联合中的第一部分是标记，它让我们知道使用的是联合的哪个部分。在这个示例中，0表示定义中的第一个data_type，它是一个int，以此类推。要创建一个联合，你必须给create_union UDF提供这个标签:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> create_union(<span class="number">0</span>, key), create_union(if(key<span class="operator">&lt;</span><span class="number">100</span>, <span class="number">0</span>, <span class="number">1</span>), <span class="number">2.0</span>, <span class="keyword">value</span>), create_union(<span class="number">1</span>, &quot;a&quot;, struct(<span class="number">2</span>, &quot;b&quot;)) <span class="keyword">FROM</span> src LIMIT <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">&#123;<span class="number">0</span>:&quot;238&quot;&#125;	&#123;<span class="number">1</span>:&quot;val_238&quot;&#125;	&#123;<span class="number">1</span>:&#123;&quot;col1&quot;:<span class="number">2</span>,&quot;col2&quot;:&quot;b&quot;&#125;&#125;</span><br><span class="line">&#123;<span class="number">0</span>:&quot;86&quot;&#125;	&#123;<span class="number">0</span>:<span class="number">2.0</span>&#125;	&#123;<span class="number">1</span>:&#123;&quot;col1&quot;:<span class="number">2</span>,&quot;col2&quot;:&quot;b&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="七、字面常量类型（Literals）"><a href="#七、字面常量类型（Literals）" class="headerlink" title="七、字面常量类型（Literals）"></a>七、字面常量类型（Literals）</h2><h3 id="7-1-浮点类型"><a href="#7-1-浮点类型" class="headerlink" title="7.1 浮点类型"></a>7.1 浮点类型</h3><p>浮点类型的字面常量被设定为DOUBLE类型，暂不支持科学计数法。</p>
<h3 id="7-2-Decimal类型"><a href="#7-2-Decimal类型" class="headerlink" title="7.2 Decimal类型"></a>7.2 Decimal类型</h3><p>十进制字面值(Decimal Literals)为浮点数提供了比DOUBLE类型更精确的值和更大的范围。十进制数据类型存储数值的精确表示，而DOUBLE数据类型存储数值的非常接近的表示。当DOUBLE类型精确度不够时，可以使用Decimal类型。</p>
<p>可以创建一个含有Decimal类型属性的表：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> decimal_1 (t <span class="type">decimal</span>);</span><br></pre></td></tr></table></figure>

<p>可以使用LazySimpleSerDe或LazyBinarySerDe在这样的表中读写值。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> decimal_1 <span class="keyword">set</span> serde <span class="string">&#x27;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 或者</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> decimal_1 <span class="keyword">set</span> serde <span class="string">&#x27;org.apache.hadoop.hive.serde2.lazy.LazyBinarySerDe&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>可以将Decimal值转换为其他基本类型，例如BOOLEAN:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">cast</span>(t <span class="keyword">as</span> <span class="type">boolean</span>) <span class="keyword">from</span> decimal_2;</span><br></pre></td></tr></table></figure>

<p> Decimal还支持许多算术运算符、数学UDF(用户自定义函数)和UDAFs，其语法与DOUBLE中使用的语法相同 。</p>
<p>可以使用在Decimal类型的基本数学运算如下：</p>
<blockquote>
<ul>
<li>Positive</li>
<li>Negative</li>
<li>Addition</li>
<li>Subtraction</li>
<li>Multiplication</li>
<li>Division</li>
<li>Average (avg)</li>
<li>Sum</li>
<li>Count</li>
<li>Modulus (pmod)</li>
<li>Sign – Hive 0.13.0 and later</li>
<li>Exp – Hive 0.13.0 and later</li>
<li>Ln – Hive 0.13.0 and later</li>
<li>Log2 – Hive 0.13.0 and later</li>
<li>Log10 – Hive 0.13.0 and later</li>
<li>Log(<em>base</em>)  – Hive 0.13.0 and later</li>
<li>Sqrt – Hive 0.13.0 and later</li>
<li>Sin – Hive 0.13.0 and later</li>
<li>Asin  – Hive 0.13.0 and later</li>
<li>Cos – Hive 0.13.0 and later</li>
<li>Acos – Hive 0.13.0 and later</li>
<li>Tan – Hive 0.13.0 and later</li>
<li>Atan – Hive 0.13.0 and later</li>
<li>Radians – Hive 0.13.0 and later</li>
<li>Degrees – Hive 0.13.0 and later</li>
</ul>
</blockquote>
<p>一些舍入函数也可以用在Decimal类型上：</p>
<blockquote>
<ul>
<li>Floor</li>
<li>Ceiling</li>
<li>Round</li>
</ul>
</blockquote>
<p>Power(decimal, n) 只支持指数n的正整数值。</p>
<ul>
<li>缺失值处理</li>
</ul>
<blockquote>
<p>缺失的值由特殊值NULL表示。要导入带有NULL字段的数据，请检查表使用的SerDe的文档。(默认的文本格式使用LazySimpleSerDe，它在导入时将字符串\N解释为NULL。)</p>
</blockquote>
<ul>
<li>类型转换</li>
</ul>
<blockquote>
<p> 当hive.metastore.disallow.incompatible.col.type.changes被设置为false时，可以将原数据中列的类型从一种类型任意转换到另一种类型，如果类型转换是成功的，结果将会被显示，否则将显示NULL。</p>
</blockquote>
<p>下表展示了类型间是否可以相互转换：</p>
<table>
<thead>
<tr>
<th></th>
<th>void</th>
<th>boolean</th>
<th>tinyint</th>
<th>smallint</th>
<th>int</th>
<th>bigint</th>
<th>float</th>
<th>double</th>
<th>decimal</th>
<th>string</th>
<th>varchar</th>
<th>timestamp</th>
<th>date</th>
<th>binary</th>
</tr>
</thead>
<tbody><tr>
<td>void to</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
</tr>
<tr>
<td>boolean to</td>
<td>false</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>tinyint to</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>smallint to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>int to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>bigint to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>float to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>double to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>decimal to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>string to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>varchar to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>timestamp to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>date to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>true</td>
<td>false</td>
</tr>
<tr>
<td>binary to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
</tr>
</tbody></table>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/Hadoop/Hive/Hive%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E4%BC%98%E5%8C%96/" class="post-title-link" itemprop="url">Hive优化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:33:22" itemprop="dateModified" datetime="2023-09-27T18:33:22+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive优化"><a href="#Hive优化" class="headerlink" title="Hive优化"></a>Hive优化</h1><h2 id="1-Fetch抓取"><a href="#1-Fetch抓取" class="headerlink" title="1. Fetch抓取"></a>1. Fetch抓取</h2><blockquote>
<p>Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算.</p>
<p>hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。</p>
</blockquote>
<h2 id="2-本地模式"><a href="#2-本地模式" class="headerlink" title="2. 本地模式"></a>2. 本地模式</h2><blockquote>
<p>有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p>
<p>可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto<span class="operator">=</span><span class="literal">true</span>;  <span class="operator">/</span><span class="operator">/</span>开启本地mr</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>设置<span class="keyword">local</span> mr的最大输入数据量，当输入数据量小于这个值时采用<span class="keyword">local</span>  mr的方式，默认为<span class="number">134217728</span>，即<span class="number">128</span>M</span><br><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto.inputbytes.max<span class="operator">=</span><span class="number">50000000</span>;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>设置<span class="keyword">local</span> mr的最大输入文件个数，当输入文件个数小于这个值时采用<span class="keyword">local</span> mr的方式，默认为<span class="number">4</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto.input.files.max<span class="operator">=</span><span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<h2 id="3-表的优化"><a href="#3-表的优化" class="headerlink" title="3. 表的优化"></a>3. 表的优化</h2><h3 id="3-1-小表、大表join"><a href="#3-1-小表、大表join" class="headerlink" title="3.1 小表、大表join"></a>3.1 小表、大表join</h3><blockquote>
<p>将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用map join让小的维度表（1000条以下的记录条数）先进内存。在map端完成reduce。</p>
<p>新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。</p>
</blockquote>
<h3 id="3-2-大表-join-大表"><a href="#3-2-大表-join-大表" class="headerlink" title="3.2 大表 join 大表"></a>3.2 大表 join 大表</h3><h4 id="3-2-1-空key过滤"><a href="#3-2-1-空key过滤" class="headerlink" title="3.2.1 空key过滤"></a>3.2.1 空key过滤</h4><blockquote>
<p>有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。</p>
<p>join前可以将值为空的连接key过滤掉。</p>
</blockquote>
<h4 id="3-2-2-空key转换"><a href="#3-2-2-空key转换" class="headerlink" title="3.2.2 空key转换"></a>3.2.2 空key转换</h4><blockquote>
<p>有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。</p>
</blockquote>
<h3 id="3-3-MapJoin"><a href="#3-3-MapJoin" class="headerlink" title="3.3 MapJoin"></a>3.3 MapJoin</h3><p>工作机制：</p>
<p><img src="/Hadoop/Hive/Hive%E4%BC%98%E5%8C%96/.%5CHive%E4%BC%98%E5%8C%96%5Cclip_image002.png" alt="img"></p>
<p>开启MapJoin功能：</p>
<p>​	<code>set hive.auto.convert.join = true; </code>         默认为true</p>
<p>大表小表的阈值设置（默认25M一下认为是小表）：</p>
<p>​	<code>set hive.mapjoin.smalltable.filesize=25000000;</code></p>
<h3 id="3-4-Group-By"><a href="#3-4-Group-By" class="headerlink" title="3.4 Group By"></a>3.4 Group By</h3><blockquote>
<p>默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。</p>
<p>并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。</p>
</blockquote>
<p>1．开启Map端聚合参数设置</p>
<p>（1）是否在Map端进行聚合，默认为True</p>
<p>​	<code>hive.map.aggr = true</code></p>
<p>（2）在Map端进行聚合操作的条目数目</p>
<p>​	<code>hive.groupby.mapaggr.checkinterval = 100000</code></p>
<p>（3）有数据倾斜的时候进行负载均衡（默认是false）</p>
<p>​	<code>hive.groupby.skewindata = true</code></p>
<blockquote>
<p>当选项设定为 true，生成的查询计划会有两个MR Job。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。</p>
</blockquote>
<h3 id="3-5-Count-Distinct-去重统计"><a href="#3-5-Count-Distinct-去重统计" class="headerlink" title="3.5 Count(Distinct) 去重统计"></a>3.5 Count(Distinct) 去重统计</h3><blockquote>
<p>数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换,虽然会多用一个Job来完成，但在数据量大的情况下，这个绝对是值得的。</p>
</blockquote>
<h3 id="3-6-笛卡尔积"><a href="#3-6-笛卡尔积" class="headerlink" title="3.6 笛卡尔积"></a>3.6 笛卡尔积</h3><blockquote>
<p>尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。</p>
</blockquote>
<h3 id="3-7-行列过滤"><a href="#3-7-行列过滤" class="headerlink" title="3.7 行列过滤"></a>3.7 行列过滤</h3><blockquote>
<p>列处理：在SELECT中，只拿需要的列，如果有，尽量使用分区过滤，少用SELECT *。</p>
<p>行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤.  所以连接的子表需要过滤时，应尽量现在子表中使用where条件过滤，实在无法再子表中过滤时再考虑在关联之后使用where条件过滤</p>
</blockquote>
<h3 id="3-8-动态分区"><a href="#3-8-动态分区" class="headerlink" title="3.8 动态分区"></a>3.8 动态分区</h3><blockquote>
<p>关系型数据库中，对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中，Hive中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过，使用Hive的动态分区，需要进行相应的配置。</p>
</blockquote>
<p><strong>1．开启动态分区参数设置</strong></p>
<p>（1）开启动态分区功能（默认true，开启）</p>
<p>​	<code>set hive.exec.dynamic.partition=true;</code></p>
<p>（2）设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。）</p>
<p>​	<code>set hive.exec.dynamic.partition.mode=nonstrict;</code></p>
<p>（3）在所有执行MR的节点上，最大一共可以创建多少个动态分区。</p>
<p>​	<code>set hive.exec.max.dynamic.partitions=1000;</code></p>
<p>​    （4）在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</p>
<p>​	<code>set hive.exec.max.dynamic.partitions.pernode=100;</code></p>
<p>（5）整个MR Job中，最大可以创建多少个HDFS文件。</p>
<p>​	<code>set hive.exec.max.created.files=100000;</code></p>
<p>（6）当有空分区生成时，是否抛出异常。一般不需要设置。</p>
<p>​	<code>set hive.error.on.empty.partition=false;</code></p>
<h2 id="4-数据倾斜（MR优化）"><a href="#4-数据倾斜（MR优化）" class="headerlink" title="4. 数据倾斜（MR优化）"></a>4. 数据倾斜（MR优化）</h2><h3 id="4-1-合理设置Map数"><a href="#4-1-合理设置Map数" class="headerlink" title="4.1 合理设置Map数"></a>4.1 合理设置Map数</h3><p><strong>1</strong>）通常情况下，作业会通过input的目录产生一个或者多个map任务。</p>
<p>​	主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。</p>
<p><strong>2</strong>）是不是map数越多越好？</p>
<p>​	答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</p>
<p><strong>3</strong>）是不是保证每个map处理接近128m的文件块，就高枕无忧了？</p>
<p>​	答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。</p>
<p>针对上面的问题2和3，我们需要采取两种方式来解决：即减少map数和增加map数；</p>
<h3 id="4-2-小文件合并"><a href="#4-2-小文件合并" class="headerlink" title="4.2 小文件合并"></a>4.2 小文件合并</h3><p>在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p>
<p>​	<code>set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</code></p>
<h3 id="4-3-复杂文件增加Map数"><a href="#4-3-复杂文件增加Map数" class="headerlink" title="4.3 复杂文件增加Map数"></a>4.3 复杂文件增加Map数</h3><p>当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p>
<p>增加map的方法为：根据computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))&#x3D;blocksize&#x3D;128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</p>
<p>设置最大切片值大小：</p>
<p>​	<code>set mapreduce.input.fileinputformat.split.maxsize=100;</code></p>
<h3 id="4-4-合理设置Reduce数"><a href="#4-4-合理设置Reduce数" class="headerlink" title="4.4 合理设置Reduce数"></a>4.4 合理设置Reduce数</h3><p><strong>1．调整reduce个数方法一</strong>   （通过设置每个Reduce处理的数据量确定Reduce的值）</p>
<p>（1）每个Reduce处理的数据量默认是256MB</p>
<p>​	<code>set hive.exec.reducers.bytes.per.reducer=256000000;</code></p>
<p>（2）每个任务最大的reduce数，默认为1009</p>
<p>​	<code>set hive.exec.reducers.max=1009;</code></p>
<p>（3）计算reducer数的公式</p>
<p>​	<code>	N=min(参数2，总输入数据量/参数1)</code></p>
<p><strong>2．调整reduce个数方法二</strong>	(直接指定reduce的个数)</p>
<p>在hadoop的mapred-default.xml文件中修改</p>
<p>设置每个job的Reduce个数(默认为-1, 按数据在MapReduce之前的大小，以及上面方法一的配置量来分配的)</p>
<p>​	<code>set mapreduce.job.reduces = 15;</code></p>
<p><strong>3．reduce个数并不是越多越好</strong></p>
<p>1）过多的启动和初始化reduce也会消耗时间和资源；</p>
<p>2）另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</p>
<p>在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</p>
<h2 id="5-并行执行"><a href="#5-并行执行" class="headerlink" title="5. 并行执行"></a>5. 并行执行</h2><p>hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。</p>
<p>​    通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p>
<p><code>set hive.exec.parallel=true; </code>      &#x2F;&#x2F;打开任务并行执行</p>
<p><code>set hive.exec.parallel.thread.number=16;</code> &#x2F;&#x2F;同一个sql允许最大并行度，默认为8。</p>
<p>当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。</p>
<h2 id="6-严格模式"><a href="#6-严格模式" class="headerlink" title="6. 严格模式"></a>6. 严格模式</h2><p>Hive提供了一个严格模式，可以防止用户执行那些可能意想不到的不好的影响的查询。</p>
<p>​    通过设置属性hive.mapred.mode值为默认是非严格模式nonstrict 。开启严格模式需要修改hive.mapred.mode值为strict     <code>set hive.mapred.mode=strict;</code></p>
<p>，开启严格模式可以禁止3种类型的查询。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.mapred.mode<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>strict<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      The mode in which the Hive operations are being performed. </span><br><span class="line">      In strict mode, some risky queries are not allowed to run. They include:</span><br><span class="line">        Cartesian Product.</span><br><span class="line">        No partition being picked up for a query.</span><br><span class="line">        Comparing bigints and strings.</span><br><span class="line">        Comparing bigints and doubles.</span><br><span class="line">        Orderby without limit.</span><br><span class="line"><span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li><p>对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p>
</li>
<li><p>对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</p>
</li>
<li><p>限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p>
</li>
</ol>
<h2 id="7-JVM重用"><a href="#7-JVM重用" class="headerlink" title="7. JVM重用"></a>7. JVM重用</h2><p>JVM重用是Hadoop调优参数的内容，其对Hive的性能具有非常大的影响，特别是对于很难避免小文件的场景或task特别多的场景，这类场景大多数执行时间都很短。</p>
<p>Hadoop的默认配置通常是使用派生JVM来执行map和Reduce任务的。这时JVM的启动过程可能会造成相当大的开销，尤其是执行的job包含有成百上千task任务的情况。JVM重用可以使得JVM实例在同一个job中重新使用N次。N的值可以在Hadoop的mapred-site.xml文件中进行配置。通常在10-20之间，具体多少需要根据具体业务场景测试得出。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.jvm.numtasks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">     How many tasks to run per jvm. If set to -1, there is no limit. </span><br><span class="line"> <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>这个功能的缺点是，开启JVM重用将一直占用使用到的task插槽，以便进行重用，直到任务完成后才能释放。如果某个“不平衡的”job中有某几个reduce task执行的时间要比其他Reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。</p>
<h2 id="8-推测执行"><a href="#8-推测执行" class="headerlink" title="8. 推测执行"></a>8. 推测执行</h2><p>在分布式集群环境下，因为程序Bug（包括Hadoop本身的bug），负载不均衡或者资源分布不均等原因，会造成同一个作业的多个任务之间运行速度不一致，有些任务的运行速度可能明显慢于其他任务（比如一个作业的某个任务进度只有50%，而其他所有任务已经运行完毕），则这些任务会拖慢作业的整体执行进度。为了避免这种情况发生，Hadoop采用了推测执行（Speculative Execution）机制，它根据一定的法则推测出“拖后腿”的任务，并为这样的任务启动一个备份任务，让该任务与原始任务同时处理同一份数据，并最终选用最先成功运行完成任务的计算结果作为最终结果。</p>
<p>设置开启推测执行参数：Hadoop的mapred-site.xml文件中进行配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some map tasks </span><br><span class="line">               may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some reduce tasks </span><br><span class="line">               may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>不过hive本身也提供了配置项来控制reduce-side的推测执行：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.mapred.reduce.tasks.speculative.execution<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether speculative execution for reducers should be turned on. <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>关于调优这些推测执行变量，还很难给一个具体的建议。如果用户对于运行时的偏差非常敏感的话，那么可以将这些功能关闭掉。如果用户因为输入数据量很大而需要执行长时间的map或者Reduce task的话，那么启动推测执行造成的浪费是非常巨大大。</p>
<h2 id="10-执行计划（Explain）"><a href="#10-执行计划（Explain）" class="headerlink" title="10. 执行计划（Explain）"></a>10. 执行计划（Explain）</h2><p>1．基本语法</p>
<p>EXPLAIN [EXTENDED | DEPENDENCY | AUTHORIZATION] query</p>
<p>2．案例实操</p>
<p>（1）查看下面这条语句的执行计划</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain <span class="keyword">select</span> deptno, <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno;</span><br></pre></td></tr></table></figure>

<p>（2）查看详细执行计划</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain extended <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain extended <span class="keyword">select</span> deptno, <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/Hadoop/Hive/Hive%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">Hive基本知识</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:32:05" itemprop="dateModified" datetime="2023-09-27T18:32:05+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>554</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive基本知识"><a href="#Hive基本知识" class="headerlink" title="Hive基本知识"></a>Hive基本知识</h1><h2 id="一、分区表"><a href="#一、分区表" class="headerlink" title="一、分区表"></a>一、分区表</h2><p>分区表是指按照数据表的某列或某些列分为多个区，区从形式上可以理解为文件夹，分区是手动进行的。</p>
<p>注意，不通与传统数据库，hive在创建分区表时 CREATE TABLE 下的字段中不能包含分区表字段，分区表字段只在PARTITION BY中定义，创建后，分区字段是表中的最后字段。</p>
<p>如果对表进行分区，即数据分分割存放在若干子目录下，则既可以将分区指向各个子目录，也可以采用递归分区使一个表访问所有子目录。当子目录无法满足这两个中的任何中情况，则会出现错误或者查询为空。</p>
<p>分区最佳实践：</p>
<ul>
<li>挑选一列作为分区键，其唯一值的个数应该在较低值到中间值之间。</li>
<li>避免分区小于1G(越大越好）。</li>
<li>当分区数量较多时，调整HiveServer2和Hive Metastore的内存。</li>
<li>当使用多列作为分区键时，对于每一个分区键列的组合都要创建一个子目录的嵌套树。应避免深入嵌套，因为这会导致太多的分区，进而是创建的文件非常小。</li>
<li>当使用Hive流处理插入数据时，如果多个会话向相同的分区写入数据，那么就会导致锁闭。</li>
<li>你可以修改某一分区表的模式，然而，一旦结构发生改变，你就无法在已有分区中修改数据了。</li>
<li>如果要将数据并行插入到多个分区，应该将<code>hive.optimize.sort.dynamic.partition</code>设置为true。</li>
</ul>
<h2 id="二、分桶表"><a href="#二、分桶表" class="headerlink" title="二、分桶表"></a>二、分桶表</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/ETL/ETL%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/ETL/ETL%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/" class="post-title-link" itemprop="url">ETL开发流程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-11-02 19:06:17" itemprop="dateModified" datetime="2023-11-02T19:06:17+08:00">2023-11-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ETL/" itemprop="url" rel="index"><span itemprop="name">ETL</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ETL开发流程"><a href="#ETL开发流程" class="headerlink" title="ETL开发流程"></a>ETL开发流程</h1><h2 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h2><h3 id="1-开发架构确定"><a href="#1-开发架构确定" class="headerlink" title="1. 开发架构确定"></a>1. 开发架构确定</h3><p>​	在接收到需求后，首先要弄清楚业务类型，以及数据源类型。在宏观上，ETL是围绕数据开展的工作，不应局限于某种技术或某种数据处理方式，所以，在条件允许的情况下，应该选取最适合业务的开发架构和方式。以下列举了几种开发架构，笔者经验所限，后续将持续更新新的架构。</p>
<ul>
<li><p>离线开发：Hadoop+ hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">经典的离线开发方式，当需求对数据的实时性要求没那么高时，可以采用此种开发方式。当然该架构对于配置要求较高，需要有Hadoop集群以及数据开发平台。</span><br></pre></td></tr></table></figure>
</li>
<li><p>实时开发：待补充</p>
</li>
<li><p>待补充</p>
</li>
</ul>
<h3 id="2-了解数据源"><a href="#2-了解数据源" class="headerlink" title="2. 了解数据源"></a>2. 了解数据源</h3><p>当拿到一份陌生的数据源&#x2F;数据源表，首先要做的是对该表进行充分的了解：</p>
<ul>
<li>表字段、字段类型、字段注释的了解</li>
<li>表的业务背景、来源、每个字段的含义</li>
<li>表的更新方式（增量&#x2F;全量）、表格结构（普通表&#x2F;分区&#x2F;分桶）、使用方式（只用最新分区&#x2F;使用部分分区&#x2F;使用全量分区）</li>
</ul>
<p>基于对表的这些了解，应该形成文档，对要点做适当的记录，避免下次使用该表时因为疏漏而踩坑。</p>
<p>然后，需要对数据源表进行数据探查，主要是为了大致评估数据量、数据质量、以及一些其他信息。数据探查的逻辑主要根据业务需求来制定，探查过后应该对资源分配、开发方式、数据源是否符合需求等有一个评估结论</p>
<h3 id="2-开发逻辑设计"><a href="#2-开发逻辑设计" class="headerlink" title="2. 开发逻辑设计"></a>2. 开发逻辑设计</h3><h3 id="3-表结构设计"><a href="#3-表结构设计" class="headerlink" title="3. 表结构设计"></a>3. 表结构设计</h3><h3 id="4-数据流梳理"><a href="#4-数据流梳理" class="headerlink" title="4. 数据流梳理"></a>4. 数据流梳理</h3><h2 id="开发阶段"><a href="#开发阶段" class="headerlink" title="开发阶段"></a>开发阶段</h2><h3 id="1-离线开发流程"><a href="#1-离线开发流程" class="headerlink" title="1. 离线开发流程"></a>1. 离线开发流程</h3><h4 id="1-1-数据探查（了解数据源）"><a href="#1-1-数据探查（了解数据源）" class="headerlink" title="1.1 数据探查（了解数据源）"></a>1.1 数据探查（了解数据源）</h4><p>当拿到一份陌生的数据源&#x2F;数据源表，首先要做的是对该表进行充分的了解，主要了解方式为数据探查：</p>
<ul>
<li><p><strong>表的业务背景、来源</strong></p>
<ul>
<li>使用数据前，必须了解数据源的来源及业务背景，这有助于理解业务，了解业务是开发的前提，否则成果将是充满隐患的。</li>
<li>这些知识可以从产品经理处获取，也可以联系数据源的创建者或相关人员，总之，为了理解业务可以联系一切业务相关的人。</li>
</ul>
</li>
<li><p><strong>了解表字段、字段类型、字段注释</strong></p>
<ul>
<li><strong>表字段</strong>：<br>表中总会有一些关键字段（类似于主键的字段）和一些维度字段，这些字段和业务息息相关。<br>① 了解这些字段的业务含义<br>② 关键字段需要探查一下是否有重复值，分析是否符合业务需求，并做好记录。<br>③ 维度字段需要探查一下字段值的组成，分析是否符合业务需求，并做好记录。<br>④ 还要关注这些字段的数据质量，例如是否有脏数据、缺失值等，并做好记录。<br>⑤ 待补充</li>
<li><strong>字段类型</strong>：<br>抽取表的一部分数据，查看各字段值的情况：<br>① 字段值形式上为集合数据类型的（例如数组、map、struct等），需要关注实际类型是否为集合类型，如果不是，则使用的时候大概率需要做类型转换，此处要做好记录。<br>② 字段值为时间或者时间戳的，需要关注一下实际类型，还要记录一下时间格式，以及时间戳的位数（10位 or 13位）。<br>③ 待补充</li>
<li><strong>字段注释</strong>：<br>字段注释是数据开发人员给出的字段简要解释，在某些情况下具有及其重要的解释意义：<br>① 有些字段是标识性的，其取值一般带有标识意义，例如用0， 1表示不同的意义，理解这些字段的关键就在于查看字段注释或者字段名称。<br>② 待补充</li>
</ul>
</li>
<li><p><strong>表的更新方式（增量&#x2F;全量）、表类型（普通表&#x2F;分区&#x2F;分桶）</strong></p>
<ul>
<li><strong>数据更新方式：</strong><br>数据更新方式有两种：增量更新和全量更新。<br>① 增量更新：以分区表为例，增量更新的表，分区内的数据只与该分区有关。例如一个天分区内只存储该天的数据。一般增量更新的表，使用的时候需要跨分区使用多个分区的数据。<br>② 全量更新：以分区表为例，全量更新的表，每个分区内都存储了截止到该分区的全量历史数据，一般全量更新的表，使用的时候只需要取最新分区的数据即可。</li>
<li><strong>表类型：</strong><br>以hive为例，介绍一下表类型：<br>① 内部表（Internal Table）：这是Hive默认创建的表类型，数据存储在Hive的数据仓库中，当删除表时，数据也会被删除。<br>② 外部表（External Table）：这种表类型的数据存储在Hive之外，例如HDFS或本地文件系统。当删除表时，数据不会被删除。③ 索引表（Index Table）：这种表类型是在Hive 0.8.0版本中引入的，它可以加速查询操作。索引表是基于内部表或外部表创建的，它们包含了指向原始表数据的指针。<br>④ 分区表（Partitioned Table）：这种表类型将数据按照指定的列分成不同的分区，可以提高查询效率。分区表可以是内部表或外部表。<br>⑤ 桶表（Bucketed Table）：这种表类型将数据按照指定的列分成不同的桶，每个桶中包含相同数量的数据。桶表可以是内部表或外部表。</li>
</ul>
</li>
</ul>
<ol>
<li><p>数据清洗<br>在充分了解了数据源之后，就需要根据业务需求对数据进行处理了：</p>
<ul>
<li><p><strong>确定业务数据范围</strong>。包括：</p>
<ul>
<li>业务数据范围：<br>在逻辑上对数据源的数据进行截取，例如只需要统计当年的数据，则通过表中的时间字段进行过滤即可。</li>
<li>字段范围：<br>确定关键的字段有哪些，根据业务抽取需要的字段，对于一些明显用不到的字段，可以舍去，对于以后可能会用到的字段予以保留，避免后续迭代对表结构做改动。</li>
<li>特别地，如果后续会经常使用该表，可以考虑只对该表做数据范围上的筛选，而不做字段范围上的限制（保留全部字段），加以清洗后形成一张通用明细表</li>
</ul>
</li>
<li><p><strong>脏数据清洗</strong>。</p>
<ul>
<li><p>字段内容清洗<br>字段内容清洗是最常见的脏数据处理方式</p>
<ul>
<li>某些字段中可能掺杂了一些特殊字符、乱码数据等。这种情况下，一般需要将特殊字符去除，或者将整个值做统一替换处理。处理方式一般为字符串替换、正则表达式替换、或者采用if 、case when 等条件函数进行映射等。</li>
<li>某些字段中可能存在一些不该存在的值，这种情况一般直接做映射处理，将这些不合适的值替换为其他值，可以采用上面的处理方式进行处理。</li>
</ul>
</li>
<li><p>缺失值处理</p>
<ul>
<li><p>缺失值统一转换：<br>对于缺失值，最常规的处理方式就是将缺失值做统一转换，可以转换为某个特定的值，也可以将不同的缺失值统一成一样的缺失值，便于后续处理。处理一般可借助COALESCE、IF、NVL、CASE WHEN等函数。<br>特别地，在处理表时，由于很多字段不能确定是否有缺失值，或者日后是否会产生缺失值，所以在处理时基本可以对所有字段进行缺失值处理，防止出现缺失值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">空值转换:</span><br><span class="line">	NVL(field, 替换后的值)</span><br><span class="line">	IF(field IS NULL, 替换后的值, field)</span><br><span class="line">空字符串转NULL:</span><br><span class="line">	IF(field = &#x27;&#x27;, 替换后的值, field)</span><br><span class="line">判断字段是否为空或者空字符串:</span><br><span class="line">	COALESCE(field, &#x27;&#x27;) = &#x27;&#x27;    --字段为空或者空字符串</span><br><span class="line">	field IS NULL OR field = &#x27;&#x27; --字段为空或者空字符串</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>详细地址解析<br>当表中只有一个长串的详细地址字段，而没有单独的省市地址字段时，需要使用正则表达式进行解析，表达式书写需要根据具体的数据情况来写，考虑到一般的地址书写格式都比较相似，下面总结了一下地址解析的HIVESQL代码，主要是从详细地址中解析出省份名称和市名称，后续会不断优化，注意代码中语句的顺序十分重要：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">CASE</span><br><span class="line">    WHEN install_addr LIKE &#x27;%市%省%&#x27; THEN &#x27;其他&#x27; --异常数据过滤</span><br><span class="line">    WHEN install_addr LIKE &#x27;%北京%&#x27; THEN &#x27;北京市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%天津%&#x27; THEN &#x27;天津市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%上海%&#x27; THEN &#x27;上海市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%重庆%&#x27; THEN &#x27;重庆市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%香港%&#x27; THEN &#x27;香港特别行政区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%澳门%&#x27; THEN &#x27;澳门特别行政区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;.*?自治区&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%省%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;.*?省&#x27;, 0)</span><br><span class="line">    ELSE &#x27;其他&#x27;</span><br><span class="line">END AS province_desc</span><br><span class="line">,CASE</span><br><span class="line">    WHEN install_addr LIKE &#x27;%北京%&#x27; THEN &#x27;北京市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%天津%&#x27; THEN &#x27;天津市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%上海%&#x27; THEN &#x27;上海市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%重庆%&#x27; THEN &#x27;重庆市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%省%自治州%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?省&#x27;, &#x27;&#x27;), &#x27;^.*?自治州&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%自治州%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?自治州&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%地区%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?地区&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%省%地区%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?省&#x27;, &#x27;&#x27;), &#x27;^.*?地区&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%盟%市%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?盟&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%市%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?市&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%盟%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?盟&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%省%市%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?省&#x27;, &#x27;&#x27;), &#x27;^.*?市&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%香港%&#x27; THEN &#x27;香港特别行政区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%澳门%&#x27; THEN &#x27;澳门特别行政区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%神农架林区%&#x27; THEN &#x27;神农架林区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%平潭综合实验区%&#x27; THEN &#x27;平潭综合实验区&#x27;</span><br><span class="line">    ELSE &#x27;其他&#x27;</span><br><span class="line">END AS city_desc</span><br></pre></td></tr></table></figure>
</li>
<li><p>字段类型转换<br>字段类型转换是一个比较头疼的问题，按规范来说，不同类型的字段应该选取最合适的字段类型。但是在实际开发中，还是推荐尽量在建表时将字段类型都指定为字符串类型，避免因类型转换带来的一系列问题。但一些数字类型的字段例外特别是整形字段，对于需要做数学运算的整形字段，建表时还是指定为整形，因为对字符串数字进行运算，结果常常会出现小数，处理比较麻烦。<br>字段类型转换遵循由简入繁的规则，特别是数值类型的字段，例如，任何整数类型都可以隐式地转换为一个范围更大的类型，TINYINT,SMALLINT,INT,BIGINT,FLOAT,STRING 都可以隐式地转换为DOUBLE，INT类型不能隐式地转换为TINYINT、SMALLINT类型（除非使用cast函数）,BOOLEAN不能转换为任何类型。</p>
</li>
</ul>
</li>
</ul>
</li>
<li></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/Hadoop/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">Hadoop学习笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-02-15 18:09:12" itemprop="dateCreated datePublished" datetime="2023-02-15T18:09:12+08:00">2023-02-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:26:20" itemprop="dateModified" datetime="2023-09-27T18:26:20+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">Hadoop学习笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hadoop学习笔记"><a href="#Hadoop学习笔记" class="headerlink" title="Hadoop学习笔记"></a>Hadoop学习笔记</h1><h3 id="1-一些基本命令"><a href="#1-一些基本命令" class="headerlink" title="1. 一些基本命令"></a>1. 一些基本命令</h3><p>启动hadoop：<br>1)开启SSH传输服务：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ssh start</span><br></pre></td></tr></table></figure>

<p>2)启动hadoop：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">一次启动</span><br><span class="line">[bash] hadoop安装路径/sbin/start-all.sh</span><br><span class="line">也可以手动多次启动</span><br></pre></td></tr></table></figure>

<p>操作HDFS系统：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop 2.x版本</span><br><span class="line">hadoop安装路径/bin/hdfs dfs -命令</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop 3.x版本</span><br><span class="line">hadoop安装路径/bin/hdfs fs -命令</span><br></pre></td></tr></table></figure>

<h3 id="2-mapreduce样例运行时的文件系统切换"><a href="#2-mapreduce样例运行时的文件系统切换" class="headerlink" title="2. mapreduce样例运行时的文件系统切换"></a>2. mapreduce样例运行时的文件系统切换</h3><p>在运行诸如mapreduce样例中的grep、wordcount等功能时，很重要的一点是指定文件的输入文件夹路径和输出文件夹（注意输出文件夹不需要提前创建），此时，我们指定的路径是本地路径还是HDFS中的路径呢？需要在Hadoop的配置文件core-site.xml进行指定，当不配置路径时，默认文件系统的路径是Hadoop的安装文件夹下，此外，可以通过配置将文件系统切换为HDFS，在core-site.xml中添加以下配置指定HDFS中NameNode的地址即可：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>添加此配置后，运行wordcount等案例时，指定的输入输出路径就是HDFS中的路径了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/root/input /user/root/output</span><br></pre></td></tr></table></figure>

<h3 id="3-hadoop50070监控界面中无法下载HDFS中的文件"><a href="#3-hadoop50070监控界面中无法下载HDFS中的文件" class="headerlink" title="3. hadoop50070监控界面中无法下载HDFS中的文件"></a>3. hadoop50070监控界面中无法下载HDFS中的文件</h3><p>添加主机到虚拟机集群的IP映射，将虚拟机hosts文件中的内容添加到windows主机中<br>虚拟机hosts文件路径：<code>/etc/hosts</code><br>windows hosts文件路径：<code>C:\Windows\System32\drivers\etc\hosts</code></p>
<p>添加后重启服务器或虚拟机即可。</p>
<h3 id="4-格式化NameNode（首次启动集群时格式化，不要总格式化）"><a href="#4-格式化NameNode（首次启动集群时格式化，不要总格式化）" class="headerlink" title="4. 格式化NameNode（首次启动集群时格式化，不要总格式化）"></a>4. 格式化NameNode（首次启动集群时格式化，不要总格式化）</h3><p><strong>注意：格式化NameNode，会产生新的集群id,导致NameNode和DataNode的集群id不一致，集群找不到已往数据。所以，格式NameNode时，一定要先删除data数据和log日志，然后再格式化NameNode。(集群id不一致将导致DataNode和NameNode不能同时启动)</strong></p>
<p><strong>提示：NameNode和DataNode的集群id可以在<code>安装路径/data/tmp/dfs/name/current/VERSION</code> <code>安装路径/data/tmp/dfs/data/current/</code>中或者<code>安装路径/tmp/dfs/name/current/VERSION</code> <code>安装路径/tmp/dfs/data/current/VERSION</code>中查看</strong></p>
<p>查看java进程，查看NameNode和DataNode是否关闭(jps是JDK中的命令，非linux自带命令)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure>

<p>将hadoop安装目录下的data文件夹 和 logs文件夹删除</p>
<p>格式化NameNode：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop安装目录下/bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>

<h3 id="5-通过yarn运行MapReduce程序时的问题处理"><a href="#5-通过yarn运行MapReduce程序时的问题处理" class="headerlink" title="5. 通过yarn运行MapReduce程序时的问题处理"></a>5. 通过yarn运行MapReduce程序时的问题处理</h3><ul>
<li>资源监控页面配置</li>
</ul>
<p>yarn资源监控界面需要在yarn-site.xml中配置主机名称，默认名称为0.0.0.0,默认端口号为8088，在启动yarn（ResourceManager和NodeManager）后可以访问资源监控页面，查看MapReduce任务的执行情况和资源使用情况。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;主机名称，自己指定&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>运行失败时classpath配置</li>
</ul>
<p>通过yarn运行MR程序时，可能出现运行失败的情况，可以在hadoop安装目录&#x2F;logs&#x2F;userlogs&#x2F;目录下，根据报错信息找到出错应用日志的位置。如报错信息中显示：<code>Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.</code>，需要将hadoop的classpath信息写入配置。在命令行中执行<code>hadoop classpath</code>,得到路径将其复制，然后写入yarn-site.xml以及mapred-site.xml中:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.application.classpath&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;classpath内容&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>虚拟内存超限配置</li>
</ul>
<p>如果运行任务遇到虚拟内存使用超过限制的报错，可以在yarn-site.xml中添加参数，使程序运行时跳过内存检查：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>由于NameNode开启了安全模式（safe-mode）导致程序运行时DataNode权限不足的问题</li>
</ul>
<p>退出安全模式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -safemode leave</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/Hexo/Hexo%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hexo/Hexo%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86/" class="post-title-link" itemprop="url">Hexo报错处理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-01-30 11:10:08" itemprop="dateCreated datePublished" datetime="2023-01-30T11:10:08+08:00">2023-01-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:34:33" itemprop="dateModified" datetime="2023-09-27T18:34:33+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>496</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hexo报错处理"><a href="#Hexo报错处理" class="headerlink" title="Hexo报错处理"></a>Hexo报错处理</h1><ol>
<li><p>使用部署命令<code>hexo d</code> <code>hexo deploy</code>或测试部署命令<code>hexo s</code> <code>hexo server</code>时出现报错：</p>
<blockquote>
<p>end of the stream or a document separator is expected</p>
</blockquote>
</li>
</ol>
<p>这种问题一般是因为头标注文件信息缺失而导致的。添加头标注文件即可，可以参考《为文章添加分类和标签》这篇文章进行解决。</p>
<ol start="2">
<li><p>为文章添加了标签tags 或分类 categorie，文章部署后，想修改标签或分类的大小写，直接修改了源文件头部标注文件，再次部署后相关tags 和 categories点击出现404空白页。</p>
<p>原因：自动生成的用于存放对应标签或分类的html文件的文件夹名字没有随源文件的更改而更改，这是由于git忽略了大小写而导致的。</p>
<p>解决办法：<br>方法一：修改git配置，在博客根目录下，显示隐藏文件，修改<code>.deploy_git/.git/config</code>文件，将该配置文件中的忽略大小写配置项改为false：<code>ignorecase = false</code><br>方法二：删除博客根目录文件夹下.deploy_git目录下tags文件夹或者categories文件夹中对应的标签或分类文件夹，然后重新部署发布，让文件夹重新生成。</p>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/Hexo/%E4%B8%BA%E6%96%87%E7%AB%A0%E6%B7%BB%E5%8A%A0%E5%88%86%E7%B1%BB%E5%92%8C%E6%A0%87%E7%AD%BE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hexo/%E4%B8%BA%E6%96%87%E7%AB%A0%E6%B7%BB%E5%8A%A0%E5%88%86%E7%B1%BB%E5%92%8C%E6%A0%87%E7%AD%BE/" class="post-title-link" itemprop="url">为文章添加分类和标签</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-01-30 10:24:24" itemprop="dateCreated datePublished" datetime="2023-01-30T10:24:24+08:00">2023-01-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:36:03" itemprop="dateModified" datetime="2023-09-27T18:36:03+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="为文章添加分类和标签"><a href="#为文章添加分类和标签" class="headerlink" title="为文章添加分类和标签"></a>为文章添加分类和标签</h1><h2 id="一、修改配置文件"><a href="#一、修改配置文件" class="headerlink" title="一、修改配置文件"></a>一、修改配置文件</h2><p>将主题目录下的配置文件中的tags 和 categories配置项置为true，注意冒号后要有空格：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tags: true</span><br><span class="line">categories: true</span><br></pre></td></tr></table></figure>

<h2 id="二、-创建样板文件"><a href="#二、-创建样板文件" class="headerlink" title="二、 创建样板文件"></a>二、 创建样板文件</h2><p>在source目录下，与_posts文件夹平行的位置，使用git工具新建两个目录categories 和 tags：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo new page &quot;tags&quot;</span><br><span class="line">hexo new page &quot;categories&quot;</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo new page --path tags/index &quot;tags&quot;</span><br><span class="line">hexo new page --path categories/index &quot;categories&quot;</span><br></pre></td></tr></table></figure>

<p>编辑tags目录下的index文件，修改内容为：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span>  <span class="string">tags</span></span><br><span class="line"><span class="attr">date:</span>  <span class="number">2022-11-19 11:04:55</span></span><br><span class="line"><span class="attr">type:</span>  <span class="string">&quot;tags&quot;</span></span><br><span class="line"><span class="attr">layout:</span>  <span class="string">&quot;tags&quot;</span></span><br></pre></td></tr></table></figure>

<p>编辑categories目录下的index文件，修改内容为：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">categories</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2022-11-19 11:04:55</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">&quot;categories&quot;</span></span><br><span class="line"><span class="attr">layout:</span> <span class="string">&quot;categories&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="三、-为文章打上分类和标签"><a href="#三、-为文章打上分类和标签" class="headerlink" title="三、 为文章打上分类和标签"></a>三、 为文章打上分类和标签</h2><p>为文章打上分类和标签的位置是Markdown文件中的头部标注文件，如果使用git工具通过hexo命令新建文件，那么头部标注文件会自动生成，修改其中内容即可添加分类和标签。如果是自己创建的Markdown文件，则需要手动添加一个头部标注文件用于添加分类和标签的信息。</p>
<h3 id="通过hexo命令创建文章"><a href="#通过hexo命令创建文章" class="headerlink" title="通过hexo命令创建文章"></a>通过hexo命令创建文章</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo n &quot;文件名&quot;</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new &quot;文件名&quot;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>编辑根目录&#x2F;scaffolds下的post.md文件，这个文件决定了通过hexo创建文章后的头部标注文件的格式，修改为以下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;title: &#123;&#123; title &#125;&#125;</span><br><span class="line">&gt;date: &#123;&#123; date &#125;&#125;</span><br><span class="line">&gt;tags: </span><br><span class="line">&gt;categories: </span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="手动创建Markdown文章"><a href="#手动创建Markdown文章" class="headerlink" title="手动创建Markdown文章"></a>手动创建Markdown文章</h3><p>在Typora中右键插入–&gt;YAML Front matter</p>
<p>然后再头部标注文件中加入以下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">title: 标题</span><br><span class="line">date: 日期，格式为yyyy-MM-dd HH:mm:ss</span><br><span class="line">tags: 标签，可以有多个</span><br><span class="line">categories: 分类，只能有一个</span><br></pre></td></tr></table></figure>

<h3 id="同一篇文章打多个标签的方式"><a href="#同一篇文章打多个标签的方式" class="headerlink" title="同一篇文章打多个标签的方式"></a>同一篇文章打多个标签的方式</h3><p>修改头部标注文件中的tags选项：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tags:</span><br><span class="line">	- 标签1</span><br><span class="line">	- 标签2</span><br></pre></td></tr></table></figure>

<p>注意：tags下另起一行，注意 - 前的tab缩进和后面的空格。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/" class="post-title-link" itemprop="url">MySQL语法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-01-30 09:56:30" itemprop="dateCreated datePublished" datetime="2023-01-30T09:56:30+08:00">2023-01-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-28 15:09:17" itemprop="dateModified" datetime="2023-09-28T15:09:17+08:00">2023-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index"><span itemprop="name">MySQL</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>17k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>31 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="MySQL语法"><a href="#MySQL语法" class="headerlink" title="MySQL语法"></a>MySQL语法</h1><h2 id="一、创建数据库"><a href="#一、创建数据库" class="headerlink" title="一、创建数据库"></a>一、创建数据库</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE `数据库名`</span><br></pre></td></tr></table></figure>



<h2 id="二、删除数据库"><a href="#二、删除数据库" class="headerlink" title="二、删除数据库"></a>二、删除数据库</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP DATABASE `数据库名`</span><br></pre></td></tr></table></figure>

<h2 id="三、选择数据库"><a href="#三、选择数据库" class="headerlink" title="三、选择数据库"></a>三、选择数据库</h2><p>在命令行中，使用以下命令选择数据库：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use 数据库名</span><br></pre></td></tr></table></figure>



<h2 id="四、数据类型"><a href="#四、数据类型" class="headerlink" title="四、数据类型"></a>四、数据类型</h2><ul>
<li><h3 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h3><p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111111721111.png" alt="image-20220111111721111"></p>
</li>
<li><h3 id="日期和时间类型"><a href="#日期和时间类型" class="headerlink" title="日期和时间类型"></a>日期和时间类型</h3></li>
</ul>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111111827606.png" alt="image-20220111111827606"></p>
<ul>
<li><h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3></li>
</ul>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111111925757.png" alt="image-20220111111925757"></p>
<h2 id="五、创建数据表"><a href="#五、创建数据表" class="headerlink" title="五、创建数据表"></a>五、创建数据表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE table_name(column_name column_type);</span><br></pre></td></tr></table></figure>

<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS `runoob_tbl`(</span><br><span class="line">   `runoob_id` INT UNSIGNED AUTO_INCREMENT,</span><br><span class="line">   `runoob_title` VARCHAR(100) NOT NULL,</span><br><span class="line">   `runoob_author` VARCHAR(40) NOT NULL,</span><br><span class="line">   `submission_date` DATE,</span><br><span class="line">   PRIMARY KEY ( `runoob_id` )</span><br><span class="line">)ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br></pre></td></tr></table></figure>

<p>例子解析：</p>
<ul>
<li><p>如果你不想字段为 <strong>NULL</strong> 可以设置字段的属性为 <strong>NOT NULL</strong>， 在操作数据库时如果输入该字段的数据为<strong>NULL</strong> ，就会报错。</p>
</li>
<li><p>AUTO_INCREMENT定义列为自增的属性，一般用于主键，数值会自动加1。</p>
</li>
<li><p>PRIMARY KEY关键字用于定义列为主键。 您可以使用多列来定义主键，列间以逗号分隔。</p>
</li>
<li><p>ENGINE 设置存储引擎，CHARSET 设置编码。</p>
</li>
</ul>
<h3 id="通过命令行创建表"><a href="#通过命令行创建表" class="headerlink" title="通过命令行创建表"></a>通过命令行创建表</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE table_name;</span><br></pre></td></tr></table></figure>



<h2 id="六、删除数据表"><a href="#六、删除数据表" class="headerlink" title="六、删除数据表"></a>六、删除数据表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE table_name;</span><br></pre></td></tr></table></figure>

<h3 id="在命令行中删除表"><a href="#在命令行中删除表" class="headerlink" title="在命令行中删除表"></a>在命令行中删除表</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE table_name;</span><br></pre></td></tr></table></figure>



<h2 id="七、插入数据"><a href="#七、插入数据" class="headerlink" title="七、插入数据"></a>七、插入数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO table_name ( field1, field2,...fieldN )</span><br><span class="line">                       VALUES</span><br><span class="line">                       ( value1, value2,...valueN );</span><br></pre></td></tr></table></figure>

<p>如果数据是字符型，必须使用单引号或者双引号，如：”value”。</p>
<p>当需要插入多条数据时，可以再values后多跟几个括号，用逗号隔开，如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO table_name ( field1, field2,...fieldN )</span><br><span class="line">                      VALUES</span><br><span class="line">                     ( value1, value2,...valueN ),( value1, value2,...valueN ),( value1, value2,...valueN );</span><br></pre></td></tr></table></figure>

<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>插入数据时，列名可以加反单引号，也可以不加；对于要插入的字符类型的值，要加单引号而不是反单引号。</p>
<p>在命令行中插入数据的语法同上。</p>
<h2 id="八、查询数据"><a href="#八、查询数据" class="headerlink" title="八、查询数据"></a>八、查询数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT column_name,column_name</span><br><span class="line">FROM table_name</span><br><span class="line">[WHERE Clause]</span><br><span class="line">[LIMIT N][ OFFSET M]</span><br></pre></td></tr></table></figure>

<ul>
<li>查询语句中你可以使用一个或者多个表，表之间使用逗号(,)分割，并使用WHERE语句来设定查询条件。</li>
<li>SELECT 命令可以读取一条或者多条记录。</li>
<li>你可以使用星号（*）来代替其他字段，SELECT语句会返回表的所有字段数据</li>
<li>你可以使用 WHERE 语句来包含任何条件。</li>
<li>你可以使用 LIMIT 属性来设定返回的记录数。</li>
<li>你可以通过OFFSET指定SELECT语句开始查询的数据偏移量。默认情况下偏移量为0。</li>
</ul>
<h4 id="注意-1"><a href="#注意-1" class="headerlink" title="注意"></a>注意</h4><p>查询中涉及到字符串时要使用单引号或双引号包括，表名可以使用反单引号，也可以直接写出。</p>
<p>命令行模式下查询数据的语法同上。</p>
<h2 id="九、WHERE-字句"><a href="#九、WHERE-字句" class="headerlink" title="九、WHERE 字句"></a>九、WHERE 字句</h2><p>where字句用于在查询数据时有条件地筛选数据。</p>
<p>语法格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT field1, field2,...fieldN FROM table_name1, table_name2...</span><br><span class="line">[WHERE condition1 [AND [OR]] condition2.....</span><br></pre></td></tr></table></figure>

<ul>
<li>查询语句中你可以使用一个或者多个表，表之间使用逗号, 分割，并使用WHERE语句来设定查询条件。</li>
<li>你可以在 WHERE 子句中指定任何条件。</li>
<li>你可以使用 AND 或者 OR 指定一个或多个条件。</li>
<li>WHERE 子句也可以运用于 SQL 的 DELETE 或者 UPDATE 命令。</li>
<li>WHERE 子句类似于程序语言中的 if 条件，根据 MySQL 表中的字段值来读取指定的数据。</li>
</ul>
<p>一下为操作符列表，可用于WHERE字句中。</p>
<p>下表中实例假定A为10，B为20</p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111133500917.png" alt="image-20220111133500917"></p>
<p>命令行模式下WHERE子句的用法同上。</p>
<h2 id="十、修改-x2F-更新数据"><a href="#十、修改-x2F-更新数据" class="headerlink" title="十、修改&#x2F;更新数据"></a>十、修改&#x2F;更新数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">UPDATE table_name SET field1=new-value1, field2=new-value2</span><br><span class="line">[WHERE Clause]</span><br></pre></td></tr></table></figure>

<ul>
<li>你可以同时更新一个或多个字段。</li>
<li>你可以在 WHERE 子句中指定任何条件。</li>
<li>你可以在一个单独表中同时更新数据。</li>
</ul>
<p>当你需要更新数据表中指定行的数据时 WHERE 子句是非常有用的。</p>
<h2 id="十一、删除表中的数据"><a href="#十一、删除表中的数据" class="headerlink" title="十一、删除表中的数据"></a>十一、删除表中的数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE FROM table_name [WHERE Clause]</span><br></pre></td></tr></table></figure>

<ul>
<li>如果没有指定 WHERE 子句，MySQL 表中的所有记录将被删除。</li>
<li>你可以在 WHERE 子句中指定任何条件</li>
<li>您可以在单个表中一次性删除记录。</li>
</ul>
<p>当你想删除数据表中指定的记录时 WHERE 子句是非常有用的。</p>
<p>在命令行中删除表中的记录的方法同上。</p>
<h2 id="十二、LIKE-子句"><a href="#十二、LIKE-子句" class="headerlink" title="十二、LIKE 子句"></a>十二、LIKE 子句</h2><p>LIKE 子句常与WHERE子句一起使用，用来表示含有某些字符的关键字看，可以用百分号%来表示任意字符，如果没有使用百分号%，LIKE子句与等号&#x3D;的效果是一样的。</p>
<p>语法格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT field1, field2,...fieldN </span><br><span class="line">FROM table_name</span><br><span class="line">WHERE field1 LIKE condition1 [AND [OR]] filed2 = &#x27;somevalue&#x27;</span><br></pre></td></tr></table></figure>

<p>在命令行模式下LIKE子句的语法格式同上。</p>
<h2 id="十三、UNION操作符-（连接两个select语句的结果）"><a href="#十三、UNION操作符-（连接两个select语句的结果）" class="headerlink" title="十三、UNION操作符  （连接两个select语句的结果）"></a>十三、UNION操作符  （连接两个select语句的结果）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT expression1, expression2, ... expression_n</span><br><span class="line">FROM tables</span><br><span class="line">[WHERE conditions]</span><br><span class="line">UNION [ALL | DISTINCT]</span><br><span class="line">SELECT expression1, expression2, ... expression_n</span><br><span class="line">FROM tables</span><br><span class="line">[WHERE conditions];</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>expression1, expression2, … expression_n</strong>: 要检索的列。</li>
<li><strong>tables:</strong> 要检索的数据表。</li>
<li><strong>WHERE conditions:</strong> 可选， 检索条件。</li>
<li><strong>DISTINCT:</strong> 可选，删除结果集中重复的数据。默认情况下 UNION 操作符已经删除了重复数据，所以 DISTINCT 修饰符对结果没啥影响。</li>
<li><strong>ALL:</strong> 可选，返回所有结果集，包含重复数据。</li>
</ul>
<h2 id="十四、排序"><a href="#十四、排序" class="headerlink" title="十四、排序"></a>十四、排序</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT field1, field2,...fieldN FROM table_name1, table_name2...</span><br><span class="line">ORDER BY field1 [ASC [DESC][默认 ASC]], [field2...] [ASC [DESC][默认 ASC]]</span><br></pre></td></tr></table></figure>

<ul>
<li>你可以使用任何字段来作为排序的条件，从而返回排序后的查询结果。</li>
<li>你可以设定多个字段来排序。</li>
<li>你可以使用 ASC 或 DESC 关键字来设置查询结果是按升序或降序排列。 默认情况下，它是按升序排列。</li>
<li>你可以添加 WHERE…LIKE 子句来设置条件。</li>
</ul>
<p>在命令行模式下排序的语法格式同上。</p>
<h2 id="十五、分组"><a href="#十五、分组" class="headerlink" title="十五、分组"></a>十五、分组</h2><p>SQL中分组使用<strong>GROUP BY</strong>语句，根据一个或多个列对结果集进行分组。在分组的列上我们可以使用COUNT,SUM,AVG等函数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT column_name, function(column_name)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE column_name operator value</span><br><span class="line">GROUP BY column_name;</span><br></pre></td></tr></table></figure>

<p><strong>WITH ROLLUP</strong> 可以实现在分组统计数据基础上再进行相同的统计（SUM,AVG,COUNT…）。</p>
<h4 id="理解和注意点："><a href="#理解和注意点：" class="headerlink" title="理解和注意点："></a>理解和注意点：</h4><p><strong>SELECT 的列必须是用于分组的列的一个或多个，不能包括其他列。</strong>理解如下：</p>
<p>要对某个表按某一列或者某几列进行分组，可以理解为除了这几列外，其余的列都放在了统一单元格里，例如：</p>
<p>原始表：</p>
<table>
<thead>
<tr>
<th>name</th>
<th>id</th>
<th>num</th>
</tr>
</thead>
<tbody><tr>
<td>a</td>
<td>1</td>
<td>12</td>
</tr>
<tr>
<td>b</td>
<td>2</td>
<td>12</td>
</tr>
<tr>
<td>c</td>
<td>3</td>
<td>13</td>
</tr>
</tbody></table>
<p>假设我们按照num列进行分组，即group by num，则得到：</p>
<table>
<thead>
<tr>
<th>name</th>
<th>id</th>
<th>num</th>
</tr>
</thead>
<tbody><tr>
<td>a   b</td>
<td>1  2</td>
<td>12</td>
</tr>
<tr>
<td>c</td>
<td>3</td>
<td>13</td>
</tr>
</tbody></table>
<p>可以看到，其余列因为分组已经写到了一起，所以select时只能选择分组的列，而不能包含其余列。</p>
<h2 id="十六、表链接"><a href="#十六、表链接" class="headerlink" title="十六、表链接"></a>十六、表链接</h2><p>可以在SELECT，UPDATE和DELETE语句中使用JOIN来联合多表查询。</p>
<p>JOIN 按照功能大致分为如下三类：</p>
<ul>
<li><strong>INNER JOIN（内连接,或等值连接）</strong>：获取两个表中字段匹配关系的记录。</li>
<li><strong>LEFT JOIN（左连接）：</strong>获取左表所有记录，即使右表没有对应匹配的记录。</li>
<li><strong>RIGHT JOIN（右连接）：</strong> 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。</li>
</ul>
<h2 id="十七、NULL值处理"><a href="#十七、NULL值处理" class="headerlink" title="十七、NULL值处理"></a>十七、NULL值处理</h2><p>处理NULL值的三大运算符：</p>
<ul>
<li><strong>IS NULL:</strong> 当列的值是 NULL,此运算符返回 true。</li>
<li><strong>IS NOT NULL:</strong> 当列的值不为 NULL, 运算符返回 true。</li>
<li><strong>&lt;&#x3D;&gt;:</strong> 比较操作符（不同于 &#x3D; 运算符），当比较的的两个值相等或者都为 NULL 时返回 true。</li>
</ul>
<h2 id="十八、MySQL正则表达式"><a href="#十八、MySQL正则表达式" class="headerlink" title="十八、MySQL正则表达式"></a>十八、MySQL正则表达式</h2><p>MySQL中使用<strong>REGEXP</strong>操作符来进行正则表达式匹配</p>
<p>正则表达式如下：</p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111140640057.png" alt="image-20220111140640057"></p>
<p>实例：<br>查找name字段中以‘st’开头的所有数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT name FROM person_tbl WHERE name REGEXP &#x27;^st&#x27;;</span><br></pre></td></tr></table></figure>



<h2 id="十九、MySQL事务"><a href="#十九、MySQL事务" class="headerlink" title="十九、MySQL事务"></a>十九、MySQL事务</h2><p>MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你既需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！</p>
<ul>
<li>在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。</li>
<li>事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。</li>
<li>事务用来管理 insert,update,delete 语句</li>
</ul>
<p>一般来说，事务是必须满足4个条件（ACID）：：原子性（<strong>A</strong>tomicity，或称不可分割性）、一致性（<strong>C</strong>onsistency）、隔离性（<strong>I</strong>solation，又称独立性）、持久性（<strong>D</strong>urability）。</p>
<ul>
<li><strong>原子性：</strong>一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。</li>
<li><strong>一致性：</strong>在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。</li>
<li><strong>隔离性：</strong>数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable  read）和串行化（Serializable）。</li>
<li><strong>持久性：</strong>事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li>
</ul>
<blockquote>
<p>在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT  操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET  AUTOCOMMIT&#x3D;0，用来禁止使用当前会话的自动提交。</p>
</blockquote>
<h3 id="事务控制语句："><a href="#事务控制语句：" class="headerlink" title="事务控制语句："></a>事务控制语句：</h3><ul>
<li>BEGIN 或 START TRANSACTION 显式地开启一个事务；</li>
<li>COMMIT 也可以使用 COMMIT WORK，不过二者是等价的。COMMIT 会提交事务，并使已对数据库进行的所有修改成为永久性的；</li>
<li>ROLLBACK 也可以使用 ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改；</li>
<li>SAVEPOINT identifier，SAVEPOINT 允许在事务中创建一个保存点，一个事务中可以有多个 SAVEPOINT；</li>
<li>RELEASE SAVEPOINT identifier 删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常；</li>
<li>ROLLBACK TO identifier 把事务回滚到标记点；</li>
<li>SET TRANSACTION 用来设置事务的隔离级别。InnoDB 存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 和 SERIALIZABLE。</li>
</ul>
<h3 id="MYSQL-事务处理主要有两种方法："><a href="#MYSQL-事务处理主要有两种方法：" class="headerlink" title="MYSQL 事务处理主要有两种方法："></a>MYSQL 事务处理主要有两种方法：</h3><p>1、用 BEGIN, ROLLBACK, COMMIT来实现</p>
<ul>
<li><strong>BEGIN</strong> 开始一个事务</li>
<li><strong>ROLLBACK</strong> 事务回滚</li>
<li><strong>COMMIT</strong>  事务确认</li>
</ul>
<p>2、直接用 SET 来改变 MySQL 的自动提交模式: </p>
<ul>
<li><strong>SET AUTOCOMMIT&#x3D;0</strong>   禁止自动提交</li>
<li><strong>SET AUTOCOMMIT&#x3D;1</strong> 开启自动提交</li>
</ul>
<h2 id="二十、ALTER命令"><a href="#二十、ALTER命令" class="headerlink" title="二十、ALTER命令"></a>二十、ALTER命令</h2><p>当我们需要修改数据表名或者修改数据表字段时，就需要使用到MySQL ALTER命令。</p>
<h3 id="删除、添加或修改表字段"><a href="#删除、添加或修改表字段" class="headerlink" title="删除、添加或修改表字段"></a>删除、添加或修改表字段</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER TABLE testalter_tbl  DROP i;</span><br></pre></td></tr></table></figure>

<p>如果数据表中只剩余一个字段则无法使用DROP来删除字段。</p>
<p>MySQL 中使用  ADD 子句来向数据表中添加列，如下实例在表 testalter_tbl 中添加 i 字段，并定义数据类型:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER TABLE testalter_tbl ADD i INT;</span><br></pre></td></tr></table></figure>

<p>执行以上命令后，i 字段会自动添加到数据表字段的末尾。</p>
<p>如果你需要指定新增字段的位置，可以使用MySQL提供的关键字 FIRST (设定位第一列)， AFTER 字段名（设定位于某个字段之后）。FIRST 和 AFTER 关键字可用于 ADD 与 MODIFY  子句，所以如果你想重置数据表字段的位置就需要先使用 DROP 删除字段然后使用 ADD 来添加字段并设置位置。如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE testalter_tbl DROP i;</span><br><span class="line">ALTER TABLE testalter_tbl ADD i INT FIRST;</span><br><span class="line">ALTER TABLE testalter_tbl DROP i;</span><br><span class="line">ALTER TABLE testalter_tbl ADD i INT AFTER c;</span><br></pre></td></tr></table></figure>

<h3 id="修改字段类型和名称"><a href="#修改字段类型和名称" class="headerlink" title="修改字段类型和名称"></a>修改字段类型和名称</h3><p>如果需要修改字段类型及名称, 你可以在ALTER命令中使用 MODIFY 或 CHANGE 子句 。</p>
<p>例如，把字段 c 的类型从 CHAR(1) 改为 CHAR(10)，可以执行以下命令:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE testalter_tbl MODIFY c CHAR(10);</span><br></pre></td></tr></table></figure>

<p>使用 CHANGE 子句, 语法有很大的不同。 在 CHANGE 关键字之后，紧跟着的是你要修改的字段名，然后指定新字段名及类型。尝试如下实例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE testalter_tbl CHANGE i j BIGINT;</span><br><span class="line">ALTER TABLE testalter_tbl CHANGE j j INT;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="ALTER-TABLE-对-Null-值和默认值的影响"><a href="#ALTER-TABLE-对-Null-值和默认值的影响" class="headerlink" title="ALTER TABLE 对 Null 值和默认值的影响"></a>ALTER TABLE 对 Null 值和默认值的影响</h3><p>当你修改字段时，你可以指定是否包含值或者是否设置默认值。</p>
<p>以下实例，指定字段 j 为 NOT NULL 且默认值为100 。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER TABLE testalter_tbl </span><br><span class="line">    -&gt; MODIFY j BIGINT NOT NULL DEFAULT 100;</span><br></pre></td></tr></table></figure>

<p>如果你不设置默认值，MySQL会自动设置该字段默认为 NULL。</p>
<h3 id="修改字段默认值"><a href="#修改字段默认值" class="headerlink" title="修改字段默认值"></a>修改字段默认值</h3><p>你可以使用 ALTER 来修改字段的默认值，尝试以下实例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE testalter_tbl ALTER i SET DEFAULT 1000;</span><br></pre></td></tr></table></figure>

<h3 id="修改表名"><a href="#修改表名" class="headerlink" title="修改表名"></a>修改表名</h3><p>如果需要修改数据表的名称，可以在  ALTER TABLE 语句中使用 RENAME 子句来实现。</p>
<p>尝试以下实例将数据表 testalter_tbl 重命名为 alter_tbl：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE testalter_tbl RENAME TO alter_tbl;</span><br></pre></td></tr></table></figure>

<h3 id="修改存储引擎"><a href="#修改存储引擎" class="headerlink" title="修改存储引擎"></a>修改存储引擎</h3><p>修改为myisam</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table tableName engine=myisam;</span><br></pre></td></tr></table></figure>

<h3 id="删除外键约束"><a href="#删除外键约束" class="headerlink" title="删除外键约束"></a>删除外键约束</h3><p>keyName是外键别名</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table tableName drop foreign key keyName</span><br></pre></td></tr></table></figure>



<h2 id="二十一、索引"><a href="#二十一、索引" class="headerlink" title="二十一、索引"></a>二十一、索引</h2><h3 id="普通索引"><a href="#普通索引" class="headerlink" title="普通索引"></a>普通索引</h3><h4 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h4><p>这是最基本的索引，没有任何限制</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX indexName ON table_name (column_name)</span><br></pre></td></tr></table></figure>

<p>如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。</p>
<h4 id="修改表结构-添加索引"><a href="#修改表结构-添加索引" class="headerlink" title="修改表结构(添加索引)"></a>修改表结构(添加索引)</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER table tableName ADD INDEX indexName(columnName)</span><br></pre></td></tr></table></figure>

<h4 id="创建表的时候直接指定"><a href="#创建表的时候直接指定" class="headerlink" title="创建表的时候直接指定"></a>创建表的时候直接指定</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE mytable(  </span><br><span class="line"> </span><br><span class="line">ID INT NOT NULL,   </span><br><span class="line"> </span><br><span class="line">username VARCHAR(16) NOT NULL,  </span><br><span class="line"> </span><br><span class="line">INDEX [indexName] (username(length))  </span><br><span class="line"> </span><br><span class="line">);  </span><br></pre></td></tr></table></figure>

<h4 id="删除索引的语法"><a href="#删除索引的语法" class="headerlink" title="删除索引的语法"></a>删除索引的语法</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP INDEX [indexName] ON mytable; </span><br></pre></td></tr></table></figure>

<hr>
<h3 id="唯一索引"><a href="#唯一索引" class="headerlink" title="唯一索引"></a>唯一索引</h3><p>它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式：</p>
<h4 id="创建索引-1"><a href="#创建索引-1" class="headerlink" title="创建索引"></a>创建索引</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE UNIQUE INDEX indexName ON mytable(username(length)) </span><br></pre></td></tr></table></figure>

<h4 id="修改表结构"><a href="#修改表结构" class="headerlink" title="修改表结构"></a>修改表结构</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER table mytable ADD UNIQUE [indexName] (username(length))</span><br></pre></td></tr></table></figure>

<h4 id="创建表的时候直接指定-1"><a href="#创建表的时候直接指定-1" class="headerlink" title="创建表的时候直接指定"></a>创建表的时候直接指定</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE mytable(  </span><br><span class="line"> </span><br><span class="line">ID INT NOT NULL,   </span><br><span class="line"> </span><br><span class="line">username VARCHAR(16) NOT NULL,  </span><br><span class="line"> </span><br><span class="line">UNIQUE [indexName] (username(length))  </span><br><span class="line"> </span><br><span class="line">);  </span><br></pre></td></tr></table></figure>

<hr>
<h3 id="使用ALTER-命令添加和删除索引"><a href="#使用ALTER-命令添加和删除索引" class="headerlink" title="使用ALTER 命令添加和删除索引"></a>使用ALTER 命令添加和删除索引</h3><p>有四种方式来添加数据表的索引：</p>
<ul>
<li>**ALTER TABLE tbl_name ADD PRIMARY KEY (column_list):**该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。</li>
<li><strong>ALTER TABLE tbl_name ADD UNIQUE index_name (column_list):</strong> 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。</li>
<li><strong>ALTER TABLE tbl_name ADD INDEX index_name (column_list):</strong> 添加普通索引，索引值可出现多次。</li>
<li>**ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list):**该语句指定了索引为  FULLTEXT ，用于全文索引。</li>
</ul>
<p>以下实例为在表中添加索引。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER TABLE testalter_tbl ADD INDEX (c);</span><br></pre></td></tr></table></figure>

<p>你还可以在 ALTER 命令中使用 DROP 子句来删除索引。尝试以下实例删除索引:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER TABLE testalter_tbl DROP INDEX c;</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="使用-ALTER-命令添加和删除主键"><a href="#使用-ALTER-命令添加和删除主键" class="headerlink" title="使用 ALTER  命令添加和删除主键"></a>使用 ALTER  命令添加和删除主键</h3><p>主键作用于列上（可以一个列或多个列联合主键），添加主键索引时，你需要确保该主键默认不为空（NOT NULL）。实例如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER TABLE testalter_tbl MODIFY i INT NOT NULL;</span><br><span class="line">mysql&gt; ALTER TABLE testalter_tbl ADD PRIMARY KEY (i);</span><br></pre></td></tr></table></figure>

<p>你也可以使用 ALTER 命令删除主键：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER TABLE testalter_tbl DROP PRIMARY KEY;</span><br></pre></td></tr></table></figure>

<p>删除主键时只需指定PRIMARY KEY，但在删除索引时，你必须知道索引名。</p>
<hr>
<h3 id="显示索引信息"><a href="#显示索引信息" class="headerlink" title="显示索引信息"></a>显示索引信息</h3><p>你可以使用 SHOW INDEX 命令来列出表中的相关的索引信息。可以通过添加 \G 来格式化输出信息。</p>
<p>尝试以下实例:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW INDEX FROM table_name\G</span><br><span class="line">........</span><br></pre></td></tr></table></figure>



<h2 id="二十二、临时表"><a href="#二十二、临时表" class="headerlink" title="二十二、临时表"></a>二十二、临时表</h2><p>MySQL 临时表在我们需要保存一些临时数据时是非常有用的。临时表只在当前连接可见，当关闭连接时，Mysql会自动删除表并释放所有空间。</p>
<p>临时表在MySQL 3.23版本中添加，如果你的MySQL版本低于 3.23版本就无法使用MySQL的临时表。不过现在一般很少有再使用这么低版本的MySQL数据库服务了。</p>
<p>MySQL临时表只在当前连接可见，如果你使用PHP脚本来创建MySQL临时表，那每当PHP脚本执行完成后，该临时表也会自动销毁。</p>
<p>如果你使用了其他MySQL客户端程序连接MySQL数据库服务器来创建临时表，那么只有在关闭客户端程序时才会销毁临时表，当然你也可以手动销毁。</p>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>以下展示了使用MySQL 临时表的简单实例，以下的SQL代码可以适用于PHP脚本的mysql_query()函数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TEMPORARY TABLE SalesSummary (</span><br><span class="line">    -&gt; product_name VARCHAR(50) NOT NULL</span><br><span class="line">    -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00</span><br><span class="line">    -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00</span><br><span class="line">    -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0</span><br><span class="line">);</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; INSERT INTO SalesSummary</span><br><span class="line">    -&gt; (product_name, total_sales, avg_unit_price, total_units_sold)</span><br><span class="line">    -&gt; VALUES</span><br><span class="line">    -&gt; (&#x27;cucumber&#x27;, 100.25, 90, 2);</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM SalesSummary;</span><br><span class="line">+--------------+-------------+----------------+------------------+</span><br><span class="line">| product_name | total_sales | avg_unit_price | total_units_sold |</span><br><span class="line">+--------------+-------------+----------------+------------------+</span><br><span class="line">| cucumber     |      100.25 |          90.00 |                2 |</span><br><span class="line">+--------------+-------------+----------------+------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>当你使用 <strong>SHOW TABLES</strong>命令显示数据表列表时，你将无法看到 SalesSummary表。</p>
<p>如果你退出当前MySQL会话，再使用 <strong>SELECT</strong>命令来读取原先创建的临时表数据，那你会发现数据库中没有该表的存在，因为在你退出时该临时表已经被销毁了。</p>
<hr>
<h3 id="删除MySQL-临时表"><a href="#删除MySQL-临时表" class="headerlink" title="删除MySQL 临时表"></a>删除MySQL 临时表</h3><p>默认情况下，当你断开与数据库的连接后，临时表就会自动被销毁。当然你也可以在当前MySQL会话使用 <strong>DROP TABLE</strong>  命令来手动删除临时表。</p>
<p>以下是手动删除临时表的实例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TEMPORARY TABLE SalesSummary (</span><br><span class="line">    -&gt; product_name VARCHAR(50) NOT NULL</span><br><span class="line">    -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00</span><br><span class="line">    -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00</span><br><span class="line">    -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0</span><br><span class="line">);</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; INSERT INTO SalesSummary</span><br><span class="line">    -&gt; (product_name, total_sales, avg_unit_price, total_units_sold)</span><br><span class="line">    -&gt; VALUES</span><br><span class="line">    -&gt; (&#x27;cucumber&#x27;, 100.25, 90, 2);</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM SalesSummary;</span><br><span class="line">+--------------+-------------+----------------+------------------+</span><br><span class="line">| product_name | total_sales | avg_unit_price | total_units_sold |</span><br><span class="line">+--------------+-------------+----------------+------------------+</span><br><span class="line">| cucumber     |      100.25 |          90.00 |                2 |</span><br><span class="line">+--------------+-------------+----------------+------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line">mysql&gt; DROP TABLE SalesSummary;</span><br><span class="line">mysql&gt;  SELECT * FROM SalesSummary;</span><br><span class="line">ERROR 1146: Table &#x27;RUNOOB.SalesSummary&#x27; doesn&#x27;t exist</span><br></pre></td></tr></table></figure>



<h2 id="二十三、复制表"><a href="#二十三、复制表" class="headerlink" title="二十三、复制表"></a>二十三、复制表</h2><p><strong>第一、只复制表结构到新表</strong></p>
<p>create table 新表 select * from 旧表 where 1&#x3D;2</p>
<p>或者</p>
<p>create table 新表 like 旧表 </p>
<p><strong>第二、复制表结构及数据到新表</strong></p>
<p>create table新表 select * from 旧表 </p>
<h2 id="二十四、元数据"><a href="#二十四、元数据" class="headerlink" title="二十四、元数据"></a>二十四、元数据</h2><p>在命令行模式中，可以很容易地获取以下的服务器信息：</p>
<ul>
<li><strong>查询结果信息：</strong> SELECT, UPDATE 或 DELETE语句影响的记录数。</li>
<li><strong>数据库和数据表的信息：</strong> 包含了数据库及数据表的结构信息。</li>
<li><strong>MySQL服务器信息：</strong> 包含了数据库服务器的当前状态，版本号等。</li>
</ul>
<h4 id="数据库和数据表列表"><a href="#数据库和数据表列表" class="headerlink" title="数据库和数据表列表"></a>数据库和数据表列表</h4><p>可以使用SHOW TABLES或SHOW DATABASES语句来获取数据库和数据表列表。</p>
<h4 id="获取服务器元数据"><a href="#获取服务器元数据" class="headerlink" title="获取服务器元数据"></a>获取服务器元数据</h4><p>命令如下表：</p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111144610993.png" alt="image-20220111144610993"></p>
<h2 id="二十五、序列"><a href="#二十五、序列" class="headerlink" title="二十五、序列"></a>二十五、序列</h2><p>MySQL 序列是一组整数：1, 2, 3, …，由于一张数据表只能有一个字段自增主键， 如果你想实现其他字段也实现自动增加，就可以使用MySQL序列来实现</p>
<h3 id="使用-AUTO-INCREMENT"><a href="#使用-AUTO-INCREMENT" class="headerlink" title="使用 AUTO_INCREMENT"></a>使用 AUTO_INCREMENT</h3><p>MySQL 中最简单使用序列的方法就是使用 MySQL AUTO_INCREMENT 来定义序列。</p>
<h4 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h4><p>以下实例中创建了数据表 insect， insect 表中 id 无需指定值可实现自动增长。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE insect</span><br><span class="line">    -&gt; (</span><br><span class="line">    -&gt; id INT UNSIGNED NOT NULL AUTO_INCREMENT,</span><br><span class="line">    -&gt; PRIMARY KEY (id),</span><br><span class="line">    -&gt; name VARCHAR(30) NOT NULL, # type of insect</span><br><span class="line">    -&gt; date DATE NOT NULL, # date collected</span><br><span class="line">    -&gt; origin VARCHAR(30) NOT NULL # where collected</span><br><span class="line">);</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line">mysql&gt; INSERT INTO insect (id,name,date,origin) VALUES</span><br><span class="line">    -&gt; (NULL,&#x27;housefly&#x27;,&#x27;2001-09-10&#x27;,&#x27;kitchen&#x27;),</span><br><span class="line">    -&gt; (NULL,&#x27;millipede&#x27;,&#x27;2001-09-10&#x27;,&#x27;driveway&#x27;),</span><br><span class="line">    -&gt; (NULL,&#x27;grasshopper&#x27;,&#x27;2001-09-10&#x27;,&#x27;front yard&#x27;);</span><br><span class="line">Query OK, 3 rows affected (0.02 sec)</span><br><span class="line">Records: 3  Duplicates: 0  Warnings: 0</span><br><span class="line">mysql&gt; SELECT * FROM insect ORDER BY id;</span><br><span class="line">+----+-------------+------------+------------+</span><br><span class="line">| id | name        | date       | origin     |</span><br><span class="line">+----+-------------+------------+------------+</span><br><span class="line">|  1 | housefly    | 2001-09-10 | kitchen    |</span><br><span class="line">|  2 | millipede   | 2001-09-10 | driveway   |</span><br><span class="line">|  3 | grasshopper | 2001-09-10 | front yard |</span><br><span class="line">+----+-------------+------------+------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<h3 id="获取AUTO-INCREMENT值"><a href="#获取AUTO-INCREMENT值" class="headerlink" title="获取AUTO_INCREMENT值"></a>获取AUTO_INCREMENT值</h3><p>在MySQL的客户端中你可以使用 SQL中的LAST_INSERT_ID( ) 函数来获取最后的插入表中的自增列的值。</p>
<h3 id="重置序列"><a href="#重置序列" class="headerlink" title="重置序列"></a>重置序列</h3><p>如果你删除了数据表中的多条记录，并希望对剩下数据的AUTO_INCREMENT列进行重新排列，那么你可以通过删除自增的列，然后重新添加来实现。 不过该操作要非常小心，如果在删除的同时又有新记录添加，有可能会出现数据混乱。操作如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER TABLE insect DROP id;</span><br><span class="line">mysql&gt; ALTER TABLE insect</span><br><span class="line">    -&gt; ADD id INT UNSIGNED NOT NULL AUTO_INCREMENT FIRST,</span><br><span class="line">    -&gt; ADD PRIMARY KEY (id);</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="设置序列的开始值"><a href="#设置序列的开始值" class="headerlink" title="设置序列的开始值"></a>设置序列的开始值</h3><p>一般情况下序列的开始值为1，但如果你需要指定一个开始值100，那我们可以通过以下语句来实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE insect</span><br><span class="line">    -&gt; (</span><br><span class="line">    -&gt; id INT UNSIGNED NOT NULL AUTO_INCREMENT,</span><br><span class="line">    -&gt; PRIMARY KEY (id),</span><br><span class="line">    -&gt; name VARCHAR(30) NOT NULL, </span><br><span class="line">    -&gt; date DATE NOT NULL,</span><br><span class="line">    -&gt; origin VARCHAR(30) NOT NULL</span><br><span class="line">)engine=innodb auto_increment=100 charset=utf8;</span><br></pre></td></tr></table></figure>

<p>或者你也可以在表创建成功后，通过以下语句来实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER TABLE t AUTO_INCREMENT = 100;</span><br></pre></td></tr></table></figure>

<p>​			</p>
<h2 id="二十六、处理重复数据"><a href="#二十六、处理重复数据" class="headerlink" title="二十六、处理重复数据"></a>二十六、处理重复数据</h2><h3 id="防止表中出现重复数据"><a href="#防止表中出现重复数据" class="headerlink" title="防止表中出现重复数据"></a>防止表中出现重复数据</h3><p>你可以在 MySQL 数据表中设置指定的字段为 <strong>PRIMARY KEY（主键）</strong>  或者 <strong>UNIQUE（唯一）</strong> 索引来保证数据的唯一性。</p>
<p>如果你想设置表中字段数据不能重复，你可以设置双主键模式来设置数据的唯一性， 如果你设置了双主键，那么那个键的默认值不能为 NULL，可设置为 NOT NULL。</p>
<p>INSERT IGNORE INTO 与 INSERT INTO 的区别就是 INSERT IGNORE INTO  会忽略数据库中已经存在的数据，如果数据库没有数据，就插入新的数据，如果有数据的话就跳过这条数据。这样就可以保留数据库中已经存在数据，达到在间隙中插入数据的目的。</p>
<p>另一种设置数据的唯一性方法是添加一个 UNIQUE 索引，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE person_tbl</span><br><span class="line">(</span><br><span class="line">   first_name CHAR(20) NOT NULL,</span><br><span class="line">   last_name CHAR(20) NOT NULL,</span><br><span class="line">   sex CHAR(10),</span><br><span class="line">   UNIQUE (last_name, first_name)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<h3 id="统计重复数据"><a href="#统计重复数据" class="headerlink" title="统计重复数据"></a>统计重复数据</h3><p>一般情况下，查询重复的值，请执行以下操作：</p>
<ul>
<li>确定哪一列包含的值可能会重复。</li>
<li>在列选择列表使用COUNT(*)列出的那些列。</li>
<li>在GROUP BY子句中列出的列。</li>
<li>HAVING子句设置重复数大于1。</li>
</ul>
<h3 id="过滤重复数据"><a href="#过滤重复数据" class="headerlink" title="过滤重复数据"></a>过滤重复数据</h3><p>如果你需要读取不重复的数据可以在 SELECT 语句中使用 DISTINCT 关键字来过滤重复数据。</p>
<p>你也可以使用 GROUP BY 来读取数据表中不重复的数据。</p>
<h3 id="删除重复数据"><a href="#删除重复数据" class="headerlink" title="删除重复数据"></a>删除重复数据</h3><p>如果你想删除数据表中的重复数据，你可以使用以下的SQL语句：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE tmp SELECT last_name, first_name, sex FROM person_tbl  GROUP BY (last_name, first_name, sex);</span><br><span class="line">mysql&gt; DROP TABLE person_tbl;</span><br><span class="line">mysql&gt; ALTER TABLE tmp RENAME TO person_tbl;</span><br></pre></td></tr></table></figure>

<p>当然你也可以在数据表中添加 INDEX（索引） 和 PRIMAY KEY（主键）这种简单的方法来删除表中的重复记录。方法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER IGNORE TABLE person_tbl</span><br><span class="line">    -&gt; ADD PRIMARY KEY (last_name, first_name);</span><br></pre></td></tr></table></figure>



<h2 id="二十七、导出数据"><a href="#二十七、导出数据" class="headerlink" title="二十七、导出数据"></a>二十七、导出数据</h2><ul>
<li>使用 <strong>SELECT … INTO OUTFILE</strong> 语句导出数据</li>
</ul>
<p>以下实例中我们将数据表 runoob_tbl 数据导出到 &#x2F;tmp&#x2F;runoob.txt 文件中: </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM runoob_tbl </span><br><span class="line">    -&gt; INTO OUTFILE &#x27;/tmp/runoob.txt&#x27;;</span><br></pre></td></tr></table></figure>

<p>你可以通过命令选项来设置数据输出的指定格式，以下实例为导出 CSV 格式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM passwd INTO OUTFILE &#x27;/tmp/runoob.txt&#x27;</span><br><span class="line">    -&gt; FIELDS TERMINATED BY &#x27;,&#x27; ENCLOSED BY &#x27;&quot;&#x27;</span><br><span class="line">    -&gt; LINES TERMINATED BY &#x27;\r\n&#x27;;</span><br></pre></td></tr></table></figure>

<p>在下面的例子中，生成一个文件，各值用逗号隔开。这种格式可以被许多程序使用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT a,b,a+b INTO OUTFILE &#x27;/tmp/result.text&#x27;</span><br><span class="line">FIELDS TERMINATED BY &#x27;,&#x27; OPTIONALLY ENCLOSED BY &#x27;&quot;&#x27;</span><br><span class="line">LINES TERMINATED BY &#x27;\n&#x27;</span><br><span class="line">FROM test_table;</span><br></pre></td></tr></table></figure>

<h3 id="SELECT-…-INTO-OUTFILE-语句的属性"><a href="#SELECT-…-INTO-OUTFILE-语句的属性" class="headerlink" title="SELECT … INTO OUTFILE 语句的属性:"></a>SELECT … INTO OUTFILE 语句的属性:</h3><ul>
<li>LOAD DATA INFILE是SELECT … INTO OUTFILE的逆操作，SELECT句法。为了将一个数据库的数据写入一个文件，使用SELECT … INTO OUTFILE，为了将文件读回数据库，使用LOAD DATA INFILE。</li>
<li>SELECT…INTO OUTFILE ‘file_name’形式的SELECT可以把被选择的行写入一个文件中。该文件被创建到服务器主机上，因此您必须拥有FILE权限，才能使用此语法。  </li>
<li>输出不能是一个已存在的文件。防止文件数据被篡改。</li>
<li>你需要有一个登陆服务器的账号来检索文件。否则 SELECT … INTO OUTFILE 不会起任何作用。</li>
<li>在UNIX中，该文件被创建后是可读的，权限由MySQL服务器所拥有。这意味着，虽然你就可以读取该文件，但可能无法将其删除。</li>
</ul>
<h3 id="导出表作为原始数据"><a href="#导出表作为原始数据" class="headerlink" title="导出表作为原始数据"></a>导出表作为原始数据</h3><p>mysqldump 是 mysql 用于转存储数据库的实用程序。它主要产生一个 SQL 脚本，其中包含从头重新创建数据库所必需的命令 CREATE TABLE INSERT 等。</p>
<p>使用 mysqldump 导出数据需要使用  –tab 选项来指定导出文件指定的目录，该目标必须是可写的。</p>
<p>以下实例将数据表 runoob_tbl 导出到 &#x2F;tmp 目录中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldump -u root -p --no-create-info \</span><br><span class="line">            --tab=/tmp RUNOOB runoob_tbl</span><br><span class="line">password ******</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="导出-SQL-格式的数据"><a href="#导出-SQL-格式的数据" class="headerlink" title="导出 SQL 格式的数据"></a>导出 SQL 格式的数据</h3><p>导出 SQL 格式的数据到指定文件，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldump -u root -p RUNOOB runoob_tbl &gt; dump.txt</span><br><span class="line">password ******</span><br></pre></td></tr></table></figure>

<p>如果你需要导出整个数据库的数据，可以使用以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldump -u root -p RUNOOB &gt; database_dump.txt</span><br><span class="line">password ******</span><br></pre></td></tr></table></figure>

<p>如果需要备份所有数据库，可以使用以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldump -u root -p --all-databases &gt; database_dump.txt</span><br><span class="line">password ******</span><br></pre></td></tr></table></figure>

<h3 id="将数据表及数据库拷贝至其他主机"><a href="#将数据表及数据库拷贝至其他主机" class="headerlink" title="将数据表及数据库拷贝至其他主机"></a>将数据表及数据库拷贝至其他主机</h3><p>如果你需要将数据拷贝至其他的 MySQL 服务器上, 你可以在 mysqldump 命令中指定数据库名及数据表。</p>
<p>在源主机上执行以下命令，将数据备份至 dump.txt 文件中:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldump -u root -p database_name table_name &gt; dump.txt</span><br><span class="line">password *****</span><br></pre></td></tr></table></figure>

<p>如果完整备份数据库，则无需使用特定的表名称。</p>
<p>如果你需要将备份的数据库导入到MySQL服务器中，可以使用以下命令，使用以下命令你需要确认数据库已经创建：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -u root -p database_name &lt; dump.txt</span><br><span class="line">password *****</span><br></pre></td></tr></table></figure>

<p>你也可以使用以下命令将导出的数据直接导入到远程的服务器上，但请确保两台服务器是相通的，是可以相互访问的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldump -u root -p database_name \</span><br><span class="line">       | mysql -h other-host.com database_name</span><br></pre></td></tr></table></figure>

<p>以上命令中使用了管道来将导出的数据导入到指定的远程主机上。</p>
<h2 id="二十八、导入数据"><a href="#二十八、导入数据" class="headerlink" title="二十八、导入数据"></a>二十八、导入数据</h2><h2 id="1、mysql-命令导入"><a href="#1、mysql-命令导入" class="headerlink" title="1、mysql  命令导入"></a>1、mysql  命令导入</h2><p>使用 mysql 命令导入语法格式为： </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u用户名    -p密码    &lt;  要导入的数据库数据(runoob.sql)</span><br></pre></td></tr></table></figure>

<p><strong>实例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># mysql -uroot -p123456 &lt; runoob.sql</span><br></pre></td></tr></table></figure>

<p>以上命令将将备份的整个数据库  runoob.sql 导入。</p>
<hr>
<h2 id="2、source-命令导入"><a href="#2、source-命令导入" class="headerlink" title="2、source  命令导入"></a>2、source  命令导入</h2><p>source 命令导入数据库需要先登录到数库终端：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database abc;      # 创建数据库</span><br><span class="line">mysql&gt; use abc;                  # 使用已创建的数据库 </span><br><span class="line">mysql&gt; set names utf8;           # 设置编码</span><br><span class="line">mysql&gt; source /home/abc/abc.sql  # 导入备份数据库</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="3、使用-LOAD-DATA-导入数据"><a href="#3、使用-LOAD-DATA-导入数据" class="headerlink" title="3、使用  LOAD DATA 导入数据"></a>3、使用  LOAD DATA 导入数据</h2><p>MySQL 中提供了LOAD DATA INFILE语句来插入数据。 以下实例中将从当前目录中读取文件 dump.txt ，将该文件中的数据插入到当前数据库的 mytbl 表中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; LOAD DATA LOCAL INFILE &#x27;dump.txt&#x27; INTO TABLE mytbl;</span><br></pre></td></tr></table></figure>

<p>　如果指定LOCAL关键词，则表明从客户主机上按路径读取文件。如果没有指定，则文件在服务器上按路径读取文件。</p>
<p>你能明确地在LOAD DATA语句中指出列值的分隔符和行尾标记，但是默认标记是定位符和换行符。</p>
<p>两个命令的 FIELDS 和 LINES 子句的语法是一样的。两个子句都是可选的，但是如果两个同时被指定，FIELDS 子句必须出现在 LINES 子句之前。</p>
<p>如果用户指定一个 FIELDS 子句，它的子句 （TERMINATED BY、[OPTIONALLY] ENCLOSED BY 和 ESCAPED BY) 也是可选的，不过，用户必须至少指定它们中的一个。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; LOAD DATA LOCAL INFILE &#x27;dump.txt&#x27; INTO TABLE mytbl</span><br><span class="line">  -&gt; FIELDS TERMINATED BY &#x27;:&#x27;</span><br><span class="line">  -&gt; LINES TERMINATED BY &#x27;\r\n&#x27;;</span><br></pre></td></tr></table></figure>

<p>LOAD DATA 默认情况下是按照数据文件中列的顺序插入数据的，如果数据文件中的列与插入表中的列不一致，则需要指定列的顺序。</p>
<p>如，在数据文件中的列顺序是 a,b,c，但在插入表的列顺序为b,c,a，则数据导入语法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; LOAD DATA LOCAL INFILE &#x27;dump.txt&#x27; </span><br><span class="line">    -&gt; INTO TABLE mytbl (b, c, a);</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="4、使用-mysqlimport-导入数据"><a href="#4、使用-mysqlimport-导入数据" class="headerlink" title="4、使用 mysqlimport 导入数据"></a>4、使用 mysqlimport 导入数据</h2><p>mysqlimport 客户端提供了 LOAD DATA INFILEQL 语句的一个命令行接口。mysqlimport 的大多数选项直接对应 LOAD DATA INFILE 子句。</p>
<p>从文件 dump.txt 中将数据导入到 mytbl 数据表中, 可以使用以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mysqlimport -u root -p --local mytbl dump.txt</span><br><span class="line">password *****</span><br></pre></td></tr></table></figure>

<p> mysqlimport 命令可以指定选项来设置指定格式,命令语句格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mysqlimport -u root -p --local --fields-terminated-by=&quot;:&quot; \</span><br><span class="line">   --lines-terminated-by=&quot;\r\n&quot;  mytbl dump.txt</span><br><span class="line">password *****</span><br></pre></td></tr></table></figure>

<p> mysqlimport 语句中使用 –columns 选项来设置列的顺序：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mysqlimport -u root -p --local --columns=b,c,a \</span><br><span class="line">    mytbl dump.txt</span><br><span class="line">password *****</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="mysqlimport的常用选项介绍"><a href="#mysqlimport的常用选项介绍" class="headerlink" title="mysqlimport的常用选项介绍"></a>mysqlimport的常用选项介绍</h2><p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111151649888.png" alt="image-20220111151649888"></p>
<p>mysqlimport 命令常用的选项还有 -v 显示版本（version）， -p 提示输入密码（password）等。</p>
<h2 id="二十九、函数"><a href="#二十九、函数" class="headerlink" title="二十九、函数"></a>二十九、函数</h2><h3 id="字符串函数"><a href="#字符串函数" class="headerlink" title="字符串函数"></a>字符串函数</h3><p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111151839188.png" alt="image-20220111151839188"><br><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111151943783.png" alt="image-20220111151943783"><br><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152039568.png" alt="image-20220111152039568"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152116038.png" alt="image-20220111152116038"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152158149.png" alt="image-20220111152158149"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152405200.png" alt="image-20220111152405200"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152515546.png" alt="image-20220111152515546"></p>
<h3 id="数字函数"><a href="#数字函数" class="headerlink" title="数字函数"></a>数字函数</h3><p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152652291.png" alt="image-20220111152652291"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152719340.png" alt="image-20220111152719340"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152805594.png" alt="image-20220111152805594"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152848876.png" alt="image-20220111152848876"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152911882.png" alt="image-20220111152911882"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111152951861.png" alt="image-20220111152951861"></p>
<h3 id="日期函数"><a href="#日期函数" class="headerlink" title="日期函数"></a>日期函数</h3><p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153103656.png" alt="image-20220111153103656"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153132694.png" alt="image-20220111153132694"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153213321.png" alt="image-20220111153213321"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153243604.png" alt="image-20220111153243604"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153314853.png" alt="image-20220111153314853"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153418806.png" alt="image-20220111153418806"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153453973.png" alt="image-20220111153453973"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153538504.png" alt="image-20220111153538504"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153612980.png" alt="image-20220111153612980"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153652982.png" alt="image-20220111153652982"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153735999.png" alt="image-20220111153735999"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153808883.png" alt="image-20220111153808883"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153830820.png" alt="image-20220111153830820"></p>
<h3 id="高级函数"><a href="#高级函数" class="headerlink" title="高级函数"></a>高级函数</h3><p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153906531.png" alt="image-20220111153906531"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111153943903.png" alt="image-20220111153943903"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111154017960.png" alt="image-20220111154017960"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111154053153.png" alt="image-20220111154053153"></p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111154115363.png" alt="image-20220111154115363"></p>
<h2 id="三十、运算符"><a href="#三十、运算符" class="headerlink" title="三十、运算符"></a>三十、运算符</h2><p>MySQL有以下几种运算符：</p>
<ul>
<li>算术运算符</li>
<li>比较运算符</li>
<li>逻辑运算符</li>
<li>位运算符</li>
</ul>
<h3 id="算数运算符"><a href="#算数运算符" class="headerlink" title="算数运算符"></a>算数运算符</h3><p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111154256455.png" alt="image-20220111154256455"></p>
<p>在除法运算和模运算中，如果除数为0，将是非法除数，返回结果为NULL。</p>
<h3 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h3><p>SELECT 语句中的条件语句经常要使用比较运算符。通过这些比较运算符，可以判断表中的哪些记录是符合条件的。比较结果为真，则返回 1，为假则返回 0，比较结果不确定则返回 NULL。</p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111154411540.png" alt="image-20220111154411540"></p>
<h3 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h3><p>逻辑运算符用来判断表达式的真假。如果表达式是真，结果返回 1。如果表达式是假，结果返回 0。</p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111154456858.png" alt="image-20220111154456858"></p>
<h3 id="位运算符"><a href="#位运算符" class="headerlink" title="位运算符"></a>位运算符</h3><p>位运算符是在二进制数上进行计算的运算符。位运算会先将操作数变成二进制数，进行位运算。然后再将计算结果从二进制数变回十进制数。</p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111154530641.png" alt="image-20220111154530641"></p>
<h3 id="运算符优先级"><a href="#运算符优先级" class="headerlink" title="运算符优先级"></a>运算符优先级</h3><p>最低优先级为： :&#x3D;。</p>
<p><img src="/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E8%AF%AD%E6%B3%95/Users\59737\AppData\Roaming\Typora\typora-user-images\image-20220111154619306.png" alt="image-20220111154619306"></p>
<p>最高优先级为： !、BINARY、 COLLATE。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.gitee.io/Hadoop/Hive/Hive%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2/" class="post-title-link" itemprop="url">Hive数据检索</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-01-30 09:54:00" itemprop="dateCreated datePublished" datetime="2023-01-30T09:54:00+08:00">2023-01-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:32:29" itemprop="dateModified" datetime="2023-09-27T18:32:29+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>28 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive数据检索"><a href="#Hive数据检索" class="headerlink" title="Hive数据检索"></a>Hive数据检索</h1><h2 id="一、Select语法"><a href="#一、Select语法" class="headerlink" title="一、Select语法"></a>一、Select语法</h2><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">WITH</span> CommonTableExpression (, CommonTableExpression)<span class="operator">*</span>]    (Note: <span class="keyword">Only</span> available starting <span class="keyword">with</span> Hive <span class="number">0.13</span><span class="number">.0</span>)</span><br><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_expr, select_expr, ...</span><br><span class="line">  <span class="keyword">FROM</span> table_reference</span><br><span class="line">  [<span class="keyword">WHERE</span> where_condition]</span><br><span class="line">  [<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">  [<span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">  [CLUSTER <span class="keyword">BY</span> col_list</span><br><span class="line">    <span class="operator">|</span> [DISTRIBUTE <span class="keyword">BY</span> col_list] [SORT <span class="keyword">BY</span> col_list]</span><br><span class="line">  ]</span><br><span class="line"> [LIMIT [<span class="keyword">offset</span>,] <span class="keyword">rows</span>]</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li><p>Select语句可以是UNION查询的一部分，也可以是另一个查询的子查询。</p>
</li>
<li><p><code>table_reference</code>是指查询的输入，它可以是一个普通表、视图、连接结构或者子查询。</p>
</li>
<li><p>表名和列名不区分大小写。</p>
<ul>
<li>在Hive 0.12 及之前版本，表名和列名中只允许出现字母、数字和下划线。</li>
<li>在Hive 0.13及之后的版本，列名可以包含任何Unicode字符。在反引号中指定的任何列名都按照字面意思处理。在反引号包裹的字符串中，可以使用连续的两个反引号来表示反引号字符。</li>
<li>如果要使用Hive 0.13之前的命名规则，即只能使用字母、数字、下划线命名的方式，可以将配置属性<code>hive.support.quoted.identifiers</code>为none，在这种设置下，反引号中的名字将被看作普通表达。</li>
</ul>
</li>
<li><p>一个简单的查询，查询表t1中的所有行列值：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t1 </span><br></pre></td></tr></table></figure>
</li>
<li><p>注意：自Hive 0.13.0起，from关键字变为可选的。</p>
</li>
<li><p>如果要获取当前数据库中的内容，可以使用current_database()函数，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> current_database()</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询时指定数据库，可以使用携带数据库名字的表名，如“db_name.table_name”(Hive 0.7 起使用)，也可以在查询之前使用USE语句(Hive 0.6起使用)。<br>“db_name.table_name”的方式允许一个查询在不同的数据库中获取表。</p>
</li>
<li><p>USE 关键字为之后的所有HiveQL语句设置了数据库，使用关键字”default”可以将数据库重设为默认数据库，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">USE database_name;</span><br><span class="line"><span class="keyword">SELECT</span> query_specifications;</span><br><span class="line">USE <span class="keyword">default</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-1-WHERE子句"><a href="#1-1-WHERE子句" class="headerlink" title="1.1 WHERE子句"></a>1.1 WHERE子句</h3><p>WHERE条件是一个布尔表达式，例如，下面的查询只返回来自美国地区的金额大于10的销售记录。Hive在WHERE子句中支持许多操作符和用户自定义函数：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> sales <span class="keyword">WHERE</span> amount <span class="operator">&gt;</span> <span class="number">10</span> <span class="keyword">AND</span> region <span class="operator">=</span> &quot;US&quot;</span><br></pre></td></tr></table></figure>

<h3 id="1-2-ALL-和-DISTINCT-子句"><a href="#1-2-ALL-和-DISTINCT-子句" class="headerlink" title="1.2 ALL 和 DISTINCT 子句"></a>1.2 ALL 和 DISTINCT 子句</h3><p>ALL 和 DISTINCT 子句用来确定重复的行是否应该被返回，如果没有给出这些选项，则默认为ALL(所有匹配的行都被返回)。DISTINCT指定了要在结果集中删除的行。注意，Hive 在 1.1.0版本后支持SELECT DISTINCT * 的写法。下面是一些例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; SELECT col1, col2 FROM t1</span><br><span class="line">    1 3</span><br><span class="line">    1 3</span><br><span class="line">    1 4</span><br><span class="line">    2 5</span><br><span class="line">hive&gt; SELECT DISTINCT col1, col2 FROM t1</span><br><span class="line">    1 3</span><br><span class="line">    1 4</span><br><span class="line">    2 5</span><br><span class="line">hive&gt; SELECT DISTINCT col1 FROM t1</span><br><span class="line">    1</span><br><span class="line">    2</span><br></pre></td></tr></table></figure>

<p>ALL 和  DISTINCT 也可以被用在UNION子句中。</p>
<h3 id="1-3-基于分区的查询"><a href="#1-3-基于分区的查询" class="headerlink" title="1.3 基于分区的查询"></a>1.3 基于分区的查询</h3><p>一般来说，选择语句查询会扫描整个表(除了抽样外)。如果建表时使用了PARTITIONED BY子句，查询范围会减小为只扫描与指定分区相关的表的一部分。如果分区谓词是在WHERE子句中，或者在JOIN中的ON子句指定的，则Hive会做分区修整。例如，如果表page_views使用日期列进行分区，下面的查询只会检索那些在2008-03-01 到 2008-03-31之间的行：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> page_views.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> page_views</span><br><span class="line"><span class="keyword">WHERE</span> page_views.date <span class="operator">&gt;=</span> <span class="string">&#x27;2008-03-01&#x27;</span> <span class="keyword">AND</span> page_views.date <span class="operator">&lt;=</span> <span class="string">&#x27;2008-03-31&#x27;</span></span><br></pre></td></tr></table></figure>

<p>如果表page_views与另一个表dim_users连接在一起，可以像下面这样在ON子句中确定分区范围：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> page_views.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> page_views <span class="keyword">JOIN</span> dim_users</span><br><span class="line">  <span class="keyword">ON</span> (page_views.user_id <span class="operator">=</span> dim_users.id <span class="keyword">AND</span> page_views.date <span class="operator">&gt;=</span> <span class="string">&#x27;2008-03-01&#x27;</span> <span class="keyword">AND</span> page_views.date <span class="operator">&lt;=</span> <span class="string">&#x27;2008-03-31&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="1-4-Having子句"><a href="#1-4-Having子句" class="headerlink" title="1.4 Having子句"></a>1.4 Having子句</h3><p>Having用法：</p>
<blockquote>
<p> 1.WHERE 子句用来筛选 FROM 子句中指定的操作所产生的行。<br> 2.GROUP BY 子句用来分组 WHERE 子句的输出。<br> 3.HAVING 子句用来从分组的结果中筛选行。</p>
</blockquote>
<p><strong>Having子句必须配合Group By 子句使用！</strong></p>
<p>在0.7.0 版本中 Hive添加了对HAVING子句的支持，而在更老的版本中，Hive也可能通过子查询达到相同的效果，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> col1 <span class="keyword">FROM</span> t1 <span class="keyword">GROUP</span> <span class="keyword">BY</span> col1 <span class="keyword">HAVING</span> <span class="built_in">SUM</span>(col2) <span class="operator">&gt;</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>也可以被这样表示：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> col1 <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> col1, <span class="built_in">SUM</span>(col2) <span class="keyword">AS</span> col2sum <span class="keyword">FROM</span> t1 <span class="keyword">GROUP</span> <span class="keyword">BY</span> col1) t2 <span class="keyword">WHERE</span> t2.col2sum <span class="operator">&gt;</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>

<h3 id="1-5-LIMIT子句"><a href="#1-5-LIMIT子句" class="headerlink" title="1.5 LIMIT子句"></a>1.5 LIMIT子句</h3><p>LIMIT子句可以用来对SELECT查询的返回结果进行行数上的限制。</p>
<p>LIMIT 关键字可以带有一到两个参数，这些参数必须是非负整数。</p>
<p>第一个参数指定了到第一行的偏移量，第二个参数指定了最大返回行数。</p>
<p>当只给定了一个参数据，它代表返回的最大行数，此时偏移量默认为0。</p>
<p>下面的查询返回了5个任意的customers：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> customers LIMIT <span class="number">5</span></span><br></pre></td></tr></table></figure>

<p>下面的查询返回了最先创建的5个customers：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> customers LIMIT <span class="number">5</span></span><br></pre></td></tr></table></figure>

<p>下面的查询返回了第三个到第七个创建的customers：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> customers <span class="keyword">ORDER</span> <span class="keyword">BY</span> create_date LIMIT <span class="number">2</span>,<span class="number">5</span></span><br></pre></td></tr></table></figure>

<p>在Hive 0.13.0之前的版本中，SELECT语句可以采用基于正则表达式(REGEX)的列规范，或者在0.13.0及以后的版本中，将<code>hive.support.quoted.identifiers</code>设置为none。</p>
<blockquote>
<p>使用Java的正则表达式语法规则。</p>
<p>下面的查询选择了除ds和hr的所有列:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> `(ds<span class="operator">|</span>hr)?<span class="operator">+</span>.<span class="operator">+</span>` <span class="keyword">FROM</span> sales</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="1-6-Group-By语法"><a href="#1-6-Group-By语法" class="headerlink" title="1.6 Group By语法"></a>1.6 Group By语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">groupByClause: GROUP BY groupByExpression (, groupByExpression)*</span><br><span class="line"> </span><br><span class="line">groupByExpression: expression</span><br><span class="line"> </span><br><span class="line">groupByQuery: SELECT expression (, expression)* FROM src groupByClause?</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<p>groupByExpression中列可以通过名字指定，但不能通过位置指定。但在Hive 0.11.0之后，列可以通过位置指定，只要按照以下方式配置：	</p>
<ul>
<li>当Hive 版本在 0.11.0 到 2.1.x之间，将<code>hive.groupby.orderby.position.alias</code>设置为true(默认为false)</li>
<li>当Hive 版本在 2.2.0及以后时，将<code>hive.groupby.position.alias</code>设置为true(默认为false)</li>
</ul>
<h4 id="1-6-1-一些样例"><a href="#1-6-1-一些样例" class="headerlink" title="1.6.1 一些样例"></a>1.6.1 一些样例</h4><ul>
<li><p>查询表中的数据行数：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> table2;</span><br></pre></td></tr></table></figure>

<p>注意在一些hive版本中不支持COUNT(*)，需要使用COUNT(1)代替。</p>
</li>
<li><p>按性别计算不同用户的数量，可以编写如下查询:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_gender_sum</span><br><span class="line"><span class="keyword">SELECT</span> pv_users.gender, <span class="built_in">count</span> (<span class="keyword">DISTINCT</span> pv_users.userid)</span><br><span class="line"><span class="keyword">FROM</span> pv_users</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> pv_users.gender;</span><br></pre></td></tr></table></figure>
</li>
<li><p>可以同时进行多个聚合，但是不能有两个聚合具有不同的DISTINCT列。例如，下面的做法是可行的，因为count(DISTINCT)和sum(DISTINCT)指定了相同的列:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_gender_agg</span><br><span class="line"><span class="keyword">SELECT</span> pv_users.gender, <span class="built_in">count</span>(<span class="keyword">DISTINCT</span> pv_users.userid), <span class="built_in">count</span>(<span class="operator">*</span>), <span class="built_in">sum</span>(<span class="keyword">DISTINCT</span> pv_users.userid)</span><br><span class="line"><span class="keyword">FROM</span> pv_users</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> pv_users.gender;</span><br></pre></td></tr></table></figure>

<p>下面的聚合则是不允许的，因为聚合的列不同：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_gender_agg</span><br><span class="line"><span class="keyword">SELECT</span> pv_users.gender, <span class="built_in">count</span>(<span class="keyword">DISTINCT</span> pv_users.userid), <span class="built_in">count</span>(<span class="keyword">DISTINCT</span> pv_users.ip)</span><br><span class="line"><span class="keyword">FROM</span> pv_users</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> pv_users.gender;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="1-6-2-select表达式和group-by子句"><a href="#1-6-2-select表达式和group-by子句" class="headerlink" title="1.6.2 select表达式和group by子句"></a>1.6.2 select表达式和group by子句</h4><p>当要使用group by子句时，select表达式中只能包含那些在group by子句中的列，当然，select表达式中可以尽可能多的使用聚合函数(如count)。</p>
<p>下面用一个例子来说明：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t1(a <span class="type">INTEGER</span>, b INTGER);</span><br></pre></td></tr></table></figure>

<p>查询上面创建的表可以这样写：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">   a,</span><br><span class="line">   <span class="built_in">sum</span>(b)</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">   t1</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">   a;</span><br></pre></td></tr></table></figure>

<p>但一下的查询方式是不被允许的，因为select表达式中含有group by子句中没有的列：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">   a,</span><br><span class="line">   b</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">   t1</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">   a;</span><br></pre></td></tr></table></figure>

<p>这是因为如果表是下面的形式：</p>
<figure class="highlight plaintext"><figcaption><span>b</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a    b</span><br><span class="line">------</span><br><span class="line">100  1</span><br><span class="line">100  2</span><br><span class="line">100  3</span><br></pre></td></tr></table></figure>

<p>如果使用a来分组，返回哪条数据是一个矛盾的问题。</p>
<h4 id="1-6-3-高级特性"><a href="#1-6-3-高级特性" class="headerlink" title="1.6.3 高级特性"></a>1.6.3 高级特性</h4><h5 id="1-6-3-1-多表分组插入"><a href="#1-6-3-1-多表分组插入" class="headerlink" title="1.6.3.1 多表分组插入"></a>1.6.3.1 多表分组插入</h5><p>聚合或简单选择的输出可以进一步发送到多个表中，甚至发送到hadoop dfs文件(然后可以使用hdfs实用程序操作这些文件)。例如，如果除了性别分类，还需要找到按年龄分列单独视图页，可以通过以下查询实现:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> pv_users</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_gender_sum</span><br><span class="line">  <span class="keyword">SELECT</span> pv_users.gender, <span class="built_in">count</span>(<span class="keyword">DISTINCT</span> pv_users.userid)</span><br><span class="line">  <span class="keyword">GROUP</span> <span class="keyword">BY</span> pv_users.gender</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE DIRECTORY <span class="string">&#x27;/user/facebook/tmp/pv_age_sum&#x27;</span></span><br><span class="line">  <span class="keyword">SELECT</span> pv_users.age, <span class="built_in">count</span>(<span class="keyword">DISTINCT</span> pv_users.userid)</span><br><span class="line">  <span class="keyword">GROUP</span> <span class="keyword">BY</span> pv_users.age</span><br></pre></td></tr></table></figure>

<h5 id="1-6-3-2-基于分组的映射端聚合"><a href="#1-6-3-2-基于分组的映射端聚合" class="headerlink" title="1.6.3.2 基于分组的映射端聚合"></a>1.6.3.2 基于分组的映射端聚合</h5><p><code>hive.map.aggr</code>参数控制了我们的聚合方式，默认为false，如果设置为true，Hive将直接在map任务中做第一级聚合。通常这样的销量更高，但是成功运行可能需要更多的内存。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.map.aggr<span class="operator">=</span>``<span class="literal">true</span>``;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> table2;</span><br></pre></td></tr></table></figure>

<p>注意：不包含HIVE-287的Hive版本需要用COUNT(1)来代替COUNT(*)。</p>
<h3 id="1-7-Order-Sort-Cluster-and-Distribute-By"><a href="#1-7-Order-Sort-Cluster-and-Distribute-By" class="headerlink" title="1.7 Order, Sort, Cluster, and Distribute By"></a>1.7 Order, Sort, Cluster, and Distribute By</h3><h4 id="1-7-1-Order-By"><a href="#1-7-1-Order-By" class="headerlink" title="1.7.1 Order By"></a>1.7.1 Order By</h4><p>语法：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">colOrder: ( <span class="keyword">ASC</span> <span class="operator">|</span> <span class="keyword">DESC</span> )</span><br><span class="line">colNullOrder: (NULLS <span class="keyword">FIRST</span> <span class="operator">|</span> NULLS <span class="keyword">LAST</span>)           <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 2.1.0 and later)</span></span><br><span class="line">orderBy: <span class="keyword">ORDER</span> <span class="keyword">BY</span> colName colOrder? colNullOrder? (<span class="string">&#x27;,&#x27;</span> colName colOrder? colNullOrder?)<span class="operator">*</span></span><br><span class="line">query: <span class="keyword">SELECT</span> expression (<span class="string">&#x27;,&#x27;</span> expression)<span class="operator">*</span> <span class="keyword">FROM</span> src orderBy</span><br></pre></td></tr></table></figure>

<p>Order By子句存在一些限制，在严格模式下(设置 hive.mapred.mode&#x3D;strict)，Order By子句后必须跟着一个Limit子句。如果没有设置严格模式的话Limit子句就不是必需的。原因是为了强制得到所有结果的总顺序，必须有一个reducer来对最终结果分类。如果输出行数非常多，则单个reducer可能会执行非常长的时间。</p>
<p>模式的排序顺序是增序（ascending，ASC）。</p>
<p>在Hive 2.1.0版本以后，支持在Order By子句中为每一列指定空的排序顺序。ASC顺序的默认空排序顺序是NULLS FIRST，而DESC顺序的默认空排序顺序是NULLS LAST。</p>
<p>在Hive 3.0.0之后，没有Limit 的Order By子句在子查询和视图中将被优化器移除，要防止这种情况，可以将<code>hive.remove.orderby.in.subquery</code>设置为false。</p>
<h4 id="1-7-2-Sort-By"><a href="#1-7-2-Sort-By" class="headerlink" title="1.7.2 Sort By"></a>1.7.2 Sort By</h4><p>语法：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">colOrder: ( <span class="keyword">ASC</span> <span class="operator">|</span> <span class="keyword">DESC</span> )</span><br><span class="line">sortBy: SORT <span class="keyword">BY</span> colName colOrder? (<span class="string">&#x27;,&#x27;</span> colName colOrder?)<span class="operator">*</span></span><br><span class="line">query: <span class="keyword">SELECT</span> expression (<span class="string">&#x27;,&#x27;</span> expression)<span class="operator">*</span> <span class="keyword">FROM</span> src sortBy</span><br></pre></td></tr></table></figure>

<p>Hive使用SORT BY中的列对行进行排序，然后再将行输入reducer。分类顺序取决于列的类型。如果列是数值类型的，那么分类顺序也是按照数值顺序。如果列是string类型的，则分类顺序将是辞典编纂的循序（字典顺序）。</p>
<p>在Hive 3.0.0之后，没有Limit 的Sort By子句在子查询和视图中将被优化器移除，要防止这种情况，可以将<code>hive.remove.orderby.in.subquery</code>设置为false。</p>
<h4 id="1-7-3-Sort-By-和-Order-By的不同点"><a href="#1-7-3-Sort-By-和-Order-By的不同点" class="headerlink" title="1.7.3 Sort By 和 Order By的不同点"></a>1.7.3 Sort By 和 Order By的不同点</h4><p>“order by”和“sort by”之间的区别是，前者保证输出的总顺序，而后者仅保证reducer内的行排序。如果有多个reducer，“sort by”可能会给出部分排序的最终结果。</p>
<p>单个列的SORT BY和CLUSTER BY之间的区别可能会令人困惑。不同之处在于CLUSTER BY是按字段进行分区，而SORT BY是在多个reducer之间随机分配数据(和加载)的情况下进行的。</p>
<p>总的来说，每个reducer中的数据将按使用者提供的顺序来分类。下面是一个例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> key, <span class="keyword">value</span> <span class="keyword">FROM</span> src SORT <span class="keyword">BY</span> key <span class="keyword">ASC</span>, <span class="keyword">value</span> <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure>

<p>查询有两个reducer，每一个的输出分别为：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>   <span class="number">5</span></span><br><span class="line"><span class="number">0</span>   <span class="number">3</span></span><br><span class="line"><span class="number">3</span>   <span class="number">6</span></span><br><span class="line"><span class="number">9</span>   <span class="number">1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>   <span class="number">4</span></span><br><span class="line"><span class="number">0</span>   <span class="number">3</span></span><br><span class="line"><span class="number">1</span>   <span class="number">1</span></span><br><span class="line"><span class="number">2</span>   <span class="number">5</span></span><br></pre></td></tr></table></figure>

<h4 id="1-7-4-为Sort-By设置类型"><a href="#1-7-4-为Sort-By设置类型" class="headerlink" title="1.7.4 为Sort By设置类型"></a>1.7.4 为Sort By设置类型</h4><p>在TRANSFORM之后，变量类型通常被认为是字符串，这意味着数字数据将按字典顺序排序。为了克服这个问题，可以在使用SORT BY之前再使用带强制转换的SELECT语句。例如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> (<span class="keyword">FROM</span> (<span class="keyword">FROM</span> src</span><br><span class="line">            <span class="keyword">SELECT</span> TRANSFORM(<span class="keyword">value</span>)</span><br><span class="line">            <span class="keyword">USING</span> <span class="string">&#x27;mapper&#x27;</span></span><br><span class="line">            <span class="keyword">AS</span> <span class="keyword">value</span>, count) mapped</span><br><span class="line">      <span class="keyword">SELECT</span> <span class="built_in">cast</span>(<span class="keyword">value</span> <span class="keyword">as</span> <span class="keyword">double</span>) <span class="keyword">AS</span> <span class="keyword">value</span>, <span class="built_in">cast</span>(count <span class="keyword">as</span> <span class="type">int</span>) <span class="keyword">AS</span> count</span><br><span class="line">      SORT <span class="keyword">BY</span> <span class="keyword">value</span>, count) sorted</span><br><span class="line"><span class="keyword">SELECT</span> TRANSFORM(<span class="keyword">value</span>, count)</span><br><span class="line"><span class="keyword">USING</span> <span class="string">&#x27;reducer&#x27;</span></span><br><span class="line"><span class="keyword">AS</span> whatever</span><br></pre></td></tr></table></figure>

<h4 id="1-7-5-Cluster-By-and-Distribute-By"><a href="#1-7-5-Cluster-By-and-Distribute-By" class="headerlink" title="1.7.5 Cluster By and Distribute By"></a>1.7.5 Cluster By and Distribute By</h4><p>Cluster By 和 Distribute By主要是和Transform&#x2F;Map-Reduce 脚本一起使用。如果需要为后续查询对查询的输出进行分区和排序，那么在SELECT语句中它有时是有用的。</p>
<p>Cluster By 是对 Distribute By 和 Sort By的一种简化方式。</p>
<p>Hive 在Distribute By 中使用列来把行分配给reducers。有相同Distribute By列 的行会分配到同一个reducer中。但是，Distribute By无法保证分配的列上的clustering 或 sorting 的属性。</p>
<p>例如，使用Distribute By x将下面的五行数据分配给两个reducer：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x1</span><br><span class="line">x2</span><br><span class="line">x4</span><br><span class="line">x3</span><br><span class="line">x1</span><br></pre></td></tr></table></figure>

<p>Reducer1得到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x1</span><br><span class="line">x2</span><br><span class="line">x1</span><br></pre></td></tr></table></figure>

<p>Reducer2得到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x4</span><br><span class="line">x3</span><br></pre></td></tr></table></figure>

<p>注意到拥有相同键值x1的两行被分配到了同一个reducer中，但是它们不能够保证聚集到了相邻的位置。</p>
<p>相反地，如果使用Cluster By x，两个reducer会对x的行做进一步的排序：</p>
<p>Reducer1得到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x1</span><br><span class="line">x1</span><br><span class="line">x2</span><br></pre></td></tr></table></figure>

<p>Reducer2得到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x3</span><br><span class="line">x4</span><br></pre></td></tr></table></figure>

<p>使用者可以指定 Distribute By 和 Sort By来代替Cluster By，所以分区列和分类列可以不同。通常的情况是分区列在分类列前面，即先分区再分类，但这不是必需的。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> col1, col2 <span class="keyword">FROM</span> t1 CLUSTER <span class="keyword">BY</span> col1</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> col1, col2 <span class="keyword">FROM</span> t1 DISTRIBUTE <span class="keyword">BY</span> col1</span><br><span class="line"> </span><br><span class="line"><span class="keyword">SELECT</span> col1, col2 <span class="keyword">FROM</span> t1 DISTRIBUTE <span class="keyword">BY</span> col1 SORT <span class="keyword">BY</span> col1 <span class="keyword">ASC</span>, col2 <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">FROM</span> pv_users</span><br><span class="line">  MAP ( pv_users.userid, pv_users.date )</span><br><span class="line">  <span class="keyword">USING</span> <span class="string">&#x27;map_script&#x27;</span></span><br><span class="line">  <span class="keyword">AS</span> c1, c2, c3</span><br><span class="line">  DISTRIBUTE <span class="keyword">BY</span> c2</span><br><span class="line">  SORT <span class="keyword">BY</span> c2, c1) map_output</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_users_reduced</span><br><span class="line">  REDUCE ( map_output.c1, map_output.c2, map_output.c3 )</span><br><span class="line">  <span class="keyword">USING</span> <span class="string">&#x27;reduce_script&#x27;</span></span><br><span class="line">  <span class="keyword">AS</span> <span class="type">date</span>, count;</span><br></pre></td></tr></table></figure>

<h3 id="1-8-TRANSFORM-和-Map-Reduce-脚本-（暂不研究）"><a href="#1-8-TRANSFORM-和-Map-Reduce-脚本-（暂不研究）" class="headerlink" title="1.8 TRANSFORM 和 Map-Reduce 脚本  （暂不研究）"></a>1.8 TRANSFORM 和 Map-Reduce 脚本  （暂不研究）</h3><h3 id="1-9-运算符和用户自定义函数-未完待续"><a href="#1-9-运算符和用户自定义函数-未完待续" class="headerlink" title="1.9 运算符和用户自定义函数  (未完待续)"></a>1.9 运算符和用户自定义函数  (未完待续)</h3><h4 id="内置运算符："><a href="#内置运算符：" class="headerlink" title="内置运算符："></a>内置运算符：</h4><ul>
<li>运算符优先级</li>
</ul>
<table>
<thead>
<tr>
<th>示例</th>
<th>运算符</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>A[B] , A.identifier</td>
<td>中括号([]), 点(.)</td>
<td>元素选择</td>
</tr>
<tr>
<td>-A</td>
<td>一元运算符，正号(+),负号(-),取反码(~)</td>
<td>前置一元运算符</td>
</tr>
<tr>
<td>A IS [NOT] (NULL|TRUE|FALSE)</td>
<td>IS NULL,IS NOT NULL, …</td>
<td>后置一元运算符</td>
</tr>
<tr>
<td>A ^ B</td>
<td>按位亦或(^)</td>
<td>按位亦或</td>
</tr>
<tr>
<td>A * B</td>
<td>乘(*), 除(&#x2F;), 取余(%), 整除(DIV)</td>
<td>乘除运算</td>
</tr>
<tr>
<td>A + B</td>
<td>加(+), 减(-)</td>
<td>加减运算</td>
</tr>
<tr>
<td>A || B</td>
<td>字符串连接(||)</td>
<td>字符串连接</td>
</tr>
<tr>
<td>A &amp; B</td>
<td>按位与(&amp;)</td>
<td>按位与</td>
</tr>
<tr>
<td>A | B</td>
<td>按位或(|)</td>
<td>按位或</td>
</tr>
</tbody></table>
<ul>
<li>关系运算符</li>
</ul>
<table>
<thead>
<tr>
<th>运算符</th>
<th>操作类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>A &#x3D; B</td>
<td>所有基本类型</td>
<td>A等于B返回true，否则返回false</td>
</tr>
<tr>
<td>A &#x3D;&#x3D; B</td>
<td>所有基本类型</td>
<td>相等，等号的同义词</td>
</tr>
<tr>
<td>A &lt;&#x3D;&gt; B</td>
<td>所有基本类型</td>
<td>操作数非空时和 ‘&#x3D;’ 运算符返回相同的结果，当两个操作数都为空时返回true，当有一个操作数为空时返回false，(Hive 0.9.0 版本起用)</td>
</tr>
<tr>
<td>A &lt;&gt; B</td>
<td>所有基本类型</td>
<td>当A或B中有一个为NULL时返回NULL，当A不等于B时返回TRUE，否则返回FALSE。</td>
</tr>
<tr>
<td>A !&#x3D; B</td>
<td>所有基本类型</td>
<td>同”&lt;&gt;”运算符</td>
</tr>
<tr>
<td>A &lt; B</td>
<td>所有基本类型</td>
<td>当A或B中有一个为NULL时返回NULL，当A小于B时返回TRUE，否则返回FALSE。</td>
</tr>
<tr>
<td>A &lt;&#x3D; B</td>
<td>所有基本类型</td>
<td>当A或B中有一个为NULL时返回NULL，当A小于等于B时返回TRUE，否则返回FALSE。</td>
</tr>
<tr>
<td>A &gt; B</td>
<td>所有基本类型</td>
<td>当A或B中有一个为NULL时返回NULL，当A大于B时返回TRUE，否则返回FALSE。</td>
</tr>
<tr>
<td>A &gt;&#x3D; B</td>
<td>所有基本类型</td>
<td>当A或B中有一个为NULL时返回NULL，当A大于等于B时返回TRUE，否则返回FALSE。</td>
</tr>
<tr>
<td>A [NOT] BETWEEN B AND C</td>
<td>所有基本类型</td>
<td>当A，B，C中任意一个为NULL时返回NULL，当A大于等于B且小于等于C时返回TRUE，否则返回FALSE。可以使用NOT关键字得到相反结果。(Hive 0.9.0 起用)</td>
</tr>
<tr>
<td>A IS NULL</td>
<td>所有类型</td>
<td>A为NULL时返回TRUE，否则返回FALSE.</td>
</tr>
<tr>
<td>A IS NOT NULL</td>
<td>所有类型</td>
<td>A不为NULL时返回TRUE，否则返回FALSE.</td>
</tr>
<tr>
<td>A IS [NOT] (TRUE|FALSE)</td>
<td>布尔类型</td>
<td>只有满足判断条件时返回TRUE。(自Hive 3.0.0 起用）注意，NULL是未知的，当要判断NULL的布尔属性时，返回FALSE。</td>
</tr>
<tr>
<td>A [NOT] LIKE B</td>
<td>字符串</td>
<td>如果A或B为NULL，则为NULL，如果字符串A匹配SQL简单正则表达式B，则为TRUE，否则为FALSE。比较是逐个字符进行的。B中的下划线字符匹配A中的任何字符。而B中的%字符匹配A中的任意数量的字符(类似于posix正则表达式中的.*)。例如，’foobar’ LIKE ‘foo’的计算结果为FALSE，而’foobar’ LIKE ‘foo_ _ _’的计算结果为TRUE， ‘foobar’ LIKE ‘foo%’的计算结果也是TRUE。</td>
</tr>
<tr>
<td>A RLIKE B</td>
<td>字符串</td>
<td>如果A或B为NULL，则为NULL，如果A的任何子字符串(可能为空)匹配Java正则表达式B，则为TRUE，否则为FALSE。例如，’foobar’ RLIKE ‘foo’的计算结果为TRUE， ‘foobar’ RLIKE ‘^f.*r$’也是如此。</td>
</tr>
<tr>
<td>A REGEXP B</td>
<td>字符串</td>
<td>同RLIKE。</td>
</tr>
</tbody></table>
<h3 id="1-10-XPath函数（暂不研究）"><a href="#1-10-XPath函数（暂不研究）" class="headerlink" title="1.10 XPath函数（暂不研究）"></a>1.10 XPath函数（暂不研究）</h3><h3 id="1-11-连接-join"><a href="#1-11-连接-join" class="headerlink" title="1.11 连接(join)"></a>1.11 连接(join)</h3><p>Hive 支持如下的表连接语法：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">join_table:</span><br><span class="line">    table_reference [<span class="keyword">INNER</span>] <span class="keyword">JOIN</span> table_factor [join_condition]</span><br><span class="line">  <span class="operator">|</span> table_reference &#123;<span class="keyword">LEFT</span><span class="operator">|</span><span class="keyword">RIGHT</span><span class="operator">|</span><span class="keyword">FULL</span>&#125; [<span class="keyword">OUTER</span>] <span class="keyword">JOIN</span> table_reference join_condition</span><br><span class="line">  <span class="operator">|</span> table_reference <span class="keyword">LEFT</span> SEMI <span class="keyword">JOIN</span> table_reference join_condition</span><br><span class="line">  <span class="operator">|</span> table_reference <span class="keyword">CROSS</span> <span class="keyword">JOIN</span> table_reference [join_condition] (<span class="keyword">as</span> <span class="keyword">of</span> Hive <span class="number">0.10</span>)</span><br><span class="line"> </span><br><span class="line">table_reference:</span><br><span class="line">    table_factor</span><br><span class="line">  <span class="operator">|</span> join_table</span><br><span class="line"> </span><br><span class="line">table_factor:</span><br><span class="line">    tbl_name [alias]</span><br><span class="line">  <span class="operator">|</span> table_subquery alias</span><br><span class="line">  <span class="operator">|</span> ( table_references )</span><br><span class="line"> </span><br><span class="line">join_condition:</span><br><span class="line">    <span class="keyword">ON</span> expression</span><br></pre></td></tr></table></figure>

<ul>
<li>版本相关：</li>
</ul>
<blockquote>
<p>从Hive 0.13.0开始支持隐式连接表示。这允许FROM子句连接以逗号分隔的表列表，省略join关键字。例如:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> table1 t1, table2 t2, table3 t3</span><br><span class="line"><span class="keyword">WHERE</span> t1.id <span class="operator">=</span> t2.id <span class="keyword">AND</span> t2.id <span class="operator">=</span> t3.id <span class="keyword">AND</span> t1.zipcode <span class="operator">=</span> <span class="string">&#x27;02535&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>从Hive 0.13.0开始，连接条件中支持非限定列引用。Hive尝试根据连接的输入来解决这些问题。如果非限定列引用解析为多个表，Hive将其标记为不明确引用。例如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> a (k1 string, v1 string);</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> b (k2 string, v2 string);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> k1, v1, k2, v2</span><br><span class="line"><span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> k1 <span class="operator">=</span> k2; </span><br></pre></td></tr></table></figure>

<p>从Hive 2.2.0开始支持ON子句中的复杂表达式。在此之前，Hive不支持非相等条件的连接条件。特别地，连接条件的语法被限制如下:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">join_condition:</span><br><span class="line">    <span class="keyword">ON</span> equality_expression ( <span class="keyword">AND</span> equality_expression )<span class="operator">*</span></span><br><span class="line"></span><br><span class="line">equality_expression:</span><br><span class="line">    expression <span class="operator">=</span> expression</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="一些示例："><a href="#一些示例：" class="headerlink" title="一些示例："></a>一些示例：</h4><p>在编写连接查询时需要考虑的一些要点如下:</p>
<ul>
<li>允许复杂的连接表达式，如：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.<span class="operator">*</span> <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.id <span class="operator">=</span> b.id)</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.<span class="operator">*</span> <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.id <span class="operator">=</span> b.id <span class="keyword">AND</span> a.department <span class="operator">=</span> b.department)</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.<span class="operator">*</span> <span class="keyword">FROM</span> a <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.id <span class="operator">&lt;&gt;</span> b.id)</span><br></pre></td></tr></table></figure>

<ul>
<li>多个表可以通过查询连接在一起，如：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.val, b.val, c.val <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key1) <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key2)</span><br></pre></td></tr></table></figure>

<ul>
<li>如果在每个表的join子句中使用了相同的列，那么Hive会将多个表的连接转换为一个map&#x2F;reduce任务,如</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.val, b.val, c.val <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key1) <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key1)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>被转换成了一个map&#x2F;reduce任务，因为连接时只涉及到了表b的key1列，另一种情况：</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.val, b.val, c.val <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key1) <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key2)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>被转换成了两个map&#x2F;reduce任务，因为第一个连接使用了表b的key1列，第二个连接使用了表b的key2列，第一个map&#x2F;reduce任务将表a和b连接在了一起，第二个map&#x2F;reduce任务将第一个的连接结果与表c连接在了一起。</p>
</blockquote>
<ul>
<li>在连接的每个map&#x2F;reduce阶段，可以通过提示指定要流化的表 ：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ STREAMTABLE(a) */</span> a.val, b.val, c.val <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key1) <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key1)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>所有这三个表被连接到一个单独的map&#x2F;reduce作业中，表b和c的键的特定值被缓冲在reducer的内存中。然后，对于从a中检索到的每一行，使用缓冲的行计算连接。如果省略STREAMTABLE提示，Hive会将最右边的表在join时流化。</p>
</blockquote>
<ul>
<li><strong>左连接、右连接、全连接和外连接</strong>的存在是为了在ON子句匹配不到时提供更多的控制，例如，下面的查询</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.val, b.val <span class="keyword">FROM</span> a <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key<span class="operator">=</span>b.key)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>返回结果对应于a中的每一行，当a.key等于b.key时，返回行将包括a.val和b.val，不相等时，返回行的结果为a.val 和NULL。语句中”FROM a LEFT OUTER JOIN b”必须写在同一行内以便于理解连接过程——查询中a在b的左边，所以来自a的行都被保留；如果是RIGHT OUTER JOIN的话b的行将被全部保留；如果是FULL OUTER JOIN的话，来自a和b的行都会被全部保留。外连接OUTER JOIN的语法应该符合标准的SQL规范。</p>
</blockquote>
<ul>
<li>连接发生在WHERE子句之前。如果想要对连接结果做过滤，则应该在WHERE子句中进行条件约束，否则应该约束应该在join子句中(实际上是ON子句可以约束连接的输出)。涉及到这个问题的一个点是分区表:</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.val, b.val <span class="keyword">FROM</span> a <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key<span class="operator">=</span>b.key)</span><br><span class="line"><span class="keyword">WHERE</span> a.ds<span class="operator">=</span><span class="string">&#x27;2009-07-07&#x27;</span> <span class="keyword">AND</span> b.ds<span class="operator">=</span><span class="string">&#x27;2009-07-07&#x27;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>如上述语句，a表和b表做左连接，产生一个含有a.val 和 b.val的列表，ds是分区列。因为是左连接，所以a是主表，连接过程中对应不到a.key 的b的连接部分将被置为NULL，包括分区列ds。而在WHERE子句中使用分区列对连接结果进行了过滤，此时由于a和b没有匹配到的行中b的部分为NULL(包括b.ds),所以这些没有成功匹配的行会被WHERE子句过滤掉，最终的结果不是左连接的结果，因为WHERE破坏了左连接的约束。如果想要在连接时增加过滤条件，应该按下面这样写：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.val, b.val <span class="keyword">FROM</span> a <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> b</span><br><span class="line"><span class="keyword">ON</span> (a.key<span class="operator">=</span>b.key <span class="keyword">AND</span> b.ds<span class="operator">=</span><span class="string">&#x27;2009-07-07&#x27;</span> <span class="keyword">AND</span> a.ds<span class="operator">=</span><span class="string">&#x27;2009-07-07&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>连接结果在连接过程中已经进行了过滤，不会出现查询完再过滤所产生的问题。同样的逻辑适用于右连接和全连接。</p>
</blockquote>
<ul>
<li>连接是不可交换的！连接是左关联的，无论是左连接还是右连接。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.val1, a.val2, b.val, c.val</span><br><span class="line"><span class="keyword">FROM</span> a</span><br><span class="line"><span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key)</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (a.key <span class="operator">=</span> c.key)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>首先a连接b(内连接)，按连接条件只保留全部匹配的行。连接后形成的表再连接c。如果一个用于连接条件的key在表a和表c中都有，但表b中没有，将产生意料之外的结果：由于b没有与a匹配的key，这些行在a和b连接时就被过滤掉了，所以ab连接结果中也没有a表中的这个key，当ab连接结果与c表左连接时，c中这个key的行也匹配不到，因为a和b的连接结果中没有这个key（连接时被过滤掉了）。类似地，如果现在是右连接，对于c的有这个key的行来说，匹配结果将是NULL，NULL，NULL，c.val.因为即使我们指定了a.key &#x3D; c.key作为连接条件，在第一次连接时由于没有匹配到，这个key已经被过滤掉了。为了得到更为直观的效果，应该改为：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> c <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> a <span class="keyword">ON</span> (c.key <span class="operator">=</span> a.key) <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key)。</span><br></pre></td></tr></table></figure>
</blockquote>
<ul>
<li>LEFT SEMI JOIN(左半连接)以一种有效的方式实现了不相关的 IN&#x2F;EXISTS子查询语法。在Hive 0.13版本中，子查询支持IN&#x2F;NOT IN&#x2F;EXISTS&#x2F;NOT EXISTS操作符，因此大多数join操作不再需要手动执行。使用LEFT SEMI JOIN的限制是，右边的表只能在连接条件(on -子句)中引用，而不能在WHERE子句或select 子句等中引用。例如：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.key, a.value</span><br><span class="line"><span class="keyword">FROM</span> a</span><br><span class="line"><span class="keyword">WHERE</span> a.key <span class="keyword">in</span></span><br><span class="line"> (<span class="keyword">SELECT</span> b.key</span><br><span class="line">  <span class="keyword">FROM</span> B);</span><br></pre></td></tr></table></figure>

<p>可以被写为：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.key, a.val</span><br><span class="line"><span class="keyword">FROM</span> a <span class="keyword">LEFT</span> SEMI <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>如果参与连接的表(除了一个以外)都很小，那么连接可以写成一个仅有map的连接，下面的查询</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ MAPJOIN(b) */</span> a.key, a.value</span><br><span class="line"><span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> a.key <span class="operator">=</span> b.key</span><br></pre></td></tr></table></figure>

<p>不需要reducer。因为对于每一个A的映射，B都会整个儿地读一遍。这样做的限制就是无法实现 a FULL&#x2F;RIGHT OUTER JOIN b。</p>
</li>
</ul>
<p><strong>！！！！！！MAPJOIN知识待补充！！！！！！！！</strong></p>
<ul>
<li><p>如果连接表的连接列是时分桶列，并且一个表中的桶数是另一个表中的桶数的倍数，那么这些桶可以相互联接。假如表A有四个分桶，表B也有四个分桶，下面的连接：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ MAPJOIN(b) */</span> a.key, a.value</span><br><span class="line"><span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> a.key <span class="operator">=</span> b.key</span><br></pre></td></tr></table></figure>

<p>只能通过映射器mapper来完成。只需获取需要的桶，而不必为了A的每个映射器来完全获取B。拿上面的查询来说，处理A的桶1的映射器将只获取b的桶1，这种行为不是默认的，而是由以下的参数来控制的：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapjoin <span class="operator">=</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>如果两个表的连接列被用来分类sort和分桶，并且它们有相同数量的桶，则可以执行排序-合并连接(sort-merge)。对应的桶将在映射器上互相连接，如果A和B都有四个桶：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ MAPJOIN(b) */</span> a.key, a.value</span><br><span class="line"><span class="keyword">FROM</span> A a <span class="keyword">JOIN</span> B b <span class="keyword">ON</span> a.key <span class="operator">=</span> b.key</span><br></pre></td></tr></table></figure>

<p>上面的查询只能通过映射器来实现。A桶的映射器将会遍历B桶。这也不是默认行为，需要进行如下设置：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.input.format<span class="operator">=</span>org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;</span><br><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapjoin <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapjoin.sortedmerge <span class="operator">=</span> <span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="MapJoin的限制"><a href="#MapJoin的限制" class="headerlink" title="MapJoin的限制"></a>MapJoin的限制</h4><ul>
<li><p>如果参与连接的表(除了一个以外)都很小，那么连接可以写成一个仅有map的连接，下面的查询</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ MAPJOIN(b) */</span> a.key, a.value</span><br><span class="line"><span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> a.key <span class="operator">=</span> b.key</span><br></pre></td></tr></table></figure>

<p>不需要reducer。因为对于每一个A的映射，B都会被完整地读一遍。</p>
</li>
<li><p>以下是一些不受支持的行为：</p>
<ul>
<li>Union后接MapJoin</li>
<li>Lateral View后接MapJoin</li>
<li>Reduce Sink (Group By&#x2F;Join&#x2F;Sort By&#x2F;Cluster By&#x2F;Distribute By) 后接MapJoin</li>
<li>MapJoin后接Union</li>
<li>MapJoin后接Join</li>
<li>MapJoin后接MapJoin</li>
</ul>
</li>
<li><p>在一般情况下，配置变量<code>hive.auto.convert.join</code>如果为true，运行时joins操作将会自动转换为mapjoins操作，应以此种方式代替上面的mapjoins提示使用方法，mapjoins提示只能用于以下的查询方式：</p>
<ul>
<li>如果输入是分桶或者分类的，join应该转换为分桶的map-side join 或者分桶的 sort-merge join.</li>
</ul>
</li>
<li><p>考虑一种多个mapjoin在不同key上的可能情况：</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+MAPJOIN(smallTableTwo)*/</span> idOne, idTwo, <span class="keyword">value</span> <span class="keyword">FROM</span></span><br><span class="line">  ( <span class="keyword">select</span> <span class="comment">/*+MAPJOIN(smallTableOne)*/</span> idOne, idTwo, <span class="keyword">value</span> <span class="keyword">FROM</span></span><br><span class="line">    bigTable <span class="keyword">JOIN</span> smallTableOne <span class="keyword">on</span> (bigTable.idOne <span class="operator">=</span> smallTableOne.idOne)                                                  </span><br><span class="line">  ) firstjoin                                                            </span><br><span class="line">  <span class="keyword">JOIN</span>                                                                 </span><br><span class="line">  smallTableTwo <span class="keyword">ON</span> (firstjoin.idTwo <span class="operator">=</span> smallTableTwo.idTwo)   </span><br></pre></td></tr></table></figure>

<p><em><strong>下面三段来自机器翻译</strong></em> </p>
<p>不支持上述查询。如果没有mapjoin提示，上面的查询将作为2个只包含map的作业执行。如果用户事先知道输入足够小，可以放入内存中，那么可以使用以下可配置参数来确保查询在单个map-reduce作业中执行。</p>
<ul>
<li><p>Hive .auto.convert.join.noconditionaltask - Hive是否根据输入文件大小对普通连接转换为mapjoin进行优化。如果该参数是开启的，并且n-1个表&#x2F;分区的大小之和小于指定的大小，则连接将直接转换为mapjoin(没有条件任务)。</p>
</li>
<li><p>hive.auto.convert.join.noconditionaltask.size—如果hive.auto.convert.join.noconditionaltask是关闭的，则该参数不生效。但是，如果它是开启的，并且n-1个表&#x2F;分区的大小之和小于这个大小，那么这个连接将直接转换为映射连接(没有条件任务)。默认是10MB。</p>
</li>
</ul>
<h3 id="1-12-jion优化（暂不研究）"><a href="#1-12-jion优化（暂不研究）" class="headerlink" title="1.12 jion优化（暂不研究）"></a>1.12 jion优化（暂不研究）</h3><h4 id="1-12-1-Hive优化器的改进"><a href="#1-12-1-Hive优化器的改进" class="headerlink" title="1.12.1 Hive优化器的改进"></a>1.12.1 Hive优化器的改进</h4><p>版本信息：</p>
<blockquote>
<p>join优化自Hive 0.11.0开始引入。</p>
</blockquote>
<p>Hive自动识别变量的使用场景并优化它们，Hive 0.11版本起，优化器在一下情形中做出了改进：</p>
<blockquote>
</blockquote>
<h3 id="1-13-联合-Union"><a href="#1-13-联合-Union" class="headerlink" title="1.13 联合(Union)"></a>1.13 联合(Union)</h3><ul>
<li>Union语法</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select_statement <span class="keyword">UNION</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_statement <span class="keyword">UNION</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_statement ...</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<blockquote>
<p>Union用于将多个select语句的结果联合成一个结果集。</p>
<ul>
<li>1.2.0之前的Hive版本仅支持UNION ALL,不排除重复行。</li>
<li>在Hive 1.2.0及之后，UNION默认将重复行从结果集中移除。可选关键字DISTINCT和这种默认情形没有区别，因为它也是确认和移除重复行。如果带有可选关键字ALL，重复行不再移除，结果集中包含所有select语句的所有匹配行。</li>
</ul>
<p>可以将UNION ALL 和 UNION DISTINCT在同一个查询中混合使用。在混合的Union类型中，DISTINCT union 会把它左边的 ALL union都覆盖掉。</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/4/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Powered by Hackertaizi</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">170k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">5:09</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
