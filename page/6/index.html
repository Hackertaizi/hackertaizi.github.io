<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hackertaizi.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.1","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="太子的个人博客">
<meta property="og:url" content="https://hackertaizi.github.io/page/6/index.html">
<meta property="og:site_name" content="太子的个人博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Taizi">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://hackertaizi.github.io/page/6/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/6/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>太子的个人博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">太子的个人博客</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Have a nice day !</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/categories/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Taizi</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">64</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">40</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/Hadoop/Hive/Hive%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/" class="post-title-link" itemprop="url">Hive文件格式</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:32:56" itemprop="dateModified" datetime="2023-09-27T18:32:56+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive-文件格式"><a href="#Hive-文件格式" class="headerlink" title="Hive 文件格式"></a>Hive 文件格式</h1><h2 id="一、-ORC-Files"><a href="#一、-ORC-Files" class="headerlink" title="一、 ORC Files"></a>一、 ORC Files</h2><h3 id="1-ORC文件格式概述"><a href="#1-ORC文件格式概述" class="headerlink" title="1. ORC文件格式概述"></a>1. ORC文件格式概述</h3><p>ORC(<em>Optimized Row Columnar</em>)文件格式提供了一种非常高效的方式来存储hive数据。它旨在克服其他Hive文件格式的限制。使用ORC文件可以提升Hive在读、写、处理数据时的性能。</p>
<p>以RCFile 格式做比较，ORC文件格式有许多有优点，例如：</p>
<blockquote>
<ul>
<li><p>单个文件作为每个任务的输出，这减少了NameNode的负载 .</p>
</li>
<li><p>Hive类型支持datetime,decimal,以及一些复杂类型（struct, list, map, and union）.</p>
</li>
<li><p>文件中存储了轻量级的索引：</p>
<ul>
<li>跳过那些没有通过谓词筛选的行组</li>
<li>查询给定行</li>
</ul>
</li>
<li><p>基于数据类型的块模式压缩 </p>
</li>
<li><p>Integer类型的列用行程长度编码(Run Length Encoding)</p>
</li>
<li><p>String类型的列用字典编码(Dictionary Encoding)；</p>
</li>
<li><p>使用单独的RecordReader并发读取同一文件 </p>
</li>
<li><p>无需扫描标记即可拆分文件 </p>
</li>
<li><p>绑定读写所需的内存量 </p>
</li>
<li><p>使用协议缓冲区存储元数据，允许添加和删除字段</p>
</li>
</ul>
</blockquote>
<h3 id="2-ORC文件结构"><a href="#2-ORC文件结构" class="headerlink" title="2. ORC文件结构"></a>2. ORC文件结构</h3><p>ORC文件包含一组称为条纹(<strong>stripes</strong>)的行数据，以及FileFooter中的辅助信息。在文件末尾，postscript保存压缩参数和压缩页脚的大小。</p>
<p>默认的 stripes 大小为250MB，大的stripes使得Hive能够对HDFS进行高效的读取。</p>
<p>FileFooter包含文件中的stripes列表、每个stripes的行数以及每列的数据类型。它还包含了列级聚合count、min、max和sum。 </p>
<p>下图说明了ORC文件结构： </p>
<p><img src="/Hadoop/Hive/Hive%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/.%5CHive%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%5Cimage-20220530141339875.png" alt="image-20220530141339875"></p>
<h3 id="3-Stripe结构："><a href="#3-Stripe结构：" class="headerlink" title="3. Stripe结构："></a>3. Stripe结构：</h3><p>从上图可以看出，ORC文件中的每个stripe都包括索引数据(Index Data)、行数据(Row Data)以及Stripe Footer。</p>
<p><code>Stripe Footer</code>包含了流数据位置的目录，<code>Row Data</code>则用于表的扫描。</p>
<p><code>Index data</code>中包含了每一列中的最大和最小值，以及每列所在的行（还可以包括位字段或布隆过滤器），行索引里面提供了偏移量，它可以跳到正确的压缩块位置以及解压缩块的字节位置。请注意，ORC索引仅用于选择 <code>Stripe</code> 和行组，而不用于查询。</p>
<p>Stripe中具有相对频繁的行索引、能够跳过行来进行快速读取，尽管Stripe很大。默认情况下最大可以跳过10000行。</p>
<p>通过谓词筛选器跳过大量行集，你可以使用表的第二主键来进行分类从而减少大量的执行时间。例如，你的表的主分区是交易日期，那么你可以在 state、zip code以及last name 上进行排序。然后在一个 state 中查找记录将跳过所有其他 state 的记录。</p>
<h3 id="4-使用语法"><a href="#4-使用语法" class="headerlink" title="4. 使用语法"></a>4. 使用语法</h3><p>文件类型是在表级（或分区级）上确定的，通过HiveQL,你可以将文件形式定义为ORC,例如：</p>
<ul>
<li><code>CREATE TABLE ... STORED AS ORC</code></li>
<li><code>ALTER TABLE ... [PARTITION partition_spec] SET FILEFORMAT ORC</code></li>
<li><code>SET hive.default.fileformat=ORC</code></li>
</ul>
<p><strong>高级设置：</strong></p>
<p>下面的参数都被放在 <code>TBLPROPERTIES </code>中:</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Default</th>
<th>Notes</th>
</tr>
</thead>
<tbody><tr>
<td>orc.bloom.filter.columns</td>
<td>“”</td>
<td>comma separated list of column names for which bloom filter should be created<br>应为其创建bloom筛选器的列名的逗号分隔列表</td>
</tr>
<tr>
<td>orc.bloom.filter.fpp</td>
<td>0.05</td>
<td>false positive probability for bloom filter (must &gt;0.0 and &lt;1.0)<br>布隆过滤器的误报概率，大小在0和1之间</td>
</tr>
<tr>
<td>orc.compress</td>
<td>ZLIB</td>
<td>high level compression (one of NONE, ZLIB, SNAPPY)<br>高级压缩，为表指定压缩算法，默认为ZLIB</td>
</tr>
<tr>
<td>orc.compress.size</td>
<td>262,144</td>
<td>number of bytes in each compression chunk<br>每个压缩区块包含的字节数</td>
</tr>
<tr>
<td>orc.create.index</td>
<td>true</td>
<td>whether to create row indexes<br>是否要创建行索引</td>
</tr>
<tr>
<td>orc.row.index.stride</td>
<td>10,000</td>
<td>number of rows between index entries (must be &gt;&#x3D; 1000)<br>索引项之间的行数，必须大于1000</td>
</tr>
<tr>
<td>orc.stripe.size</td>
<td>67,108,864</td>
<td>number of bytes in each stripe<br>每个stripe包含的字节数</td>
</tr>
</tbody></table>
<p>例如，创建一个不带压缩方式的ORC存储的表：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> Addresses (</span><br><span class="line">  name string,</span><br><span class="line">  street string,</span><br><span class="line">  city string,</span><br><span class="line">  state string,</span><br><span class="line">  zip <span class="type">int</span></span><br><span class="line">) stored <span class="keyword">as</span> orc tblproperties (&quot;orc.compress&quot;<span class="operator">=</span>&quot;NONE&quot;);</span><br></pre></td></tr></table></figure>

<h3 id="5-序列化-Serialization-和压缩-Compression"><a href="#5-序列化-Serialization-和压缩-Compression" class="headerlink" title="5. 序列化(Serialization )和压缩(Compression)"></a>5. 序列化(Serialization )和压缩(Compression)</h3><h4 id="5-1-序列化"><a href="#5-1-序列化" class="headerlink" title="5.1 序列化"></a>5.1 序列化</h4><p>ORC 文件中的序列化取决于列数据是否为Integer或者String类型的。</p>
<ul>
<li>Integer列的序列化：</li>
</ul>
<blockquote>
<p>Integer 列在两个流中序列化：</p>
<ol>
<li>当前位流：值是否非空？</li>
<li>数据流：Integers流</li>
</ol>
<p>整形数据的序列化方式采用了数字常见分布的优点：</p>
<ul>
<li>整数编码才用可变宽度编码，这使得小整形数字占用更少的字节</li>
<li>重复值采用行程编码（Run-Length Encoding，RLE）</li>
<li>在-128到127范围内的常数使用的是行程编码</li>
</ul>
</blockquote>
<p>知识拓展：</p>
<p>可变宽度编码（<em>variable-width encoding</em>）<strong>待补充</strong></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">可变宽度编码基于Google的协议缓冲区，并使用高位表示该字节是否不是编码数据的最后一位和低位7位来编码。为了对附属进行编码，0, -1, 1, -2, 和 2 被映射为 0, 1, 2, 3, 4, 和 5 respectively.</span><br><span class="line"></span><br><span class="line">每个集合中的数是按以下方式编码的：</span><br><span class="line"><span class="emphasis">*如果第一个字节b0是负数：</span></span><br><span class="line"><span class="emphasis">	*</span> b0后是可变长度整数</span><br><span class="line"><span class="emphasis">*如果第一个字节b0是正数：</span></span><br><span class="line"><span class="emphasis">	</span></span><br><span class="line"><span class="emphasis"></span></span><br></pre></td></tr></table></figure>



<p>行程编码（<em>Run-Length Encoding</em>，RLE）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">行程编码（RLE）是一种无损数据压缩形式，其中数据的runs（即，在许多连续数据元素中出现相同数据值的序列）被存储为单个数据值和计数，而不是原来的runs。这对包含许多此类runs的数据最有用。例如，考虑简单的图形图像，如图标，线条图。它对于没有很多runs的文件没有用，因为它可能会大大增加文件大小。</span><br><span class="line">例如，考虑在纯白色背景上包含纯黑色文本的屏幕。空白区域中会有很多长白色像素，文本中会有很多短黑色像素。假设的扫描线，B代表黑色像素，W代表白色，可能如下所示：</span><br><span class="line"></span><br><span class="line">WWWWWWWWWWWWBWWWWWWWWWWWWBBBWWWWWWWWWWWWWWWWWWWWWWWWBWWWWWWWWWWWWWW</span><br><span class="line"></span><br><span class="line">通过应用于上述假设扫描线的行程编码（RLE）数据压缩算法，可以如下呈现：</span><br><span class="line"></span><br><span class="line">12W1B12W3B24W1B14W</span><br><span class="line"></span><br><span class="line">这可以解释为12个W,1个B，12个W，3个B，24个W，1个B，14个W的序列。</span><br></pre></td></tr></table></figure>

<ul>
<li>String列的序列化</li>
</ul>
<blockquote>
<p>字符串列的序列化使用字典来形成唯一的列值。对字典进行排序以加快谓词过滤并提高压缩比。</p>
<p>String 列在四个流中序列化：</p>
<ol>
<li>当前位流：值是否非空？</li>
<li>字典数据：字符串的字节数</li>
<li>字典长度：每个条目的长度</li>
<li>行数据：行中的数据</li>
</ol>
<p>字典长度和行数据都是Integer中的行程编码。</p>
</blockquote>
<h4 id="5-2-压缩"><a href="#5-2-压缩" class="headerlink" title="5.2 压缩"></a>5.2 压缩</h4><p>流使用编解码器进行压缩，编解码器被指定为该表中所有流的表属性。为了优化内存的使用，压缩是在每个块生成的时候以增量的方式进行的。可以直接跳过压缩块，而无需先解压再扫描。流中的位置使用块的开始位置和块中的偏移来表示。</p>
<p>编码解码器可以是Snappy，Zlib，或者none。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/Hadoop/Hive/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E8%AF%AD%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E8%AF%AD%E6%B3%95/" class="post-title-link" itemprop="url">Hive基本语法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:27:55" itemprop="dateModified" datetime="2023-09-27T18:27:55+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>25 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive-基本语法"><a href="#Hive-基本语法" class="headerlink" title="Hive 基本语法"></a>Hive 基本语法</h1><h2 id="一、DDL"><a href="#一、DDL" class="headerlink" title="一、DDL"></a>一、DDL</h2><h3 id="1-数据库操作"><a href="#1-数据库操作" class="headerlink" title="1. 数据库操作"></a>1. 数据库操作</h3><h4 id="1-1-创建数据库"><a href="#1-1-创建数据库" class="headerlink" title="1.1 创建数据库"></a>1.1 创建数据库</h4><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [REMOTE] (DATABASE<span class="operator">|</span>SCHEMA) [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] database_name</span><br><span class="line">  [COMMENT database_comment]<span class="comment">-- 数据库注释信息</span></span><br><span class="line">  [LOCATION hdfs_path] <span class="comment">-- 内部表数据存储路径 在hive4.0版本一下内外部表都用此命令设置存储路径</span></span><br><span class="line">  [MANAGEDLOCATION hdfs_path] <span class="comment">-- 外部表存储路径 hive4.0版本后可用</span></span><br><span class="line">  [<span class="keyword">WITH</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]; <span class="comment">-- 指派自定义属性</span></span><br></pre></td></tr></table></figure>

<p><strong>自己指定的的位置的话,在hdfs上面生成的数据库路径文件夹是没有.db,使用默认路径生成的数据库路径文件夹有.db</strong></p>
<p>具体实例如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> shopping</span><br><span class="line">COMMENT `stores <span class="keyword">all</span> shopping basket data`</span><br><span class="line">LOCATION `<span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>retail<span class="operator">/</span>hive<span class="operator">/</span>SHOPPING.db`</span><br><span class="line"><span class="keyword">WITH</span> PROPERTIES (<span class="string">&#x27;purpose&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testing&#x27;</span>);</span><br></pre></td></tr></table></figure>

<h4 id="1-2-删除数据库"><a href="#1-2-删除数据库" class="headerlink" title="1.2 删除数据库"></a>1.2 删除数据库</h4><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> (DATABASE<span class="operator">|</span>SCHEMA) [IF <span class="keyword">EXISTS</span>] database_name [RESTRICT<span class="operator">|</span>CASCADE];</span><br></pre></td></tr></table></figure>

<blockquote>
<p>若选择RESTRICT，该表的删除是有限制条件的。该表不能被其他表的约束所引用（如CHECK，FOREIGN KEY等约束），不能有触发器，不能有视图，不能有函数和存储过程等。如果该表存在这些依赖的对象，此表不能删除。	</p>
<p>若选择CASCADE，该表的删除没有限制条件。在删除基本表的同时，相关的依赖对象将会被一起删除。<br>​</p>
<p>默认是RESTRICT</p>
</blockquote>
<h4 id="1-3-修改数据库"><a href="#1-3-修改数据库" class="headerlink" title="1.3 修改数据库"></a>1.3 修改数据库</h4><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...);   <span class="comment">-- (<span class="doctag">Note:</span> SCHEMA added in Hive 0.14.0) 修改元数据属性</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> OWNER [<span class="keyword">USER</span><span class="operator">|</span>ROLE] user_or_role;   <span class="comment">-- (<span class="doctag">Note:</span> Hive 0.13.0 and later; SCHEMA added in Hive 0.14.0) 修改所有者</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> LOCATION hdfs_path; <span class="comment">-- (<span class="doctag">Note:</span> Hive 2.2.1, 2.4.0 and later) 修改数据存储路径</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> MANAGEDLOCATION hdfs_path; <span class="comment">-- (<span class="doctag">Note:</span> Hive 4.0.0 and later) </span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>DATABASE|SCHEMA (数据库|架构)，创建时二选一即可，这里它们是同义的。</p>
</blockquote>
<h4 id="1-4-选择数据库"><a href="#1-4-选择数据库" class="headerlink" title="1.4 选择数据库"></a>1.4 选择数据库</h4><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">USE database_name;</span><br><span class="line">USE <span class="keyword">DEFAULT</span>;</span><br></pre></td></tr></table></figure>



<h3 id="2-数据表操作"><a href="#2-数据表操作" class="headerlink" title="2. 数据表操作"></a>2. 数据表操作</h3><h4 id="2-1-创建表"><a href="#2-1-创建表" class="headerlink" title="2.1 创建表"></a>2.1 创建表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [TEMPORARY] [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name    <span class="comment">-- (<span class="doctag">Note:</span> TEMPORARY available in Hive 0.14.0 and later)</span></span><br><span class="line">  [(col_name data_type [column_constraint_specification] [COMMENT col_comment], ... [constraint_specification])]</span><br><span class="line">  [COMMENT table_comment]</span><br><span class="line">  [PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">  [CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) [SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] </span><br><span class="line">   <span class="keyword">INTO</span> num_buckets BUCKETS]</span><br><span class="line">  [SKEWED <span class="keyword">BY</span> (col_name, col_name, ...) ]<span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.10.0 and later)</span></span><br><span class="line">   <span class="keyword">ON</span> ((col_value, col_value, ...), (col_value, col_value, ...), ...) </span><br><span class="line">  [STORED <span class="keyword">AS</span> DIRECTORIES]</span><br><span class="line">  [</span><br><span class="line">   [<span class="type">ROW</span> FORMAT row_format] </span><br><span class="line">   [STORED <span class="keyword">AS</span> file_format]</span><br><span class="line">     <span class="operator">|</span> STORED <span class="keyword">BY</span> <span class="string">&#x27;storage.handler.class.name&#x27;</span> [<span class="keyword">WITH</span> SERDEPROPERTIES (...)]  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.6.0 and later)</span></span><br><span class="line">  ]</span><br><span class="line">  [LOCATION hdfs_path]</span><br><span class="line">  [TBLPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.6.0 and later)</span></span><br><span class="line">  [<span class="keyword">AS</span> select_statement];   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.5.0 and later; not supported for external tables)</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">CREATE</span> [TEMPORARY] [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name</span><br><span class="line">  <span class="keyword">LIKE</span> existing_table_or_view_name</span><br><span class="line">  [LOCATION hdfs_path];</span><br><span class="line"> </span><br><span class="line">data_type</span><br><span class="line">  : primitive_type</span><br><span class="line">  <span class="operator">|</span> array_type</span><br><span class="line">  <span class="operator">|</span> map_type</span><br><span class="line">  <span class="operator">|</span> struct_type</span><br><span class="line">  <span class="operator">|</span> union_type  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.7.0 and later)</span></span><br><span class="line"> </span><br><span class="line">primitive_type</span><br><span class="line">  : TINYINT</span><br><span class="line">  <span class="operator">|</span> <span class="type">SMALLINT</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">INT</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">BIGINT</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">BOOLEAN</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">FLOAT</span></span><br><span class="line">  <span class="operator">|</span> <span class="keyword">DOUBLE</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">DOUBLE PRECISION</span> <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 2.2.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> STRING</span><br><span class="line">  <span class="operator">|</span> <span class="type">BINARY</span>      <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.8.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">TIMESTAMP</span>   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.8.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">DECIMAL</span>     <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.11.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">DECIMAL</span>(<span class="keyword">precision</span>, scale)  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">DATE</span>        <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.12.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">VARCHAR</span>     <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.12.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> <span class="type">CHAR</span>        <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13.0 and later)</span></span><br><span class="line"> </span><br><span class="line">array_type</span><br><span class="line">  : <span class="keyword">ARRAY</span> <span class="operator">&lt;</span> data_type <span class="operator">&gt;</span></span><br><span class="line"> </span><br><span class="line">map_type</span><br><span class="line">  : MAP <span class="operator">&lt;</span> primitive_type, data_type <span class="operator">&gt;</span></span><br><span class="line"> </span><br><span class="line">struct_type</span><br><span class="line">  : STRUCT <span class="operator">&lt;</span> col_name : data_type [COMMENT col_comment], ...<span class="operator">&gt;</span></span><br><span class="line"> </span><br><span class="line">union_type</span><br><span class="line">   : UNIONTYPE <span class="operator">&lt;</span> data_type, data_type, ... <span class="operator">&gt;</span>  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.7.0 and later)</span></span><br><span class="line"> </span><br><span class="line">row_format</span><br><span class="line">  : DELIMITED [FIELDS TERMINATED <span class="keyword">BY</span> <span class="type">char</span> [ESCAPED <span class="keyword">BY</span> <span class="type">char</span>]] [COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>]</span><br><span class="line">        [MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] [LINES TERMINATED <span class="keyword">BY</span> <span class="type">char</span>]</span><br><span class="line">        [<span class="keyword">NULL</span> DEFINED <span class="keyword">AS</span> <span class="type">char</span>]   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13 and later)</span></span><br><span class="line">  <span class="operator">|</span> SERDE serde_name [<span class="keyword">WITH</span> SERDEPROPERTIES (property_name<span class="operator">=</span>property_value, property_name<span class="operator">=</span>property_value, ...)]</span><br><span class="line"> </span><br><span class="line">file_format:</span><br><span class="line">  : SEQUENCEFILE</span><br><span class="line">  <span class="operator">|</span> TEXTFILE    <span class="comment">-- (Default, depending on hive.default.fileformat configuration)</span></span><br><span class="line">  <span class="operator">|</span> RCFILE      <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.6.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> ORC         <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.11.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> PARQUET     <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> AVRO        <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.14.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> JSONFILE    <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 4.0.0 and later)</span></span><br><span class="line">  <span class="operator">|</span> INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname</span><br><span class="line"> </span><br><span class="line">column_constraint_specification:</span><br><span class="line">  : [ <span class="keyword">PRIMARY</span> KEY<span class="operator">|</span><span class="keyword">UNIQUE</span><span class="operator">|</span><span class="keyword">NOT</span> <span class="keyword">NULL</span><span class="operator">|</span><span class="keyword">DEFAULT</span> [default_value]<span class="operator">|</span><span class="keyword">CHECK</span>  [check_expression] ENABLE<span class="operator">|</span>DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br><span class="line"> </span><br><span class="line">default_value:</span><br><span class="line">  : [ LITERAL<span class="operator">|</span><span class="built_in">CURRENT_USER</span>()<span class="operator">|</span><span class="built_in">CURRENT_DATE</span>()<span class="operator">|</span><span class="built_in">CURRENT_TIMESTAMP</span>()<span class="operator">|</span><span class="keyword">NULL</span> ] </span><br><span class="line"> </span><br><span class="line">constraint_specification:</span><br><span class="line">  : [, <span class="keyword">PRIMARY</span> KEY (col_name, ...) DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br><span class="line">    [, <span class="keyword">PRIMARY</span> KEY (col_name, ...) DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br><span class="line">    [, <span class="keyword">CONSTRAINT</span> constraint_name <span class="keyword">FOREIGN</span> KEY (col_name, ...) <span class="keyword">REFERENCES</span> table_name(col_name, ...) DISABLE NOVALIDATE </span><br><span class="line">    [, <span class="keyword">CONSTRAINT</span> constraint_name <span class="keyword">UNIQUE</span> (col_name, ...) DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br><span class="line">    [, <span class="keyword">CONSTRAINT</span> constraint_name <span class="keyword">CHECK</span> [check_expression] ENABLE<span class="operator">|</span>DISABLE NOVALIDATE RELY<span class="operator">/</span>NORELY ]</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>对几个关键点说明</strong><br>a) temporary 创建临时表，只在本次回话生效<br>b) external关键字，加上这个关键字建的表是外部表，不加这个关键字建的表就是内部表<br>    内部表和外部表的区别：<br>    (1）概念本质上<br>    内部表数据自己的管理的在进行表删除时数据和元数据一并删除。<br>    外部表只是对HDFS的一个目录的数据进行关联，外部表在进行删除时只删除元数据，原始数据是不会被删除的。<br>    (2）应用场景上<br>    外部表一般用于存储原始数据、公共数据，内部表一般用于存储某一个模块的中间结果数据。<br>    (3）存储目录上<br>    外部表：一般在进行建表时候需要手动指定表的数据目录为共享资源目录，用lication关键字指定。<br>    内部表：无严格的要求，一般使用的默认目录。<br>c) partitioned by 指定分区字段<br>    partitioned by（分区字段名 分区字段类型 COMMENT 字段描述信息）<br>    注意：分区字段一定不能存在于建表字段中。<br>d) [row format row_format] 指定分割符的<br>    fields terminated by 列分割符<br>    lines terminated by 行分割符<br>    map keys terminated by<br>e) [stored as AS file_format] 指定原始数据的存储格式<br>    textfile 文本格式 默认的方式<br>    cfile 行列格式， 在行的方向切分数据的存储的块 保证一行数据在一个数据块中，每列个块中存储的时候 进行划分存储的。<br>    SequenceFile 二进制存储格式</p>
</blockquote>
<h4 id="2-2-删除表"><a href="#2-2-删除表" class="headerlink" title="2.2 删除表"></a>2.2 删除表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> [IF <span class="keyword">EXISTS</span>] table_name [PURGE];     <span class="comment">-- (<span class="doctag">Note:</span> PURGE available in Hive 0.14.0 and later)</span></span><br></pre></td></tr></table></figure>

<h4 id="2-3-截断表（删除表的所有行，即清空表）"><a href="#2-3-截断表（删除表的所有行，即清空表）" class="headerlink" title="2.3 截断表（删除表的所有行，即清空表）"></a>2.3 截断表（删除表的所有行，即清空表）</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">TRUNCATE</span> [<span class="keyword">TABLE</span>] table_name [<span class="keyword">PARTITION</span> partition_spec];</span><br><span class="line"> </span><br><span class="line">partition_spec:</span><br><span class="line">  : (partition_column <span class="operator">=</span> partition_col_value, partition_column <span class="operator">=</span> partition_col_value, ...)</span><br></pre></td></tr></table></figure>

<h4 id="2-4-修改表"><a href="#2-4-修改表" class="headerlink" title="2.4 修改表"></a>2.4 修改表</h4><h5 id="2-4-1-重命名"><a href="#2-4-1-重命名" class="headerlink" title="2.4.1 重命名"></a>2.4.1 重命名</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name RENAME <span class="keyword">TO</span> new_table_name;</span><br></pre></td></tr></table></figure>

<h5 id="2-4-2-修改表属性"><a href="#2-4-2-修改表属性" class="headerlink" title="2.4.2 修改表属性"></a>2.4.2 修改表属性</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">SET</span> TBLPROPERTIES table_properties;</span><br><span class="line"> </span><br><span class="line">table_properties:</span><br><span class="line">  : (property_name <span class="operator">=</span> property_value, property_name <span class="operator">=</span> property_value, ... )</span><br></pre></td></tr></table></figure>

<h5 id="2-4-3-修改表注释"><a href="#2-4-3-修改表注释" class="headerlink" title="2.4.3 修改表注释"></a>2.4.3 修改表注释</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">SET</span> TBLPROPERTIES (<span class="string">&#x27;comment&#x27;</span> <span class="operator">=</span> new_comment);</span><br></pre></td></tr></table></figure>

<h5 id="2-4-4-添加正则表达式过滤属性"><a href="#2-4-4-添加正则表达式过滤属性" class="headerlink" title="2.4.4 添加正则表达式过滤属性"></a>2.4.4 添加正则表达式过滤属性</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> partition_spec] <span class="keyword">SET</span> SERDE serde_class_name [<span class="keyword">WITH</span> SERDEPROPERTIES serde_properties];</span><br><span class="line"> </span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> partition_spec] <span class="keyword">SET</span> SERDEPROPERTIES serde_properties;</span><br><span class="line"> </span><br><span class="line">serde_properties:</span><br><span class="line">  : (property_name <span class="operator">=</span> property_value, property_name <span class="operator">=</span> property_value, ... )</span><br></pre></td></tr></table></figure>

<h5 id="2-4-5-删除正则表达式过滤属性"><a href="#2-4-5-删除正则表达式过滤属性" class="headerlink" title="2.4.5 删除正则表达式过滤属性"></a>2.4.5 删除正则表达式过滤属性</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> partition_spec] UNSET SERDEPROPERTIES (property_name, ... );</span><br></pre></td></tr></table></figure>



<h2 id="二、DML"><a href="#二、DML" class="headerlink" title="二、DML"></a>二、DML</h2><h3 id="1-将文件导入数据表"><a href="#1-将文件导入数据表" class="headerlink" title="1. 将文件导入数据表"></a>1. 将文件导入数据表</h3><p>语法格式:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)]</span><br><span class="line"> </span><br><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] [INPUTFORMAT <span class="string">&#x27;inputformat&#x27;</span> SERDE <span class="string">&#x27;serde&#x27;</span>] (<span class="number">3.0</span> <span class="keyword">or</span> later)</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li><p>LOAD DATA ：数据导入关键字</p>
</li>
<li><p>关于LOCAL关键字</p>
</li>
</ul>
<blockquote>
<p>LOCAL 关键字：如果指定了 LOCAL， LOAD 命令会去查找本地文件系统中的 filepath。如果没有指定 LOCAL 关键字，则根据 inpath 中的 uri 查找文件。<br>注意：uri 是指 hdfs 上的路径，分简单模式和完整模式两种，例如：</p>
<ul>
<li>简单模式：&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
<li>完整模式：hdfs:&#x2F;&#x2F;namenode_host:9000&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
</ul>
</blockquote>
<ul>
<li>关于文件路径 filepath</li>
</ul>
<blockquote>
<p>在hive3.0之前，文件导入操作是通过单纯的复制&#x2F;移动的方式来将数据文件导入路径下的数据表中，其中，文件路径可以是以下几种形式：</p>
<ul>
<li><p>相对路径，如<code>project/data1</code></p>
</li>
<li><p>绝对路径，如<code>/user/hive/project/data1</code></p>
</li>
<li><p>带有模式和权限(可选)的完整URI，如<code>hdfs://namenode:9000/user/hive/project/data1</code></p>
</li>
</ul>
<p>文件路径可以具体到某个要导入的文件，也可以是某个目录(文件夹)，如果是目录，hive会将目录下的所有文件导入表中。</p>
</blockquote>
<ul>
<li>关于导入表的类型</li>
</ul>
<blockquote>
<p>接收导入数据的表可以是一个已有表或者分区表，如果表是分区表，则必须指定分区字段内所有属性(列)的值。也可以使用 </p>
<p>CREATE TABLE 在导入时创建导入表。</p>
</blockquote>
<ul>
<li>输入格式控制(Hive 3.0之后可用)</li>
</ul>
<blockquote>
<p>输入格式(inputformat)可以是hive 的任何输入格式，如text、ORC等。</p>
<p>serde可以是关联的配置单元serde。</p>
<p>inputformat和serde都区分大小写</p>
</blockquote>
<ul>
<li>其他加载操作</li>
</ul>
<blockquote>
<p>Hive 3.0及更高版本中，除了移动复制操作之外，还支持其他加载操作，因为Hive在内部在某些场合下会将加载重写为<strong>INSERT AS SELECT</strong>。<br>比如，如果表具有分区，而load命令没有指定分区，则将load转换为INSERT AS SELECT，并假定最后一组列为分区列。如果文件不符合预期的架构，它将引发错误。</p>
</blockquote>
<p>注意：</p>
<ul>
<li><p>文件路径下不能包含有子目录，即如果指定的文件路径是一个目录，该目录下不能包含子目录。</p>
</li>
<li><p>如果没有指定LOCAL关键字，则导入的文件必须与表在同一个文件系统下</p>
</li>
</ul>
<h3 id="2-通过查询语句将数据插入数据表（常用）"><a href="#2-通过查询语句将数据插入数据表（常用）" class="headerlink" title="2. 通过查询语句将数据插入数据表（常用）"></a>2. 通过查询语句将数据插入数据表（常用）</h3><h4 id="2-1-普通表和静态分区表的插入"><a href="#2-1-普通表和静态分区表的插入" class="headerlink" title="2.1 普通表和静态分区表的插入"></a>2.1 普通表和静态分区表的插入</h4><p>使用这种方式可以将查询结果插入数据表。</p>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Standard syntax:<span class="comment">-- 标准语法格式</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...) [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement1 <span class="keyword">FROM</span> from_statement;<span class="comment">-- 覆盖插入</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] select_statement1 <span class="keyword">FROM</span> from_statement; <span class="comment">-- 增量插入</span></span><br><span class="line"> </span><br><span class="line">Hive extension (multiple inserts):<span class="comment">-- hive拓展，多表插入</span></span><br><span class="line"><span class="keyword">FROM</span> from_statement</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...) [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement1</span><br><span class="line">[<span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ... [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement2]</span><br><span class="line">[<span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ...] select_statement2] ...;</span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> from_statement</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] select_statement1</span><br><span class="line">[<span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ...] select_statement2]</span><br><span class="line">[<span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ... [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement2] ...;</span><br><span class="line"> </span><br><span class="line">Hive extension (<span class="keyword">dynamic</span> <span class="keyword">partition</span> inserts): <span class="comment">-- hive拓展，动态分区插入</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename <span class="keyword">PARTITION</span> (partcol1[<span class="operator">=</span>val1], partcol2[<span class="operator">=</span>val2] ...) select_statement <span class="keyword">FROM</span> from_statement;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename <span class="keyword">PARTITION</span> (partcol1[<span class="operator">=</span>val1], partcol2[<span class="operator">=</span>val2] ...) select_statement <span class="keyword">FROM</span> from_statement;</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li>两种插入方式概述</li>
</ul>
<blockquote>
<p>INSERT OVERWRITE 方式插入数据会将表或者分区表中的信息清空覆盖，具体实现是先查找到要插入的数据，然后将表清空，最后插入数据</p>
<p>INSERT INTO 方式插入数据会在表或者分区表中添加增量信息，即不改变表中的原有数据，而是在后面添加。</p>
<p>在Hive 0.13.0之后，创建数据表时可以指定表属性TBLPROPERTIES(“immutable”&#x3D;”true”)，(immutable默认为false),这样表就是不可变的，如果一个不可变的表上有任何数据的话，INSERT INTO 方式插入数据不能在不可变的表上操作。但如果不可变的表是空的，则仍然可以通过INSERT INTO 方式插入数据。INSERT OVERWRITE 插入方式不受表的immutable属性限制。</p>
</blockquote>
<ul>
<li>IF NOT EXISTS 关键字</li>
</ul>
<blockquote>
<p>如果使用了该关键字，当数据插入时如果表不存在，会创建一个表；如果没有使用改关键字，当数据插入时如果表不存在，指令会执行失败。</p>
</blockquote>
<ul>
<li>分区表插入注意事项</li>
</ul>
<blockquote>
<p>可以向表或者分区表中插入数据，如果是分区表，插入时则必须指定所有分区字段的值，如果<code>hive.typecheck.on.insert</code>被设置为true,则hive会校验、转化、规范化这些值使它们符合列的类型。(Hive 0.12.0以后)</p>
</blockquote>
<ul>
<li>多表插入</li>
</ul>
<blockquote>
<p>多表插入的意思是可以在一个查询中指定多个INSERT语句，只需要扫描一遍源表。如果要使用覆盖的方法插入，OVERWRITE关键字是必须的，不是可选的。多表插入可最大限度地减少所需的数据扫描次数。Hive只需扫描输入数据一次（并对输入数据应用不同的查询运算符），即可将数据插入多个表中。</p>
<p><strong>多表插入时，如果目标表是普通表，则不能插入相同的表。</strong></p>
<p><strong>多表插入时，如果目标表是分区表，则插入的表不能是相同表的相同分区，可以是相同表的不通分区。</strong></p>
</blockquote>
<ul>
<li>输出格式</li>
</ul>
<blockquote>
<p>输出格式由表的元数据定义。</p>
</blockquote>
<blockquote>
<p>自Hive 0.14起，如果一个表的OutputFormat实现了AcidOutputFormat，并且系统配置为使用实现ACID的事务管理器，则该表的插入覆盖将被禁用。这是为了避免用户无意中覆盖事务历史记录。同样的功能也可以通过使用TRUNCATE TABLE（对于非分区表）或DROP PARTITION，然后INSERT INTO来实现。</p>
</blockquote>
<ul>
<li>其他</li>
</ul>
<blockquote>
<p>自Hive1.1.0开始，关键字TABLE 变成了可选的而不是必需的。</p>
</blockquote>
<blockquote>
<p>自Hive3.1.0起，不允许从数据源中使用UNION ALL对完整CRUD ACID表进行插入覆盖。</p>
</blockquote>
<h4 id="2-2-动态分区表的插入"><a href="#2-2-动态分区表的插入" class="headerlink" title="2.2 动态分区表的插入"></a>2.2 动态分区表的插入</h4><p>动态分区表插入时，动态分区列必须在select语句的最后进行指定，且指定顺序必须与partition中指定的先后顺序相同。从Hive3.0.0起，不需要指定动态分区列。</p>
<p>在Hive0.9.0之前，动态分区是默认不可用的，在Hive0.9.0之后，动态分区是默认可用的，以下是有关动态分区表的插入的一些属性配置：</p>
<table>
<thead>
<tr>
<th>配置属性</th>
<th>默认值</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>hive.exec.dynamic.partition</td>
<td>true</td>
<td>当动态分区表插入时需要被设置为true</td>
</tr>
<tr>
<td>hive.exec.dynamic.partition.mode</td>
<td>strict</td>
<td>在严格模式下，使用者必须确定至少一个静态分区来防止所有分区被意外覆盖，而在非严格模式下，所有分区都可以是动态的。</td>
</tr>
<tr>
<td>hive.exec.max.dynamic.partitions.pernode</td>
<td>100</td>
<td>在一个mapper&#x2F;reducer节点中允许创建的最大动态分区数</td>
</tr>
<tr>
<td>hive.exec.max.dynamic.partitions</td>
<td>1000</td>
<td>允许创建的最大动态分区总数</td>
</tr>
<tr>
<td>hive.exec.max.created.files</td>
<td>100000</td>
<td>在一个MapReduce任务中所有mappers&#x2F;reducers可以创建的最大HDFS文件数量总数</td>
</tr>
<tr>
<td>hive.error.on.empty.partition</td>
<td>false</td>
<td>如果动态分区插入结果为空是否抛出异常</td>
</tr>
</tbody></table>
<h3 id="3-通过查询将数据写入文件系统"><a href="#3-通过查询将数据写入文件系统" class="headerlink" title="3. 通过查询将数据写入文件系统"></a>3. 通过查询将数据写入文件系统</h3><p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Standard syntax: <span class="comment">-- 标准语法</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory1</span><br><span class="line">  [<span class="type">ROW</span> FORMAT row_format] [STORED <span class="keyword">AS</span> file_format] (Note: <span class="keyword">Only</span> available starting <span class="keyword">with</span> Hive <span class="number">0.11</span><span class="number">.0</span>)</span><br><span class="line">  <span class="keyword">SELECT</span> ... <span class="keyword">FROM</span> ...</span><br><span class="line"> </span><br><span class="line">Hive extension (multiple inserts): <span class="comment">-- hive拓展，多插入</span></span><br><span class="line"><span class="keyword">FROM</span> from_statement</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory1 select_statement1</span><br><span class="line">[<span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory2 select_statement2] ...</span><br><span class="line"> </span><br><span class="line">  </span><br><span class="line">row_format</span><br><span class="line">  : DELIMITED [FIELDS TERMINATED <span class="keyword">BY</span> <span class="type">char</span> [ESCAPED <span class="keyword">BY</span> <span class="type">char</span>]] [COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>]</span><br><span class="line">        [MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] [LINES TERMINATED <span class="keyword">BY</span> <span class="type">char</span>]</span><br><span class="line">        [<span class="keyword">NULL</span> DEFINED <span class="keyword">AS</span> <span class="type">char</span>] (Note: <span class="keyword">Only</span> available starting <span class="keyword">with</span> Hive <span class="number">0.13</span>)</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li>INSERT OVERWRITE :插入语法关键字</li>
<li>LOCAL关键字</li>
</ul>
<blockquote>
<p>LOCAL 关键字：如果指定了 LOCAL， Hive会将数据写入到本次文件系统中。如果没有指定 LOCAL 关键字，则根据 DIRECTORY 中的 uri 查找文件。<br>注意：uri 是指 hdfs 上的路径，分简单模式和完整模式两种，例如：</p>
<ul>
<li>简单模式：&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
<li>完整模式：hdfs:&#x2F;&#x2F;namenode_host:9000&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
</ul>
</blockquote>
<ul>
<li>DIRECTORY 要写入的文件目录</li>
</ul>
<blockquote>
<p>目录可以是一个完整的URI，当标识和权限不确定时，Hive将会从hadoop配置变量fs.default.name中确定URI。</p>
</blockquote>
<ul>
<li>写入格式</li>
</ul>
<blockquote>
<p>数据在写入文件系统时会被序列化成text文本，列之间使用<code>^A</code>分隔符分隔，行之间使用换行分隔，如果任何列不是基本类型，那么这些列将会被序列化为JSON格式。</p>
</blockquote>
<ul>
<li>注意</li>
</ul>
<blockquote>
<p>INSERT OVERWRITE语句写入目录、本地目录，表（或分区表）可以写在一个查询中。</p>
<p>当有大量数据时，使用Hive将数据写入HDFS文件系统的目录中是最好的处理方式，因为Hive可以在一个MapReduce中将数据并行地写入HDFS目录中。</p>
<p>指定的目录如果存在，则写入操作会将目录中原来的数据覆盖，即会先将原有的数据删除，然后插入查询到的数据。</p>
<p>从Hive 0.11.0开始，可以指定使用的分隔符；在早期版本中，它始终是^A字符（\ 001）。但是，在Hive0.11.0至1.1.0中，仅支持自定义分隔符用于本地写入–此错误在版本1.2.0中得到修复。</p>
<p>在Hive 0.14中，插入到符合ACID的表中将在选择和插入期间停用矢量化。这将自动完成。插入数据的ACID表仍然可以使用矢量化进行查询。</p>
</blockquote>
<h3 id="4-使用SQL将数据插入表"><a href="#4-使用SQL将数据插入表" class="headerlink" title="4. 使用SQL将数据插入表"></a>4. 使用SQL将数据插入表</h3><p>使用INSERT……VALUES 通过SQL可以直接将数据插入表。</p>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Standard Syntax: <span class="comment">-- 标准语法</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1[<span class="operator">=</span>val1], partcol2[<span class="operator">=</span>val2] ...)] <span class="keyword">VALUES</span> values_row [, values_row ...]</span><br><span class="line">  </span><br><span class="line"><span class="keyword">Where</span> values_row <span class="keyword">is</span>:</span><br><span class="line">( <span class="keyword">value</span> [, <span class="keyword">value</span> ...] )</span><br><span class="line"><span class="keyword">where</span> a <span class="keyword">value</span> <span class="keyword">is</span> either <span class="keyword">null</span> <span class="keyword">or</span> <span class="keyword">any</span> valid <span class="keyword">SQL</span> literal<span class="comment">-- 值可以是null或有效的SQL语句</span></span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li><p>VALUES子句中列出的每一行都会插入到tablename表中。 </p>
</li>
<li><p>VALUES字句必须提供表中的所有列的值，不允许只提供某些列的值，为了模拟标注sql，使用者可以用null填充那些不需要赋值的列。</p>
</li>
<li><p>动态分区表的插入方式同<code>INSERT...SELECT </code>语法一样。</p>
</li>
<li><p>如果插入到的表支持ACID，并且正在使用支持ACID的事务管理器，则此操作将在成功完成后自动提交。 </p>
</li>
<li><p><strong>Hive不支持复杂类型(array, map, struct, union)文本，所以在INSERT……VALUES也不支持这些复杂类型，这意味着使用者不能通过INSERT……VALUES将数据插入复杂类型的列中。</strong></p>
</li>
</ul>
<h3 id="5-表更新（UPDATE）"><a href="#5-表更新（UPDATE）" class="headerlink" title="5. 表更新（UPDATE）"></a>5. 表更新（UPDATE）</h3><p>UPDATE语法在Hive0.14开始使用。</p>
<p><strong>UPDATE只能在支持ACID的表中使用。</strong></p>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Standard Syntax:</span><br><span class="line"><span class="keyword">UPDATE</span> tablename <span class="keyword">SET</span> <span class="keyword">column</span> <span class="operator">=</span> <span class="keyword">value</span> [, <span class="keyword">column</span> <span class="operator">=</span> <span class="keyword">value</span> ...] [<span class="keyword">WHERE</span> expression]</span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li>引用的列必须是要更新的表的列。</li>
<li>分配的值必须是Hive select子句中支持的表达式。因此，支持算术运算符、UDF、强制转换、文字等。不支持子查询。</li>
<li>分区列和分桶列不能被更新。</li>
<li>在Hive0.14 中，操作成功后更改会自动提交。</li>
</ul>
<p>注意：</p>
<ul>
<li>更新操作会关闭矢量化，这是自动执行的，不需要使用者下发指令。没更新过的表不会收影响，更新后的表也仍然可以使用矢量化查询。</li>
<li>在0.14 版本,更新时建议配置 <code>hive.optimize.sort.dynamic.partition = fasle</code>,因为会更高效。</li>
</ul>
<h2 id="6-表删除（DELETE）"><a href="#6-表删除（DELETE）" class="headerlink" title="6. 表删除（DELETE）"></a>6. 表删除（DELETE）</h2><p>DELETE语法在Hive0.14开始使用。</p>
<p><strong>DELETE只能在支持ACID的表中使用。</strong></p>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Standard Syntax:</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> tablename [<span class="keyword">WHERE</span> expression]</span><br></pre></td></tr></table></figure>

<p>注意:</p>
<ul>
<li><p>在Hive0.14 中，操作成功后更改会自动提交。</p>
</li>
<li><p>删除操作会关闭矢量化，这是自动执行的，不需要使用者下发指令。没删除过的表不会收影响，删除操作完成后的表也仍然可以使用矢量化查询。</p>
</li>
<li><p>在0.14 版本,删除时建议配置 <code>hive.optimize.sort.dynamic.partition = fasle</code>,因为会更高效。</p>
</li>
</ul>
<h3 id="7-MERGE"><a href="#7-MERGE" class="headerlink" title="7. MERGE"></a>7. MERGE</h3><p>Merge简介：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MERGE语句是SQL语句的一种。在SQL Server、Oracle数据库中可用，MySQL、PostgreSQL中不可用。MERGE是Oracle9i新增的语法，用来合并UPDATE和INSERT语句。通过MERGE语句，根据一张表（原数据表，source table）或子查询的连接条件对另外一张（目标表，target table）表进行查询，连接条件匹配上的进行UPDATE，无法匹配的执行INSERT。这个语法仅需要一次全表扫描就完成了全部工作，执行效率要高于INSERT+UPDATE。</span><br></pre></td></tr></table></figure>

<p>版本信息：</p>
<ul>
<li>MERGE在Hive 2.2中开始使用。</li>
<li><strong>MERGE只能在支持ACID的表中使用。</strong></li>
</ul>
<p>语法格式：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Standard Syntax:</span><br><span class="line"><span class="keyword">MERGE</span> <span class="keyword">INTO</span> <span class="operator">&lt;</span>target <span class="keyword">table</span><span class="operator">&gt;</span> <span class="keyword">AS</span> T <span class="keyword">USING</span> <span class="operator">&lt;</span>source expression<span class="operator">/</span><span class="keyword">table</span><span class="operator">&gt;</span> <span class="keyword">AS</span> S</span><br><span class="line"><span class="keyword">ON</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression1<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">WHEN</span> MATCHED [<span class="keyword">AND</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression2<span class="operator">&gt;</span>] <span class="keyword">THEN</span> <span class="keyword">UPDATE</span> <span class="keyword">SET</span> <span class="operator">&lt;</span><span class="keyword">set</span> clause list<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">WHEN</span> MATCHED [<span class="keyword">AND</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression3<span class="operator">&gt;</span>] <span class="keyword">THEN</span> <span class="keyword">DELETE</span></span><br><span class="line"><span class="keyword">WHEN</span> <span class="keyword">NOT</span> MATCHED [<span class="keyword">AND</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression4<span class="operator">&gt;</span>] <span class="keyword">THEN</span> <span class="keyword">INSERT</span> <span class="keyword">VALUES</span><span class="operator">&lt;</span><span class="keyword">value</span> list<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<p>语法解析：</p>
<ul>
<li><p>Merge允许基于与源表的联接结果对目标表执行操作。</p>
</li>
<li><p>自Hive2.2起，merge操作成功后会自动提交事务。</p>
</li>
</ul>
<p>注意：</p>
<ul>
<li>WHEN条件子句中，INSERT&#x2F;UPDATE&#x2F;DELETE中的每个语句最多只有一个，例如不能同时有两个insert子句。</li>
<li>WHEN NOT MATCHED必须放在多个WHEN子句的最后。</li>
<li>如果同时存在UPDATE和DELETE子句，则放在前面的哪一个字句中必须包含<code>AND &lt;boolean expression&gt;</code></li>
</ul>
<p>t条件。</p>
<ul>
<li>Merge操作会关闭矢量化，这是自动执行的，不需要使用者下发指令。没Merge过的表不会收影响，Merge操作完成后的表也仍然可以使用矢量化查询。</li>
</ul>
<h3 id="8-集群间数据迁移-IMPORT-x2F-EXPORT（这部分知识待补充）"><a href="#8-集群间数据迁移-IMPORT-x2F-EXPORT（这部分知识待补充）" class="headerlink" title="8. 集群间数据迁移 IMPORT&#x2F;EXPORT（这部分知识待补充）"></a>8. 集群间数据迁移 IMPORT&#x2F;EXPORT（这部分知识待补充）</h3><p>版本信息：</p>
<p>IMPORT&#x2F;EXPORT命令在Hive 0.8.0版本添加。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/Hadoop/Hive/Hive%E8%AF%AD%E6%B3%95%E7%B2%BE%E7%82%BC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E8%AF%AD%E6%B3%95%E7%B2%BE%E7%82%BC/" class="post-title-link" itemprop="url">Hive语法精炼</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:33:43" itemprop="dateModified" datetime="2023-09-27T18:33:43+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>155</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive语法精炼"><a href="#Hive语法精炼" class="headerlink" title="Hive语法精炼"></a>Hive语法精炼</h1><p>以下语法精简可用，但不一定是最全的语法格式，某些可选项可能被忽略，随时补充。</p>
<ul>
<li><p>查看数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> databases;</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database [if <span class="keyword">not</span> <span class="keyword">exists</span>] database_name;</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> database [if <span class="keyword">exists</span>] database_name;</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/Hadoop/Hive/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BC%80%E5%8F%91%E6%9E%B6%E6%9E%84%E5%B1%82%E6%AC%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BC%80%E5%8F%91%E6%9E%B6%E6%9E%84%E5%B1%82%E6%AC%A1/" class="post-title-link" itemprop="url">数据仓库开发架构层次</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:29:07" itemprop="dateModified" datetime="2023-09-27T18:29:07+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>644</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="数据仓库开发架构层次"><a href="#数据仓库开发架构层次" class="headerlink" title="数据仓库开发架构层次"></a>数据仓库开发架构层次</h1><h2 id="一、STG原始数据层（数据落地）"><a href="#一、STG原始数据层（数据落地）" class="headerlink" title="一、STG原始数据层（数据落地）"></a>一、STG原始数据层（数据落地）</h2><p>这层的工作主要是原始数据在数据仓库的落地，数据结构和原始数据保持一致，不做逻辑处理。</p>
<h2 id="二、ODS数据操作层（数据清洗）"><a href="#二、ODS数据操作层（数据清洗）" class="headerlink" title="二、ODS数据操作层（数据清洗）"></a>二、ODS数据操作层（数据清洗）</h2><p>用于原始数据在数据平台的落地。数据从数据结构、数据之间的逻辑关系上都与STG原始数据层基本保持一致。源数据进入这一层时，要进行业务字段提取、去掉不用的字段、脏数据处理等，也就是进行数据清洗。</p>
<p><strong>在实际开发中，不一定会同时创建STG层和ODS层，因为两个层差异不大，更多的是直接创建ODS层。</strong></p>
<h2 id="三、DWD数据明细层（合成明细表）"><a href="#三、DWD数据明细层（合成明细表）" class="headerlink" title="三、DWD数据明细层（合成明细表）"></a>三、DWD数据明细层（合成明细表）</h2><p>用于源系统数据在数据平台中的永久存储。它用以支撑DWS层和ADS层无法覆盖的需求，比如数据明细方面的需求。这一层主要解决数据质量问题以及数据的完整性度问题。一般会生成整个开发流程中最为明细的数据表。</p>
<h2 id="四、DWS数据服务层（数据轻度聚合）"><a href="#四、DWS数据服务层（数据轻度聚合）" class="headerlink" title="四、DWS数据服务层（数据轻度聚合）"></a>四、DWS数据服务层（数据轻度聚合）</h2><p>数据汇总层，该层会在DWD层的数据基础上。对数据做轻度的聚合操作，生成一系列的中间表，提升公共指标的复用性，减少重复加工。按照业务划分，如流量、产品、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP分析，数据分发等。</p>
<h2 id="五、ADS应用数据层（业务指标聚合）"><a href="#五、ADS应用数据层（业务指标聚合）" class="headerlink" title="五、ADS应用数据层（业务指标聚合）"></a>五、ADS应用数据层（业务指标聚合）</h2><p>该层存放数据产品个性化的统计指标数据，一般以某个业务应用为出发点进行建设，ADS层只关心自己需要的数据，不会全盘考虑企业整体的数据架构和应用。面向实际的业务数据需求，以DWD或者DWS层的数据为基础，组成各种统计报表。</p>
<h2 id="六、DIM维度层（"><a href="#六、DIM维度层（" class="headerlink" title="六、DIM维度层（"></a>六、DIM维度层（</h2><p>主要存储公共的属性数据，比如产品类别、地理位置、时间详情等信息。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/Hadoop/Hive/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%87%BD%E6%95%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%87%BD%E6%95%B0/" class="post-title-link" itemprop="url">数据库函数</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-12-22 17:23:03" itemprop="dateModified" datetime="2023-12-22T17:23:03+08:00">2023-12-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>21 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="数据库函数"><a href="#数据库函数" class="headerlink" title="数据库函数"></a>数据库函数</h1><p>[TOC]</p>
<h2 id="空值处理"><a href="#空值处理" class="headerlink" title="空值处理"></a>空值处理</h2><h3 id="COALESCE-hive"><a href="#COALESCE-hive" class="headerlink" title="COALESCE	(hive)"></a>COALESCE	(hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	coalesce(expr1,expr2,...)</span><br><span class="line">用途：</span><br><span class="line">	返回列表中第一个非null的值，如果列表中的所有值都是null则返回null</span><br><span class="line">参数说明：</span><br><span class="line">	*expri是要测试的值。所有这些值类型必须相同或为null，否则会引发异常。</span><br><span class="line">返回值：</span><br><span class="line">	返回值类型和参数类型相同。</span><br><span class="line">备注：</span><br><span class="line">	参数至少有一个，否则引发异常。</span><br></pre></td></tr></table></figure>



<h3 id="NVL-hive"><a href="#NVL-hive" class="headerlink" title="NVL	(hive)"></a>NVL	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	nvl(expr1,expr2)</span><br><span class="line">用途：</span><br><span class="line">	替换空值，如果第一个参数expr1的值为<span class="keyword">NULL</span>，则返回第二个参数的值。</span><br><span class="line">备注：</span><br><span class="line">	最多只能传递两个参数。</span><br></pre></td></tr></table></figure>



<h2 id="格式处理"><a href="#格式处理" class="headerlink" title="格式处理"></a>格式处理</h2><h3 id="TRANSLATE-hive"><a href="#TRANSLATE-hive" class="headerlink" title="TRANSLATE	(hive)"></a>TRANSLATE	(hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	TRANSLATE(input_string, from__characters, to_characters);</span><br><span class="line">用途：</span><br><span class="line">	替换字符串中的字符，第一个字符串是源字符串，第二个字符串是字符串中要替换掉的字符串的表达式，最后一个字符串是要替换为的字符串的表达式。</span><br><span class="line">返回值：</span><br><span class="line">	返回被替换完毕的字符串。</span><br><span class="line">注意：</span><br><span class="line">	如果任何参数为null，函数返回值为null</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- from 和 to 长度一样，如translate(&quot;abcdef-abcdef&quot;,&quot;abcdef&quot;,&quot;123456&quot;);替换不是说把&quot;abcdef&quot;替换成&quot;123456&quot;，而是把a替换成1，把b替换成2，把c替换成3，把d替换成4，e替换成5，f替换成6.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="built_in">translate</span>(<span class="string">&#x27;abcdef-abcdef&#x27;</span>, <span class="string">&#x27;abcd&#x27;</span>, <span class="string">&#x27;1234&#x27;</span>),<span class="comment">--1234ef-1234ef</span></span><br><span class="line">       <span class="built_in">translate</span>(<span class="string">&#x27;abcdef-abcdef&#x27;</span>, <span class="string">&#x27;ab&#x27;</span>, <span class="string">&#x27;12&#x27;</span>),    <span class="comment">--12cdef-12cdef</span></span><br><span class="line">       <span class="built_in">translate</span>(<span class="string">&#x27;abcdef-abcdef&#x27;</span>, <span class="string">&#x27;ad&#x27;</span>, <span class="string">&#x27;14&#x27;</span>),    <span class="comment">--1bc4ef-1bc4ef</span></span><br><span class="line">       <span class="built_in">translate</span>(<span class="string">&#x27;abcdef-abcdef&#x27;</span>, <span class="string">&#x27;da&#x27;</span>, <span class="string">&#x27;41&#x27;</span>);<span class="comment">--1bc4ef-1bc4ef</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- from 字符串长度&gt;to的字符串长度 ，例如translate(&#x27;abcdef-abcdef&#x27;,&#x27;adbc&#x27;,&#x27;123&#x27;)    意思是把 a替换为1，b替换为2，c替换为3，d替换为空，即删除掉。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="built_in">translate</span>(<span class="string">&#x27;abcdef-abcdef&#x27;</span>, <span class="string">&#x27;abcd&#x27;</span>, <span class="string">&#x27;123&#x27;</span>), <span class="comment">--123ef-123ef</span></span><br><span class="line">       <span class="built_in">translate</span>(<span class="string">&#x27;abcdef-abcdef&#x27;</span>, <span class="string">&#x27;adbc&#x27;</span>, <span class="string">&#x27;123&#x27;</span>); <span class="comment">--132ef-132ef</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 如果 from里有重复字符 比如abca，1231，重复的字符a对应to的替换不会起作用</span></span><br><span class="line"><span class="keyword">select</span> <span class="built_in">TRANSLATE</span> (<span class="string">&#x27;abcdaabbaaabbb&#x27;</span>,<span class="string">&#x27;aa&#x27;</span>,<span class="string">&#x27;12&#x27;</span>)<span class="comment">--1bcd11bb111bbb </span></span><br></pre></td></tr></table></figure>



<h3 id="REGEXP-hive"><a href="#REGEXP-hive" class="headerlink" title="REGEXP (hive)"></a>REGEXP (hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	A REGEXP B</span><br><span class="line">用途：</span><br><span class="line">	判断字符串A是否符合正则表达式B，返回结果为boolean(true、false)或者null。</span><br></pre></td></tr></table></figure>



<h3 id="REGEXP-REPLACE-hive"><a href="#REGEXP-REPLACE-hive" class="headerlink" title="REGEXP_REPLACE	(hive)"></a>REGEXP_REPLACE	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	REGEXP_REPLACE(string A, string B, string C);</span><br><span class="line">用途：</span><br><span class="line">	将字符串A中的部分字符做替换。</span><br><span class="line">用法：</span><br><span class="line">	将字符串A中满足Java正则表达式B的部分替换为字符串C。</span><br></pre></td></tr></table></figure>



<h3 id="REGEXP-EXTRACT-hive"><a href="#REGEXP-EXTRACT-hive" class="headerlink" title="REGEXP_EXTRACT (hive)"></a>REGEXP_EXTRACT (hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	REGEXP_EXTRACT(STRING subject, STRING pattern, INT index)</span><br><span class="line">用途：</span><br><span class="line">	将字符串进行正则拆分</span><br><span class="line">用法：</span><br><span class="line">	将字符串subject按照pattern正则表达式的规则进行拆分，返回index指定部分的字符，index从1开始计。</span><br><span class="line">	* index = 0时，将字符串与整个pattern正则表达式进行匹配，返回匹配结果</span><br><span class="line">	* index = 1时，将字符串与pattern中第一个括号里的表达式进行匹配，返回结果。</span><br><span class="line">	index &gt;=1时以此类推</span><br><span class="line">示例：</span><br><span class="line">	select regexp_extract(&#x27;AA123bbcccc&#x27; ,&#x27;A&#123;2&#125;([1-9]&#123;3&#125;)([a-z]&#123;6&#125;)&#x27;,0);</span><br><span class="line">	结果：AA123bbcccc</span><br><span class="line">	select regexp_extract(&#x27;AA123bbcccc&#x27; ,&#x27;A&#123;2&#125;([1-9]&#123;3&#125;)([a-z]&#123;6&#125;)&#x27;,2);</span><br><span class="line">	结果：bbcccc</span><br></pre></td></tr></table></figure>



<h3 id="TRIM-hive"><a href="#TRIM-hive" class="headerlink" title="TRIM	(hive)"></a>TRIM	(hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	TRIM(string)</span><br><span class="line">用途：</span><br><span class="line">	去掉字段首尾的空格</span><br></pre></td></tr></table></figure>



<h3 id="LTRIM-hive"><a href="#LTRIM-hive" class="headerlink" title="LTRIM	(hive)"></a>LTRIM	(hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	LTRIM(string)</span><br><span class="line">用途：</span><br><span class="line">	去掉字段的前置空格</span><br></pre></td></tr></table></figure>



<h3 id="RTRIM-hive"><a href="#RTRIM-hive" class="headerlink" title="RTRIM	(hive)"></a>RTRIM	(hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	RTRIM(string)</span><br><span class="line">用途：</span><br><span class="line">	去掉字段的后置空格</span><br></pre></td></tr></table></figure>



<h3 id="EXPLODE-hive"><a href="#EXPLODE-hive" class="headerlink" title="EXPLODE	(hive)"></a>EXPLODE	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	EXPLODE(col)</span><br><span class="line">用途：</span><br><span class="line">	将某列炸裂为多行。</span><br><span class="line">例如：</span><br><span class="line">	某列字段col<span class="operator">=</span> [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>],将该列炸裂开explode(col) <span class="operator">=</span> </span><br><span class="line">	a</span><br><span class="line">	b</span><br><span class="line">	c</span><br><span class="line">注意：</span><br><span class="line">	列字段值必须是<span class="keyword">array</span> 或 map类型的字段，如果不是，可以将其转化为<span class="keyword">array</span> 或 map类型后再使用炸裂函数。</span><br><span class="line">	通常，如果字段值是一串有相同分隔符的字符串，可以使用split函数将其转换为<span class="keyword">array</span>类型。</span><br><span class="line">	如果想把某列按另一列字段值炸裂开来，即炸裂是与另一列相关的，则需要使用到<span class="keyword">Lateral</span> <span class="keyword">view</span>函数。</span><br><span class="line">常用组合：</span><br><span class="line">	常与split、<span class="keyword">Lateral</span> <span class="keyword">view</span>函数一起使用。</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="LATERAL-VIEW-hive"><a href="#LATERAL-VIEW-hive" class="headerlink" title="LATERAL VIEW	(hive)"></a>LATERAL VIEW	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	<span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> udtf(expression) tableAlias <span class="keyword">AS</span> columnAlias</span><br><span class="line">用途：</span><br><span class="line">	用于和split, explode等UDTF一起使用，它能够将一列数据拆成多行数据，在此基础上可以对拆分后的数据进行聚合。</span><br></pre></td></tr></table></figure>



<h3 id="SPLIT-hive"><a href="#SPLIT-hive" class="headerlink" title="SPLIT	(hive)"></a>SPLIT	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	SPLIT(string ,pat)</span><br><span class="line">返回值：</span><br><span class="line">	<span class="keyword">array</span> 数组</span><br><span class="line">用途：</span><br><span class="line">	按照指定分隔符将字符串string使用pat进行分隔</span><br><span class="line">注意：</span><br><span class="line">	第二个参数可以是正则表达式，如果分隔符是正则表达式中的特殊符号，则需要进行转义，有些特殊字符只需\，而有些需要\\。如果整个语句本身是一个字符串的话，转义字符前还需加上\\，即可能有三个或四个\进行转义。</span><br></pre></td></tr></table></figure>



<h2 id="常用逻辑"><a href="#常用逻辑" class="headerlink" title="常用逻辑"></a>常用逻辑</h2><h3 id="IF-hive"><a href="#IF-hive" class="headerlink" title="IF	(hive)"></a>IF	(hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	IF( expr1 , expr2 , expr3 )</span><br><span class="line">用途：</span><br><span class="line">	条件判断，如果expr1的值为true，返回值为expr2，如果为false，返回值为exper3。</span><br></pre></td></tr></table></figure>



<h3 id="CASE…WHEN…THEN…END-hive"><a href="#CASE…WHEN…THEN…END-hive" class="headerlink" title="CASE…WHEN…THEN…END	(hive)"></a>CASE…WHEN…THEN…END	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">用途：</span><br><span class="line">	根据不同条件返回不同的值</span><br><span class="line">用法<span class="number">1</span> <span class="keyword">case</span> 后不跟匹配列：</span><br><span class="line">	<span class="keyword">case</span> </span><br><span class="line">	<span class="keyword">when</span> tb1.os <span class="operator">=</span> <span class="string">&#x27;android&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;android&#x27;</span></span><br><span class="line">	<span class="keyword">when</span> tb1.os <span class="operator">=</span> <span class="string">&#x27;ios&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;iPhone&#x27;</span></span><br><span class="line">	<span class="keyword">else</span> <span class="string">&#x27;PC&#x27;</span></span><br><span class="line">	<span class="keyword">end</span> <span class="keyword">as</span> os,</span><br><span class="line">	</span><br><span class="line">用法<span class="number">2</span> <span class="keyword">case</span> 后跟匹配列</span><br><span class="line">	<span class="keyword">case</span> tb1.os</span><br><span class="line">	<span class="keyword">when</span> <span class="string">&#x27;android&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;android&#x27;</span></span><br><span class="line">	<span class="keyword">when</span> <span class="string">&#x27;ios&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;iPhone&#x27;</span></span><br><span class="line">	<span class="keyword">else</span> <span class="string">&#x27;PC&#x27;</span></span><br><span class="line">	<span class="keyword">end</span> <span class="keyword">as</span> os,</span><br><span class="line">两种用法都可以实现同样的效果</span><br></pre></td></tr></table></figure>



<h2 id="排序去重"><a href="#排序去重" class="headerlink" title="排序去重"></a>排序去重</h2><h3 id="ROW-NUMBER-hive"><a href="#ROW-NUMBER-hive" class="headerlink" title="ROW_NUMBER	(hive)"></a>ROW_NUMBER	(hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	row_number()</span><br><span class="line">用途：</span><br><span class="line">	按查出的记录数前后排序，序号不重复。即第1条记录序号为1，第2条记录序号2，第3条记录序号为3（不考虑3条记录的排序字段是否重复）。</span><br><span class="line">常用组合：</span><br><span class="line">	需搭配窗口函数ROW()使用</span><br><span class="line">	ROW_NUMBER() OVER(PARTITION BY COLUMN1 ORDER BY COLUMN2)</span><br><span class="line">	意思是先根据COLUMN1进行结果集分分组，结果集内部按照COLUMN2排序。</span><br><span class="line">	在使用 row_number() over()函数的时候，over()里面的分组以及排序的执行晚于 where、group by、order by 的执行。</span><br><span class="line">总结：</span><br><span class="line">	会按照顺序给出排序，如对10,10,9,8进行排序，输出结果为1,2,3,4</span><br></pre></td></tr></table></figure>



<h3 id="RANK-hive"><a href="#RANK-hive" class="headerlink" title="RANK	(hive)"></a>RANK	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	<span class="built_in">RANK</span>()</span><br><span class="line">常用组合：</span><br><span class="line">	需搭配窗口函数<span class="type">ROW</span>()使用</span><br><span class="line">总结：</span><br><span class="line">	排序相同是排名会重复，总数不会变，如对<span class="number">10</span>,<span class="number">10</span>,<span class="number">9</span>,<span class="number">8</span>进行排序，输出结果为<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span></span><br></pre></td></tr></table></figure>



<h3 id="DENSE-RANK-hive"><a href="#DENSE-RANK-hive" class="headerlink" title="DENSE_RANK	(hive)"></a>DENSE_RANK	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	<span class="built_in">DENSE_RANK</span>()</span><br><span class="line">常用组合：</span><br><span class="line">	需搭配窗口函数<span class="type">ROW</span>()使用</span><br><span class="line">总结：</span><br><span class="line">	排序相同时排名会重复，总数会减少，如对<span class="number">10</span>,<span class="number">10</span>,<span class="number">9</span>,<span class="number">8</span>进行排序，输出结果为<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span></span><br></pre></td></tr></table></figure>



<h3 id="FIELD-hive-mysql"><a href="#FIELD-hive-mysql" class="headerlink" title="FIELD 	(hive,mysql)"></a>FIELD 	(hive,mysql)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">		FIELD(col,value_1,value_2,...)</span><br><span class="line">用途：</span><br><span class="line">	用于排序时给出指定的排序顺序。</span><br><span class="line">用法：</span><br><span class="line">	第一个参数col为排序的列，后面的参数<span class="keyword">value</span>可以给出排序顺序，查询结果将按照给定的值排序来进行排序。</span><br><span class="line">常用组合：</span><br><span class="line">	sort <span class="keyword">by</span> field(col,value_1,value_2,...), <span class="keyword">order</span> <span class="keyword">by</span> field(col,value_1,value_2,...)</span><br><span class="line">实例：</span><br><span class="line">	<span class="keyword">select</span> name,age</span><br><span class="line">	<span class="keyword">from</span> student </span><br><span class="line">	<span class="keyword">order</span> <span class="keyword">by</span> field(age,<span class="number">12</span>,<span class="number">11</span>,<span class="number">13</span>,<span class="number">14</span>)</span><br><span class="line">	输出结果将按给定的值顺序来排序</span><br></pre></td></tr></table></figure>



<h2 id="时间函数"><a href="#时间函数" class="headerlink" title="时间函数"></a>时间函数</h2><h3 id="DATEDIFF-hive"><a href="#DATEDIFF-hive" class="headerlink" title="DATEDIFF	(hive)"></a>DATEDIFF	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	DATEDIFF(endDate,startDate)</span><br><span class="line">用途：</span><br><span class="line">	返回endDate和startDate相差的天数，返回值是整数。</span><br><span class="line">注意：</span><br><span class="line">	参数类型最好保持一致</span><br><span class="line">	该函数是hive中的形式，与mysql中的同名函数datediff用法不同。</span><br><span class="line">	计算不包括边界值，例如两个相同日期计算差值返回<span class="number">0</span>，两个相邻日期计算差值返回<span class="number">1</span></span><br></pre></td></tr></table></figure>



<h3 id="DATE-ADD（hive）"><a href="#DATE-ADD（hive）" class="headerlink" title="DATE_ADD（hive）"></a>DATE_ADD（hive）</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	DATE_ADD(<span class="type">date</span>, <span class="type">int</span>)</span><br><span class="line">用途：</span><br><span class="line">	返回某日期增加<span class="type">int</span>天(当<span class="type">int</span>为正数)或者减少<span class="type">int</span>天(当<span class="type">int</span>为负数)后得到的日期</span><br><span class="line">注意：</span><br><span class="line">	<span class="type">date</span>的形式必须是标准形式，即<span class="string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>或 <span class="string">&#x27;yyyy-MM-dd&#x27;</span></span><br><span class="line">	第二个参数可以是正数也可以是负数。</span><br></pre></td></tr></table></figure>



<h3 id="DATE-SUB-hive"><a href="#DATE-SUB-hive" class="headerlink" title="DATE_SUB	(hive)"></a>DATE_SUB	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">效果与date_add函数相反。</span><br></pre></td></tr></table></figure>



<h3 id="DATE-FORMAT-hive"><a href="#DATE-FORMAT-hive" class="headerlink" title="DATE_FORMAT	(hive)"></a>DATE_FORMAT	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	DATE_FORMAT(<span class="type">date</span>,format);</span><br><span class="line">用途：</span><br><span class="line">	格式化日期或日期字符串</span><br><span class="line">用法：</span><br><span class="line">	第一个参数可以为日期或日期字符串，第二个参数为日期格式，函数将返回格式化后的日期字符串。</span><br><span class="line">注意：</span><br><span class="line">	如果日期的月或日是不符合常理的数字，且大于常规值，则返回结果是计算后的结果，例如date_format(<span class="string">&#x27;2022-16-1&#x27;</span>,<span class="string">&#x27;yyyy-MM-dd&#x27;</span>)的返回值为<span class="string">&#x27;2023-04-01&#x27;</span></span><br></pre></td></tr></table></figure>



<h3 id="UNIX-TIMESTAMP-hive"><a href="#UNIX-TIMESTAMP-hive" class="headerlink" title="UNIX_TIMESTAMP	(hive)"></a>UNIX_TIMESTAMP	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	UNIX_TIMESTAMP(dateString,[format])</span><br><span class="line">用途：</span><br><span class="line">	返回参数dateString对应的时间戳，时间戳为<span class="number">10</span>位，单位为秒</span><br><span class="line">用法：</span><br><span class="line">	如果dateString满足<span class="string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>的形式，可以直接使用UNIX_TIMESTAMP(dateString)得到其时间戳，如果不满足该形式，则可以在函数内使用格式参数，如UNIX_TIMESTAMP(<span class="string">&#x27;20220719&#x27;</span>,<span class="string">&#x27;yyyyMMdd&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h3 id="FROM-UNIXTIME-hive"><a href="#FROM-UNIXTIME-hive" class="headerlink" title="FROM_UNIXTIME	(hive)"></a>FROM_UNIXTIME	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	FROM_UNIXTIME(unix_timestamp,format)</span><br><span class="line">用途：</span><br><span class="line">	将时间戳unix_timestamp按照时间格式format进行转换</span><br></pre></td></tr></table></figure>



<h3 id="获取日期中的年月日时分秒周数等-hiveQL"><a href="#获取日期中的年月日时分秒周数等-hiveQL" class="headerlink" title="获取日期中的年月日时分秒周数等	(hiveQL)"></a>获取日期中的年月日时分秒周数等	(hiveQL)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	<span class="keyword">year</span>(<span class="type">date</span><span class="operator">/</span><span class="type">timestamp</span>)<span class="comment">----------返回日期中的年</span></span><br><span class="line">	<span class="keyword">month</span>(<span class="type">date</span><span class="operator">/</span><span class="type">timestamp</span>)<span class="comment">----------返回日期中的月</span></span><br><span class="line">	<span class="keyword">day</span>(<span class="type">date</span><span class="operator">/</span><span class="type">timestamp</span>)<span class="comment">----------返回日期中的日</span></span><br><span class="line">	<span class="keyword">hour</span>(<span class="type">date</span><span class="operator">/</span><span class="type">timestamp</span>)<span class="comment">----------返回日期中的小时</span></span><br><span class="line">	<span class="keyword">minute</span>(<span class="type">date</span><span class="operator">/</span><span class="type">timestamp</span>)<span class="comment">----------返回日期中的分钟</span></span><br><span class="line">	<span class="keyword">second</span>(<span class="type">date</span><span class="operator">/</span><span class="type">timestamp</span>)<span class="comment">----------返回日期中的秒</span></span><br><span class="line">	weekofyear(<span class="type">date</span><span class="operator">/</span><span class="type">timestamp</span>)<span class="comment">----------返回日期是当年的哪一周</span></span><br></pre></td></tr></table></figure>



<h3 id="获取日期中的年月日时分秒周数等-PostgreSql-Mysql-Oracle"><a href="#获取日期中的年月日时分秒周数等-PostgreSql-Mysql-Oracle" class="headerlink" title="获取日期中的年月日时分秒周数等	(PostgreSql,Mysql,Oracle)"></a>获取日期中的年月日时分秒周数等	(PostgreSql,Mysql,Oracle)</h3><h3 id="EXTRACT"><a href="#EXTRACT" class="headerlink" title="EXTRACT"></a>EXTRACT</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	<span class="built_in">extract</span>(<span class="keyword">year</span><span class="operator">|</span><span class="keyword">month</span><span class="operator">|</span><span class="keyword">day</span><span class="operator">|</span><span class="keyword">hour</span><span class="operator">|</span><span class="keyword">minute</span><span class="operator">|</span><span class="keyword">second</span><span class="operator">|</span>week <span class="keyword">from</span> [类型声明] <span class="type">date</span><span class="operator">/</span><span class="type">interval</span>类型值)</span><br><span class="line">如：</span><br><span class="line">	<span class="built_in">extract</span>(week <span class="keyword">from</span> <span class="type">timestamp</span> <span class="string">&#x27;2022-08-01&#x27;</span>) <span class="comment">----获取8月1日处于2022年的第几周</span></span><br></pre></td></tr></table></figure>



<h3 id="TRUNC"><a href="#TRUNC" class="headerlink" title="TRUNC"></a>TRUNC</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	TRUNC(<span class="type">date</span>, format)</span><br><span class="line">	TRUNC(number,[decimals])</span><br><span class="line">用途：</span><br><span class="line">	TRUNC函数返回以指定元素格式截去一部分的日期值，或者直接对数字格式的数据进行截断</span><br><span class="line">用法：</span><br><span class="line">	第一个参数若为数字number，number为待截取处理的数值，decimals指明需保留小数点后面的位数，为可选项，忽略此项时会截去所有小数部分，第二个参数可以为负数，表示为小数点左边指定位数后面的部分截去，即均以<span class="number">0</span>记。与取整类似，比如参数为<span class="number">1</span>即取整到十分位，如果是<span class="number">-1</span>，则是取整到十位，以此类推；如果所设置的参数为负数，且负数的位数大于整数的字节数的话，则返回为<span class="number">0</span>。如：TRUNC(<span class="number">89.985</span>,<span class="number">-3</span>)<span class="operator">=</span><span class="number">0</span>。</span><br><span class="line">	第一个参数若为日期值<span class="type">date</span>，形式需为标准形式，第二个参数format为截断粒度，如trunc(<span class="string">&#x27;2020-05-02&#x27;</span>, <span class="string">&#x27;YY&#x27;</span>) <span class="operator">=</span> <span class="string">&#x27;2020-01-01&#x27;</span>, format值参考如下：</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Unit</th>
<th>Valid format parameters</th>
</tr>
</thead>
<tbody><tr>
<td>Year</td>
<td>SYYYY, YYYY, YEAR, SYEAR, YYY, YY, Y</td>
</tr>
<tr>
<td>ISO Year</td>
<td>IYYY, IY, I</td>
</tr>
<tr>
<td>Quarter</td>
<td>Q</td>
</tr>
<tr>
<td>Month</td>
<td>MONTH, MON, MM, RM</td>
</tr>
<tr>
<td>Week</td>
<td>WW</td>
</tr>
<tr>
<td>IW</td>
<td>IW</td>
</tr>
<tr>
<td>W</td>
<td>W</td>
</tr>
<tr>
<td>Day</td>
<td>DDD, DD, J</td>
</tr>
<tr>
<td>Start day of the week</td>
<td>DAY, DY, D</td>
</tr>
<tr>
<td>Hour</td>
<td>HH, HH12, HH24</td>
</tr>
<tr>
<td>Minute</td>
<td>MI</td>
</tr>
</tbody></table>
<h3 id="ADD-MONTHS-hive"><a href="#ADD-MONTHS-hive" class="headerlink" title="ADD_MONTHS	(hive)"></a>ADD_MONTHS	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	ADD_MONTHS(<span class="type">date</span>, number)</span><br><span class="line">用途：</span><br><span class="line">	计算日期增减几个月后的日期</span><br><span class="line">用法:</span><br><span class="line">	第一个参数<span class="type">date</span>为日期，需为标准形式，第二个参数为增量值，可以为负数，计算结果为日期增减增量值个月份后的结果。</span><br></pre></td></tr></table></figure>



<h3 id="NEXT-DAY-hive"><a href="#NEXT-DAY-hive" class="headerlink" title="NEXT_DAY	(hive)"></a>NEXT_DAY	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	NEXT_DAY(<span class="type">date</span>, weekday)</span><br><span class="line">用途：</span><br><span class="line">	可以取到当前日期的下一个周一的日期，方便进行其他操作。</span><br><span class="line">用法：</span><br><span class="line">	第一个参数<span class="type">date</span>为日期，形式需为标准形式，且粒度至少到日；第二个参数weekday是指定周几，该参数可以使用全拼，也可以使用全拼的前两位或前三位作为缩写，建议使用全拼比较直观。</span><br><span class="line">	weekday取值：Monday，Tuesday、Wednesday、Thursday、Friday、Saturday、Sunday.</span><br><span class="line">示例：</span><br><span class="line">	取日期下一周的周一</span><br><span class="line">	<span class="keyword">select</span> NEXT_DAY(<span class="string">&#x27;2022-10-26&#x27;</span>, <span class="string">&#x27;MONDAY&#x27;</span>)</span><br><span class="line">	<span class="keyword">select</span> NEXT_DAY(<span class="string">&#x27;2022-10-26&#x27;</span>, <span class="string">&#x27;MO&#x27;</span>)</span><br><span class="line">	<span class="keyword">select</span> NEXT_DAY(<span class="string">&#x27;2022-10-26&#x27;</span>, <span class="string">&#x27;MO&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h2 id="字符串函数"><a href="#字符串函数" class="headerlink" title="字符串函数"></a>字符串函数</h2><h3 id="CONCAT-hive"><a href="#CONCAT-hive" class="headerlink" title="CONCAT	(hive)"></a>CONCAT	(hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	CONCAT(STRING_1,STRING_2,.....)</span><br><span class="line">用途：</span><br><span class="line">	字符串拼接</span><br><span class="line">用法：</span><br><span class="line">	按顺序将传入的字符串参数拼接成一个字符串。</span><br></pre></td></tr></table></figure>



<h3 id="CONCAT-WS-hive"><a href="#CONCAT-WS-hive" class="headerlink" title="CONCAT_WS	(hive)"></a>CONCAT_WS	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	CONCAT_WS(separator, str1, str2, ...)</span><br><span class="line">用途：</span><br><span class="line">	字符串拼接时指定分隔符</span><br><span class="line">注意：</span><br><span class="line">	如果分隔符是 <span class="keyword">NULL</span>，返回值也将为 <span class="keyword">NULL</span>。这个函数会跳过分隔符参数后的任何 <span class="keyword">NULL</span> 和空字符串。分隔符将被加到被连接的字符串之间;</span><br><span class="line">其他说明：</span><br><span class="line">	该函数返回值类型为字符串类型</span><br></pre></td></tr></table></figure>



<h2 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h2><h3 id="COLLECT-SET-hive"><a href="#COLLECT-SET-hive" class="headerlink" title="COLLECT_SET	(hive)"></a>COLLECT_SET	(hive)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	COLLECT_SET(expression)</span><br><span class="line">用途：</span><br><span class="line">	执行列转行操作，可以按照某些列分组，然后将剩余的一列的多行的值放在一个数组里转成一行。如果有多列想要转成一行，可以将这些列使用其他函数(例如concat、concat_ws、map等函数)拼接成一列，然后使用该函数转成一行，再想办法将拼接的列分开即可。</span><br><span class="line">	注意该函数会根据列值进行去重汇总，产生array类型字段。该函数为聚合函数，不在聚合范围内的列需要进行group by操作</span><br><span class="line">	即可以将列数据转为一行</span><br><span class="line">	如果不希望对聚合字段去重，可以使用下面的COLLECT_LIST() 函数</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-- 现有数据,存放在表student中</span><br><span class="line">age		name</span><br><span class="line">13		小明</span><br><span class="line">13		小红</span><br><span class="line">14		小伟</span><br><span class="line">-- 按照年龄分组，将名字聚合成一行</span><br><span class="line">SELECT </span><br><span class="line">	age </span><br><span class="line">	,COLLECT_SET(name) as names</span><br><span class="line">FROM </span><br><span class="line">	student</span><br><span class="line">GROUP BY </span><br><span class="line">	age</span><br><span class="line">-- 将取得如下结果</span><br><span class="line">age		names</span><br><span class="line">13		[小明，小红]</span><br><span class="line">14		[小伟]</span><br></pre></td></tr></table></figure>



<h3 id="COLLECT-LIST"><a href="#COLLECT-LIST" class="headerlink" title="COLLECT_LIST()"></a>COLLECT_LIST()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	COLLECT_LIST(expression)</span><br><span class="line">用途：</span><br><span class="line">	执行列转行操作，可以按照某些列分组，然后将剩余的一列的多行的值放在一个数组里转成一行。如果有多列想要转成一行，可以将这些列使用其他函数(例如concat、concat_ws、map等函数)拼接成一列，然后使用该函数转成一行，再想办法将拼接的列分开即可。</span><br><span class="line">	函数不会根据列值进行去重汇总，保留所有列值，产生array类型字段。该函数为聚合函数，不在聚合范围内的列需要进行group by操作</span><br><span class="line">	即可以将列数据转为一行</span><br><span class="line">	如果希望聚合时对聚合列去重，可以使用上面的COLLECT_SET() 函数</span><br></pre></td></tr></table></figure>





<h2 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h2><h3 id="OVER-hive"><a href="#OVER-hive" class="headerlink" title="OVER	(hive)"></a>OVER	(hive)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	<span class="keyword">OVER</span>()</span><br><span class="line">用途：</span><br><span class="line">	指定分析函数工作的窗口大小，一般放在函数后面</span><br><span class="line">用法：</span><br><span class="line">	<span class="keyword">over</span>函数是对每一条数据都进行开窗，当<span class="keyword">over</span>括号中没有传入参数时，窗口大小默认为数据集大小。当使用distribute <span class="keyword">by</span> <span class="operator">/</span> sort <span class="keyword">by</span> <span class="operator">/</span> <span class="keyword">order</span> <span class="keyword">by</span>等关键字进行限制时，窗口大小相应地发生变化</span><br><span class="line">	</span><br><span class="line">相关参数(传入<span class="keyword">over</span>后的括号内使用)：</span><br><span class="line">	<span class="keyword">CURRENT</span> <span class="type">ROW</span>: 当前行</span><br><span class="line">	n PRECEDING: 往前n行数据</span><br><span class="line">	n FOLLOWING: 往后n行数据</span><br><span class="line">	UNBOUNDED: 起点</span><br><span class="line">	UNBOUNDED PRECEDING：表示从前面的起点</span><br><span class="line">	UNBOUNDED FOLLOWING：表示到后面的终点</span><br><span class="line">常配合使用的函数：</span><br><span class="line">	窗口函数可以对函数工作范围进行开窗，经常配合使用<span class="keyword">over</span>()的函数有以下几个:</span><br><span class="line">	<span class="built_in">row_number</span>():为结果集的每一行分配一个连续的整数，从<span class="number">1</span>开始</span><br><span class="line">	<span class="built_in">lag</span>(col,n,<span class="keyword">default</span>): 往前第n行数据，第一个参数指定列，第三个参数是当前面第n行该列不存在时的默认值</span><br><span class="line">	<span class="built_in">lead</span>(col,n,<span class="keyword">default</span>)：往后第n行数据，第一个参数指定列，第三个参数是当后面第n行该列不存在时的默认值</span><br></pre></td></tr></table></figure>



<h3 id="LAG"><a href="#LAG" class="headerlink" title="LAG"></a>LAG</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	LAG(col, n, DEFAULT)</span><br><span class="line">用途：</span><br><span class="line">	用于获取当前行之前的行的值，可以用于计算当前行与之前行之间的值的差异或百分比变化等。</span><br><span class="line">用法：</span><br><span class="line">	结合OVER()函数开窗使用，在LAG函数中，第一个参数为列名；第二个参数为偏移量，即往前多少行；最后一个参数为默认值，就是如果往前n行没有值的话，就取这个默认值，如果不指定默认值，则默认值为NULL</span><br><span class="line">示例：</span><br><span class="line">SELECT * FROM TALBE;</span><br><span class="line">	name	time</span><br><span class="line">&gt; 	name1	2023-09-01 </span><br><span class="line">	name1 	2023-09-03</span><br><span class="line">	name1 	2023-09-02</span><br><span class="line">	name2 	2023-09-02</span><br><span class="line">	name2 	2023-09-01</span><br><span class="line">	name2 	2023-09-04</span><br><span class="line">SELECT </span><br><span class="line">	name</span><br><span class="line">	,time</span><br><span class="line">	,LAG(time, 1, &#x27;1970-01-01&#x27;) OVER(PARTITION BY name ORDER BY time) as last_1_time</span><br><span class="line">	,LAG(time, 2) OVER(PARTITION BY name ORDER BY time) as last_2_time</span><br><span class="line">FROM </span><br><span class="line">	TABLE</span><br><span class="line">	name	time		last_1_time		last_2_time</span><br><span class="line">&gt;	name1 	2023-09-01	1970-01-01		NULL</span><br><span class="line">	name1 	2023-09-02	2023-09-01		NULL</span><br><span class="line">	name1 	2023-09-03	2023-09-02		2023-09-01</span><br><span class="line">	name2	2023-09-01	1970-01-01		NULL</span><br><span class="line">	name2	2023-09-02	2023-09-01		NULL</span><br><span class="line">	name2	2023-09-04	2023-09-02		2023-09-01</span><br></pre></td></tr></table></figure>



<h3 id="LEAD"><a href="#LEAD" class="headerlink" title="LEAD"></a>LEAD</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	LEAD(col, n, DEFAULT)</span><br><span class="line">用途：</span><br><span class="line">	用于获取当前行之后的行的值，可以用于计算当前行与之后行之间的值的差异或百分比变化等。</span><br><span class="line">用法：</span><br><span class="line">	结合OVER()函数开窗使用，在LAG函数中，第一个参数为列名；第二个参数为偏移量，即往后多少行；最后一个参数为默认值，就是如果往后n行没有值的话，就取这个默认值，如果不指定默认值，则默认值为NULL</span><br><span class="line">示例：</span><br><span class="line">SELECT * FROM TALBE;</span><br><span class="line">	name 	time</span><br><span class="line">&gt; 	name1	2023-09-01 </span><br><span class="line">	name1 	2023-09-03</span><br><span class="line">	name1 	2023-09-02</span><br><span class="line">	name2 	2023-09-02</span><br><span class="line">	name2 	2023-09-01</span><br><span class="line">	name2 	2023-09-04</span><br><span class="line">SELECT </span><br><span class="line">	name</span><br><span class="line">	,time</span><br><span class="line">	,LEAD(time, 1, &#x27;1970-01-01&#x27;) OVER(PARTITION BY name ORDER BY time) as after_1_time</span><br><span class="line">	,LEAD(time, 2) OVER(PARTITION BY name ORDER BY time) as after_2_time</span><br><span class="line">FROM </span><br><span class="line">	TABLE</span><br><span class="line">	</span><br><span class="line">	name	time		after_1_time	after_2_time</span><br><span class="line">&gt;	name1 	2023-09-01	2023-09-02		2023-09-03</span><br><span class="line">	name1 	2023-09-02	2023-09-03		NULL</span><br><span class="line">	name1 	2023-09-03	1970-01-01		NULL</span><br><span class="line">	name2	2023-09-01	2023-09-02		2023-09-04</span><br><span class="line">	name2	2023-09-02	2023-09-04		NULL</span><br><span class="line">	name2	2023-09-04	1970-01-01		NULL</span><br></pre></td></tr></table></figure>



<h2 id="数据类型处理"><a href="#数据类型处理" class="headerlink" title="数据类型处理"></a>数据类型处理</h2><h3 id="CAST"><a href="#CAST" class="headerlink" title="CAST"></a>CAST</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	CAST(expression AS data_type)</span><br><span class="line">用途：</span><br><span class="line">	将字段类型转换成指定数据类型，显式类型转换</span><br><span class="line">用法：</span><br><span class="line">	expression:任何有效的字段或者表达式</span><br><span class="line">	data_type:要转换的数据类型</span><br><span class="line">特殊说明：</span><br><span class="line">	1.如果将浮点型的数据转换成int类型的，内部操作是通过round()或者floor()函数来实现的，而不是通过cast实现</span><br><span class="line">	2.对于BINARY类型的数据，只能将BINARY类型的数据转换成STRING类型。如果你确信BINARY类型数据是一个数字类型(a number)，这时候你可以利用嵌套的cast操作，比如a是一个BINARY，且它是一个数字类型，那么你可以用下面的查询：</span><br><span class="line">	SELECT (cast(cast(a as string) as double )) from src;</span><br><span class="line">	3.对于Date类型的数据，只能在Date、Timestamp以及String之间进行转换	</span><br></pre></td></tr></table></figure>



<h2 id="集合函数"><a href="#集合函数" class="headerlink" title="集合函数"></a>集合函数</h2><h3 id="SIZE"><a href="#SIZE" class="headerlink" title="SIZE"></a>SIZE</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	SIZE(collection)</span><br><span class="line">用途：</span><br><span class="line">	判断集合大小</span><br><span class="line">用法：</span><br><span class="line">	collection：一个集合类型的字段，或者最终返回类型为集合类型的表达式</span><br><span class="line">特殊说明：</span><br><span class="line">	该函数返回值类型为INT,表示集合的大小</span><br></pre></td></tr></table></figure>





<h3 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	MAP(col1, col2)</span><br><span class="line">用途：</span><br><span class="line">	使用两列构造一个map列</span><br><span class="line">用法：</span><br><span class="line">	col1: 当做key的列</span><br><span class="line">	col2: 当做value的列</span><br><span class="line">其他说明：</span><br><span class="line">	可以使用[]运算符获取map中的值</span><br></pre></td></tr></table></figure>



<h3 id="MAP-KEYS"><a href="#MAP-KEYS" class="headerlink" title="MAP_KEYS"></a>MAP_KEYS</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	MAP_KEYS(map_expression)</span><br><span class="line">用途：</span><br><span class="line">	获取map中的所有key</span><br><span class="line">用法：</span><br><span class="line">	map_expression: map类型的列，或者最终返回类型为map类型的表达式</span><br><span class="line">其他说明：</span><br><span class="line">	该函数返回一个由map中的所有key组成的数组</span><br></pre></td></tr></table></figure>



<h3 id="MAP-VALUES"><a href="#MAP-VALUES" class="headerlink" title="MAP_VALUES"></a>MAP_VALUES</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	MAP_VALUES(map_expression)</span><br><span class="line">用途：</span><br><span class="line">	获取map中的所有value</span><br><span class="line">用法：</span><br><span class="line">	map_expression: map类型的列，或者最终返回类型为map类型的表达式</span><br><span class="line">其他说明：</span><br><span class="line">	该函数返回一个由map中的所有value组成的数组</span><br></pre></td></tr></table></figure>



<h3 id="STR-TO-MAP"><a href="#STR-TO-MAP" class="headerlink" title="STR_TO_MAP"></a>STR_TO_MAP</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	STR_TO_MAP(string, 键值对之间的分隔符， 键值之间的分隔符)</span><br><span class="line">用途：</span><br><span class="line">	将字符串转换为map</span><br><span class="line">其他说明：</span><br><span class="line">	指定的两个分隔符，string本身应该携带这两种分隔符，否则无法进行分割</span><br></pre></td></tr></table></figure>



<h3 id="ARRAY"><a href="#ARRAY" class="headerlink" title="ARRAY"></a>ARRAY</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	ARRAY(col1, col2, col3, ……)</span><br><span class="line">用途：</span><br><span class="line">	根据多列或者多个值构造一个数组</span><br><span class="line">用法：</span><br><span class="line">	指定要作为数组元素的列，即可按照每一列的值来构造数组</span><br></pre></td></tr></table></figure>





<h3 id="ARRAY-CONTAINS"><a href="#ARRAY-CONTAINS" class="headerlink" title="ARRAY_CONTAINS"></a>ARRAY_CONTAINS</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	ARRAY_CONTAINS(array_expression, value)</span><br><span class="line">用途：</span><br><span class="line">	判断数组中是否包含指定的元素</span><br><span class="line">用法：</span><br><span class="line">	array_expression: array类型的字段，或者最终返回类型为array类型的表达式</span><br><span class="line">	value: 指定值。需要判断指定值是否在数组元素中</span><br><span class="line">其他说明：</span><br><span class="line">	该函数会返回一个布尔类型值true或false，表明指定值是否在数组元素中</span><br></pre></td></tr></table></figure>



<h3 id="SORT-ARRAY"><a href="#SORT-ARRAY" class="headerlink" title="SORT_ARRAY"></a>SORT_ARRAY</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	SORT_ARRAY(array_expresson)</span><br><span class="line">用途：</span><br><span class="line">	对数组元素进行排序</span><br><span class="line">用法：</span><br><span class="line">	array_expression: 需要进行排序的array类型的字段，或者最终返回类型为array类型的表达式</span><br><span class="line">其他说明：</span><br><span class="line">	该函数会对数组元素，按照自然顺序作升序排列，没有提供降序排列方式。如果需要降序排列，可以添加辅助列进行处理。</span><br></pre></td></tr></table></figure>



<h2 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h2><h3 id="PMOD"><a href="#PMOD" class="headerlink" title="PMOD"></a>PMOD</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">命令格式：</span><br><span class="line">	PMOD(numerator, denominator)</span><br><span class="line">用途：</span><br><span class="line">	求两个数的余数</span><br><span class="line">用法：</span><br><span class="line">	numerator：分子</span><br><span class="line">	denominator：分母</span><br><span class="line">其他说明：</span><br><span class="line">	两个参数可以是任何数值类型的值(INT,DOUBLE等等)</span><br><span class="line">	两个参数中任何一个为null时，返回值为null</span><br><span class="line">	分母为0时，返回值为null</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/Hadoop/Hive/Hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/" class="post-title-link" itemprop="url">Hive数据类型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:33:03" itemprop="dateModified" datetime="2023-09-27T18:33:03+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>8.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive数据类型"><a href="#Hive数据类型" class="headerlink" title="Hive数据类型"></a>Hive数据类型</h1><h2 id="一、数字类型"><a href="#一、数字类型" class="headerlink" title="一、数字类型"></a>一、数字类型</h2><ul>
<li><p>TINYINT  (1字节有符号整数，范围从-128到127)</p>
</li>
<li><p>SMALLINT  (2字节有符号整数，范围从-32,768到32,767)</p>
</li>
<li><p>INT &#x2F; INTEGER  (4字节有符号整数，范围从 -2,147,483,648 到 2,147,483,647)</p>
</li>
<li><p>BIGINT  (8字节有符号整数，范围从-9,223,372,036,854,775,808到9,223,372,036,854,775,807)</p>
</li>
<li><p>FLOAT  (4字节单精度浮点数)</p>
</li>
<li><p>DOUBLE  (8字节双精度浮点数)</p>
</li>
<li><p>DOUBLE PRECISION  (DOUBLE的别名，自Hive2.2.0起可用)</p>
</li>
<li><p>DECIMAL</p>
<ul>
<li>Hive0.11.0起引入，38位精度</li>
<li>Hive0.13.0起支持用于自定义精度和比例</li>
</ul>
</li>
<li><p>NUMBERIC  (同DECIMAL，Hive3.0.0起可用)</p>
</li>
</ul>
<h2 id="二、日期-x2F-时间类型"><a href="#二、日期-x2F-时间类型" class="headerlink" title="二、日期&#x2F;时间类型"></a>二、日期&#x2F;时间类型</h2><ul>
<li>TIMESTAMP  (Hive 0.8.0起可用)</li>
<li>DATE  (Hive 0.12.0起可用)</li>
<li>INTERVAL  (Hive 1.2.0起可用)</li>
</ul>
<h2 id="三、字符串类型"><a href="#三、字符串类型" class="headerlink" title="三、字符串类型"></a>三、字符串类型</h2><ul>
<li>STRING</li>
<li>VARCHAR  (Hive 0.12.0起可用)</li>
<li>CHAR  (Hive 0.13.0起可用)</li>
</ul>
<h2 id="四、其他类型"><a href="#四、其他类型" class="headerlink" title="四、其他类型"></a>四、其他类型</h2><ul>
<li>BOOLEAN</li>
<li>BINARY  (Hive 0.8.0起可用)</li>
</ul>
<h2 id="五-、复杂类型"><a href="#五-、复杂类型" class="headerlink" title="五 、复杂类型"></a>五 、复杂类型</h2><ul>
<li>arrays : ARRAY<data_type>  (Hive 0.14起可用)</data_type></li>
<li>maps : MAP&lt;primitive_type,data_type&gt;  (Hive 0.14起可用)</li>
<li>structs : STRUCT&lt;col_name : data_type [COMMENT col_comment], …&gt;</li>
<li>union : UNIONTYPE&lt;data_type, data_type, …&gt; (Hive 0.7.0起可用)</li>
</ul>
<h2 id="六、列类型"><a href="#六、列类型" class="headerlink" title="六、列类型"></a>六、列类型</h2><h3 id="6-1-整形类型（TINYINT-SMALLINT-INT-INTEGER-BIGINT）"><a href="#6-1-整形类型（TINYINT-SMALLINT-INT-INTEGER-BIGINT）" class="headerlink" title="6.1 整形类型（TINYINT, SMALLINT, INT/INTEGER, BIGINT）"></a>6.1 整形类型（<code>TINYINT</code>, <code>SMALLINT</code>, <code>INT/INTEGER</code>, <code>BIGINT</code>）</h3><p>在默认情况下，整形类型被设定为<code>INT</code>,如果数字超过了INT的范围，这时列类型将会被转换为<code>BIGINT</code>，或者可以使用下载后缀的方式指定整形类型：</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Postfix</th>
<th>Example</th>
</tr>
</thead>
<tbody><tr>
<td>TINYINT</td>
<td>Y</td>
<td>100Y</td>
</tr>
<tr>
<td>SMALLINT</td>
<td>S</td>
<td>100S</td>
</tr>
<tr>
<td>BIGINT</td>
<td>L</td>
<td>100L</td>
</tr>
</tbody></table>
<p>版本信息：INTEGER在Hive 2.2.0中作为INT 的同义词引入。</p>
<h3 id="6-2-String类型"><a href="#6-2-String类型" class="headerlink" title="6.2 String类型"></a>6.2 String类型</h3><p>字符串型类型值可以使用单引号或双引号表示，Hive将使用C风格在字符串中转义。</p>
<h3 id="6-3-Varchar类型"><a href="#6-3-Varchar类型" class="headerlink" title="6.3 Varchar类型"></a>6.3 Varchar类型</h3><p>varchar类型在创建时需要指定长度（范围1~65535），即定义允许存放的最大字符数。如果要转换&#x2F;分配给varchar类型的字符串超过了指定的长度，字符串会被自动截断。 字符长度由字符串包含的代码点数决定。 </p>
<p>和string一样，尾随在varchar最后的空格很重要，会影响比较的结果。</p>
<p>版本信息：</p>
<blockquote>
<p>varchar 在Hive 0.12.0之后起可用</p>
</blockquote>
<h3 id="6-4-Char-类型"><a href="#6-4-Char-类型" class="headerlink" title="6.4 Char 类型"></a>6.4 Char 类型</h3><p>Char类型与Varchar类型相似，但是Char类型的字符串是固定长度的，没有达到固定长度的部分会使用空格填充，这也意味着在Char类型在比较时尾部的空格没有那么重要，Char的最大长度固定为255。</p>
<p>版本信息：</p>
<blockquote>
<p>Char 类型在Hive 0.13.0后可用</p>
</blockquote>
<h3 id="6-5-Timestamp类型"><a href="#6-5-Timestamp类型" class="headerlink" title="6.5 Timestamp类型"></a>6.5 Timestamp类型</h3><p>支持具有可选纳秒精度的传统UNIX时间戳。</p>
<p>支持的转换：</p>
<ul>
<li><p>整数数字类型：以秒为单位解释为UNIX时间戳</p>
</li>
<li><p>浮点数字类型：以秒为单位，以十进制精度解释为UNIX时间戳</p>
</li>
<li><p>字符串：符合JDBC的java、sql。时间戳格式“YYYY-MM-DD HH:MM:SS.FFFFFFF”（小数点后9位精度）</p>
</li>
</ul>
<p>时间戳被解释为无时区的，并存储为UNIX历元的偏移量。提供了方便的自定义项（to_utc_timestamp, from_utc_timestamp）用于时区之间的转换。</p>
<p>所有现有的datetime UDF（月、日、年、小时等）都使用时间戳数据类型。</p>
<p>文本文件中的时间戳必须使用格式yyyy-mm-dd hh:mm:ss[.f…]。如果它们是另一种格式，请将其声明为适当的类型（INT、FLOAT、STRING等），并使用UDF将其转换为时间戳。</p>
<p>通过设置<code>hive.parquet.write.int64.timestamp=true</code>和<code>hive.parquet.timestamp.time.unit</code>为默认的存储时间单位 (“nanos”纳秒, “micros”微秒, “millis毫秒”; default: “micros”)，Parquet 文件中的时间戳可以存储为int64（而不是int96）。请注意，由于仅存储了64位，如果超出1677-09-21T00:12:43.15和2262-04-11T23:47:16.8的范围，则存储时间单位为“nanos”的int64时间戳将存储为NULL。</p>
<p>在表级别上，可以通过向SerDe属性“timestamp.formats”提供格式（从HIVE1.2.0开始），来支持其他时间戳格式。例如，yyyy-MM-dd’T’HH:MM:ss。SSS，yyyy-MM-dd’T’HH:MM:ss。</p>
<p>版本信息:</p>
<blockquote>
<p>Timestamp在Hive 0.8.0起可用。</p>
</blockquote>
<h3 id="6-6-Dates-类型"><a href="#6-6-Dates-类型" class="headerlink" title="6.6 Dates 类型"></a>6.6 Dates 类型</h3><p>Date类型：</p>
<p>Date 值主要用来描述年月日信息，使用形式YYYY-MM-DD,例如，Date ‘2022-05-30’。Date类型中没有时间组件。Date类型支持的值的范围为0000-01-01到9999-12-31，取决于原Java提供的日期类型的支持。</p>
<p>版本信息：</p>
<blockquote>
<p>Dates 在Hive 0.12.0之后可用。</p>
</blockquote>
<p>类型转换：</p>
<p>Date类型可以转换&#x2F;被转换为Date，Timestamp，或者String类型。也可以按使用者指定的格式转换（<strong>知识暂未深入研究</strong>）</p>
<p>以下是一些有关Date类型转换的说明：</p>
<table>
<thead>
<tr>
<th>转换为Date&#x2F; Date转换为其他时间类型</th>
<th>转换结果</th>
</tr>
</thead>
<tbody><tr>
<td>Date 转换为 Date</td>
<td>结果相同</td>
</tr>
<tr>
<td>Timestamp 转换为 Date</td>
<td>年、月、日在timestamp中是定好的，基于当地的时区将其转换为Date类型</td>
</tr>
<tr>
<td>String 转换为 Date</td>
<td>如果string 的格式为”YYYY-MM-DD”，将会按此年月日来转换成Date，如果String不是这种格式，则转换结果为NULL</td>
</tr>
<tr>
<td>Date 转换为Timestamp</td>
<td>基于本地时区，生成与日期值的年&#x2F;月&#x2F;日的午夜相对应的时间戳值。</td>
</tr>
<tr>
<td>Date 转换为 String</td>
<td>Date的年月日将以”YYYY-MM-DD”的格式转换为String</td>
</tr>
</tbody></table>
<p><strong>Interval类型：暂未研究</strong></p>
<h3 id="6-7-Decimal类型"><a href="#6-7-Decimal类型" class="headerlink" title="6.7 Decimal类型"></a>6.7 Decimal类型</h3><p>版本信息：</p>
<blockquote>
<p>Decimal数据类型在Hive 0.11.0引入，在Hive 0.13.0修正。在Hive 3.0.0中，	NUMERIC与Decimal类型作为同义词引入。</p>
</blockquote>
<p>介绍：</p>
<blockquote>
<p>Hive中的Decimal 类型是基于Java中用来表示不可变的任意精度的十进制数的BigDecimal类型而产生的。所有常规的数字运算（如加减乘除）和自定义项（如 Floor, Ceil, Round等）都可以用来处理Decimal类型。可以按照自己的想法将Decimal转换为其他类型，或将其他类型转换为Decimal。Decimal类型的持久性使得它支持科学和非科学计数法。</p>
</blockquote>
<p>使用：</p>
<blockquote>
<ul>
<li>Hive 0.11 和 0.12 版本Decimal类型的精度固定为38位</li>
<li>从Hive 0.13起，使用者可以自定义精度(字段长度）和范围（小数位数），创建表时，对于Decimal类型只需使用DECIMAL(precision, scale)的语法格式即可。如果小数位数没有确定，则其默认值为0；如果精度没有确定，其默认值为10。</li>
</ul>
</blockquote>
<p>以下是一个建表时指定Decimal类型属性的例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> foo (</span><br><span class="line">  a <span class="type">DECIMAL</span>, <span class="comment">-- Defaults to decimal(10,0)</span></span><br><span class="line">  b <span class="type">DECIMAL</span>(<span class="number">9</span>, <span class="number">7</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>Decimal 文本：</p>
<blockquote>
<p>大于BIGINT的整型文本必须使用Decimal(38,0)来处理，且’BD’后缀是必须携带的，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">CAST</span>(<span class="number">18446744073709001000</span>BD <span class="keyword">AS</span> <span class="type">DECIMAL</span>(<span class="number">38</span>,<span class="number">0</span>)) </span><br><span class="line"><span class="keyword">from</span> my_table limit <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>Hive 0.12.0 和 Hive 0.13.0版本间的Decimal类型是不兼容的。</strong></p>
<blockquote>
<p>由于Hive 0.13.0中Decimal类型的变化，Hive 0.13.0 之前版本的Decimal类型的列，在Hive 0.13.0版本后将被视为decimal(10,0),这意味着写入或写出这张表的整形值都会被转换为10位长度，所以从0.12.0版本获取的表最好升级到0.13.0版本后。</p>
</blockquote>
<p>更新Hive 0.13.0版本之前的表的Decimal类型列：</p>
<blockquote>
<ol>
<li>确定要对Decimal类型设置的的精度和范围。</li>
<li>对于表中的每一个Decimal类型的列，使用ALTER TABLE 命令将其修改为想要的精度和范围，如：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE foo CHANGE COLUMN dec_column_name dec_column_name DECIMAL(38,18);</span><br></pre></td></tr></table></figure>

<p>​	如果不是分区表，更新到此已经完成了，如果是分区表，还需要继续下面的第三步。</p>
<ol start="3">
<li><p>如果表是分区表，先查询表的分区列列表，如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SHOW PARTITIONS foo;</span><br><span class="line">  </span><br><span class="line">ds=2008-04-08/hr=11</span><br><span class="line">ds=2008-04-08/hr=12</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
<li><p>表中现有的每个分区必须修改其Decimal列，以添加所需的精度和范围。可以通过动态分区的ALTER TABLE CHANGE COLUMN(Hive 0.14.0后可用)来实现，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> hive.exec.dynamic.partition <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">     </span><br><span class="line"><span class="comment">-- hive.exec.dynamic.partition needs to be set to true to enable dynamic partitioning with ALTER PARTITION</span></span><br><span class="line"><span class="comment">-- This will alter all existing partitions of the table - be sure you know what you are doing!</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> foo <span class="keyword">PARTITION</span> (ds, hr) CHANGE <span class="keyword">COLUMN</span> dec_column_name dec_column_name <span class="type">DECIMAL</span>(<span class="number">38</span>,<span class="number">18</span>);</span><br></pre></td></tr></table></figure>

<p>或者，可以使用ALTER TABLE CHANGE COLUMN一次指定一个分区，通过为每个语句指定一个分区来完成，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> foo <span class="keyword">PARTITION</span> (ds<span class="operator">=</span><span class="string">&#x27;2008-04-08&#x27;</span>, hr<span class="operator">=</span><span class="number">11</span>) CHANGE <span class="keyword">COLUMN</span> dec_column_name dec_column_name <span class="type">DECIMAL</span>(<span class="number">38</span>,<span class="number">18</span>);</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> foo <span class="keyword">PARTITION</span> (ds<span class="operator">=</span><span class="string">&#x27;2008-04-08&#x27;</span>, hr<span class="operator">=</span><span class="number">12</span>) CHANGE <span class="keyword">COLUMN</span> dec_column_name dec_column_name <span class="type">DECIMAL</span>(<span class="number">38</span>,<span class="number">18</span>);</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
</ol>
</blockquote>
<h3 id="6-8-UNION类型"><a href="#6-8-UNION类型" class="headerlink" title="6.8 UNION类型"></a>6.8 UNION类型</h3><p> <strong>UNIONTYPE支持不完整</strong> ：</p>
<blockquote>
<p> 在Hive 0.7.0（Hive-537）中引入了UNIONTYPE数据类型，但在Hive中对该类型的完全支持仍不完整。在JOIN（HIVE-2508）、WHERE和GROUP BY子句中引用UNIONTYPE字段的查询将失败，并且HIVE没有定义提取UNIONTYPE的标记或值字段的语法。这意味着UNIONTYPEs只能有效地传递。 </p>
</blockquote>
<p>使用：</p>
<blockquote>
<p>联合类型可以在任意一点保存它们指定的数据类型之一。你可以使用create_union UDF创建该类型的实例:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> union_test(foo UNIONTYPE<span class="operator">&lt;</span><span class="type">int</span>, <span class="keyword">double</span>, <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>, struct<span class="operator">&lt;</span>a:<span class="type">int</span>,b:string<span class="operator">&gt;&gt;</span>);</span><br><span class="line"><span class="keyword">SELECT</span> foo <span class="keyword">FROM</span> union_test;</span><br><span class="line"></span><br><span class="line">&#123;<span class="number">0</span>:<span class="number">1</span>&#125;</span><br><span class="line">&#123;<span class="number">1</span>:<span class="number">2.0</span>&#125;</span><br><span class="line">&#123;<span class="number">2</span>:[&quot;three&quot;,&quot;four&quot;]&#125;</span><br><span class="line">&#123;<span class="number">3</span>:&#123;&quot;a&quot;:<span class="number">5</span>,&quot;b&quot;:&quot;five&quot;&#125;&#125;</span><br><span class="line">&#123;<span class="number">2</span>:[&quot;six&quot;,&quot;seven&quot;]&#125;</span><br><span class="line">&#123;<span class="number">3</span>:&#123;&quot;a&quot;:<span class="number">8</span>,&quot;b&quot;:&quot;eight&quot;&#125;&#125;</span><br><span class="line">&#123;<span class="number">0</span>:<span class="number">9</span>&#125;</span><br><span class="line">&#123;<span class="number">1</span>:<span class="number">10.0</span>&#125;</span><br></pre></td></tr></table></figure>

<p>反序列化的联合中的第一部分是标记，它让我们知道使用的是联合的哪个部分。在这个示例中，0表示定义中的第一个data_type，它是一个int，以此类推。要创建一个联合，你必须给create_union UDF提供这个标签:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> create_union(<span class="number">0</span>, key), create_union(if(key<span class="operator">&lt;</span><span class="number">100</span>, <span class="number">0</span>, <span class="number">1</span>), <span class="number">2.0</span>, <span class="keyword">value</span>), create_union(<span class="number">1</span>, &quot;a&quot;, struct(<span class="number">2</span>, &quot;b&quot;)) <span class="keyword">FROM</span> src LIMIT <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">&#123;<span class="number">0</span>:&quot;238&quot;&#125;	&#123;<span class="number">1</span>:&quot;val_238&quot;&#125;	&#123;<span class="number">1</span>:&#123;&quot;col1&quot;:<span class="number">2</span>,&quot;col2&quot;:&quot;b&quot;&#125;&#125;</span><br><span class="line">&#123;<span class="number">0</span>:&quot;86&quot;&#125;	&#123;<span class="number">0</span>:<span class="number">2.0</span>&#125;	&#123;<span class="number">1</span>:&#123;&quot;col1&quot;:<span class="number">2</span>,&quot;col2&quot;:&quot;b&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="七、字面常量类型（Literals）"><a href="#七、字面常量类型（Literals）" class="headerlink" title="七、字面常量类型（Literals）"></a>七、字面常量类型（Literals）</h2><h3 id="7-1-浮点类型"><a href="#7-1-浮点类型" class="headerlink" title="7.1 浮点类型"></a>7.1 浮点类型</h3><p>浮点类型的字面常量被设定为DOUBLE类型，暂不支持科学计数法。</p>
<h3 id="7-2-Decimal类型"><a href="#7-2-Decimal类型" class="headerlink" title="7.2 Decimal类型"></a>7.2 Decimal类型</h3><p>十进制字面值(Decimal Literals)为浮点数提供了比DOUBLE类型更精确的值和更大的范围。十进制数据类型存储数值的精确表示，而DOUBLE数据类型存储数值的非常接近的表示。当DOUBLE类型精确度不够时，可以使用Decimal类型。</p>
<p>可以创建一个含有Decimal类型属性的表：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> decimal_1 (t <span class="type">decimal</span>);</span><br></pre></td></tr></table></figure>

<p>可以使用LazySimpleSerDe或LazyBinarySerDe在这样的表中读写值。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> decimal_1 <span class="keyword">set</span> serde <span class="string">&#x27;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 或者</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> decimal_1 <span class="keyword">set</span> serde <span class="string">&#x27;org.apache.hadoop.hive.serde2.lazy.LazyBinarySerDe&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>可以将Decimal值转换为其他基本类型，例如BOOLEAN:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">cast</span>(t <span class="keyword">as</span> <span class="type">boolean</span>) <span class="keyword">from</span> decimal_2;</span><br></pre></td></tr></table></figure>

<p> Decimal还支持许多算术运算符、数学UDF(用户自定义函数)和UDAFs，其语法与DOUBLE中使用的语法相同 。</p>
<p>可以使用在Decimal类型的基本数学运算如下：</p>
<blockquote>
<ul>
<li>Positive</li>
<li>Negative</li>
<li>Addition</li>
<li>Subtraction</li>
<li>Multiplication</li>
<li>Division</li>
<li>Average (avg)</li>
<li>Sum</li>
<li>Count</li>
<li>Modulus (pmod)</li>
<li>Sign – Hive 0.13.0 and later</li>
<li>Exp – Hive 0.13.0 and later</li>
<li>Ln – Hive 0.13.0 and later</li>
<li>Log2 – Hive 0.13.0 and later</li>
<li>Log10 – Hive 0.13.0 and later</li>
<li>Log(<em>base</em>)  – Hive 0.13.0 and later</li>
<li>Sqrt – Hive 0.13.0 and later</li>
<li>Sin – Hive 0.13.0 and later</li>
<li>Asin  – Hive 0.13.0 and later</li>
<li>Cos – Hive 0.13.0 and later</li>
<li>Acos – Hive 0.13.0 and later</li>
<li>Tan – Hive 0.13.0 and later</li>
<li>Atan – Hive 0.13.0 and later</li>
<li>Radians – Hive 0.13.0 and later</li>
<li>Degrees – Hive 0.13.0 and later</li>
</ul>
</blockquote>
<p>一些舍入函数也可以用在Decimal类型上：</p>
<blockquote>
<ul>
<li>Floor</li>
<li>Ceiling</li>
<li>Round</li>
</ul>
</blockquote>
<p>Power(decimal, n) 只支持指数n的正整数值。</p>
<ul>
<li>缺失值处理</li>
</ul>
<blockquote>
<p>缺失的值由特殊值NULL表示。要导入带有NULL字段的数据，请检查表使用的SerDe的文档。(默认的文本格式使用LazySimpleSerDe，它在导入时将字符串\N解释为NULL。)</p>
</blockquote>
<ul>
<li>类型转换</li>
</ul>
<blockquote>
<p> 当hive.metastore.disallow.incompatible.col.type.changes被设置为false时，可以将原数据中列的类型从一种类型任意转换到另一种类型，如果类型转换是成功的，结果将会被显示，否则将显示NULL。</p>
</blockquote>
<p>下表展示了类型间是否可以相互转换：</p>
<table>
<thead>
<tr>
<th></th>
<th>void</th>
<th>boolean</th>
<th>tinyint</th>
<th>smallint</th>
<th>int</th>
<th>bigint</th>
<th>float</th>
<th>double</th>
<th>decimal</th>
<th>string</th>
<th>varchar</th>
<th>timestamp</th>
<th>date</th>
<th>binary</th>
</tr>
</thead>
<tbody><tr>
<td>void to</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
</tr>
<tr>
<td>boolean to</td>
<td>false</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>tinyint to</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>smallint to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>int to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>bigint to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>float to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>double to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>decimal to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>string to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>varchar to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>timestamp to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
</tr>
<tr>
<td>date to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
<td>true</td>
<td>false</td>
<td>true</td>
<td>false</td>
</tr>
<tr>
<td>binary to</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
<td>true</td>
</tr>
</tbody></table>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/Hadoop/Hive/Hive%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">Hive基本知识</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:32:05" itemprop="dateModified" datetime="2023-09-27T18:32:05+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>554</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive基本知识"><a href="#Hive基本知识" class="headerlink" title="Hive基本知识"></a>Hive基本知识</h1><h2 id="一、分区表"><a href="#一、分区表" class="headerlink" title="一、分区表"></a>一、分区表</h2><p>分区表是指按照数据表的某列或某些列分为多个区，区从形式上可以理解为文件夹，分区是手动进行的。</p>
<p>注意，不通与传统数据库，hive在创建分区表时 CREATE TABLE 下的字段中不能包含分区表字段，分区表字段只在PARTITION BY中定义，创建后，分区字段是表中的最后字段。</p>
<p>如果对表进行分区，即数据分分割存放在若干子目录下，则既可以将分区指向各个子目录，也可以采用递归分区使一个表访问所有子目录。当子目录无法满足这两个中的任何中情况，则会出现错误或者查询为空。</p>
<p>分区最佳实践：</p>
<ul>
<li>挑选一列作为分区键，其唯一值的个数应该在较低值到中间值之间。</li>
<li>避免分区小于1G(越大越好）。</li>
<li>当分区数量较多时，调整HiveServer2和Hive Metastore的内存。</li>
<li>当使用多列作为分区键时，对于每一个分区键列的组合都要创建一个子目录的嵌套树。应避免深入嵌套，因为这会导致太多的分区，进而是创建的文件非常小。</li>
<li>当使用Hive流处理插入数据时，如果多个会话向相同的分区写入数据，那么就会导致锁闭。</li>
<li>你可以修改某一分区表的模式，然而，一旦结构发生改变，你就无法在已有分区中修改数据了。</li>
<li>如果要将数据并行插入到多个分区，应该将<code>hive.optimize.sort.dynamic.partition</code>设置为true。</li>
</ul>
<h2 id="二、分桶表"><a href="#二、分桶表" class="headerlink" title="二、分桶表"></a>二、分桶表</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/Hadoop/Hive/Hive%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hive/Hive%E4%BC%98%E5%8C%96/" class="post-title-link" itemprop="url">Hive优化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:33:22" itemprop="dateModified" datetime="2023-09-27T18:33:22+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hive优化"><a href="#Hive优化" class="headerlink" title="Hive优化"></a>Hive优化</h1><h2 id="1-Fetch抓取"><a href="#1-Fetch抓取" class="headerlink" title="1. Fetch抓取"></a>1. Fetch抓取</h2><blockquote>
<p>Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算.</p>
<p>hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。</p>
</blockquote>
<h2 id="2-本地模式"><a href="#2-本地模式" class="headerlink" title="2. 本地模式"></a>2. 本地模式</h2><blockquote>
<p>有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p>
<p>可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto<span class="operator">=</span><span class="literal">true</span>;  <span class="operator">/</span><span class="operator">/</span>开启本地mr</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>设置<span class="keyword">local</span> mr的最大输入数据量，当输入数据量小于这个值时采用<span class="keyword">local</span>  mr的方式，默认为<span class="number">134217728</span>，即<span class="number">128</span>M</span><br><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto.inputbytes.max<span class="operator">=</span><span class="number">50000000</span>;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>设置<span class="keyword">local</span> mr的最大输入文件个数，当输入文件个数小于这个值时采用<span class="keyword">local</span> mr的方式，默认为<span class="number">4</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto.input.files.max<span class="operator">=</span><span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<h2 id="3-表的优化"><a href="#3-表的优化" class="headerlink" title="3. 表的优化"></a>3. 表的优化</h2><h3 id="3-1-小表、大表join"><a href="#3-1-小表、大表join" class="headerlink" title="3.1 小表、大表join"></a>3.1 小表、大表join</h3><blockquote>
<p>将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用map join让小的维度表（1000条以下的记录条数）先进内存。在map端完成reduce。</p>
<p>新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。</p>
</blockquote>
<h3 id="3-2-大表-join-大表"><a href="#3-2-大表-join-大表" class="headerlink" title="3.2 大表 join 大表"></a>3.2 大表 join 大表</h3><h4 id="3-2-1-空key过滤"><a href="#3-2-1-空key过滤" class="headerlink" title="3.2.1 空key过滤"></a>3.2.1 空key过滤</h4><blockquote>
<p>有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。</p>
<p>join前可以将值为空的连接key过滤掉。</p>
</blockquote>
<h4 id="3-2-2-空key转换"><a href="#3-2-2-空key转换" class="headerlink" title="3.2.2 空key转换"></a>3.2.2 空key转换</h4><blockquote>
<p>有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。</p>
</blockquote>
<h3 id="3-3-MapJoin"><a href="#3-3-MapJoin" class="headerlink" title="3.3 MapJoin"></a>3.3 MapJoin</h3><p>工作机制：</p>
<p><img src="/Hadoop/Hive/Hive%E4%BC%98%E5%8C%96/.%5CHive%E4%BC%98%E5%8C%96%5Cclip_image002.png" alt="img"></p>
<p>开启MapJoin功能：</p>
<p>​	<code>set hive.auto.convert.join = true; </code>         默认为true</p>
<p>大表小表的阈值设置（默认25M一下认为是小表）：</p>
<p>​	<code>set hive.mapjoin.smalltable.filesize=25000000;</code></p>
<h3 id="3-4-Group-By"><a href="#3-4-Group-By" class="headerlink" title="3.4 Group By"></a>3.4 Group By</h3><blockquote>
<p>默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。</p>
<p>并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。</p>
</blockquote>
<p>1．开启Map端聚合参数设置</p>
<p>（1）是否在Map端进行聚合，默认为True</p>
<p>​	<code>hive.map.aggr = true</code></p>
<p>（2）在Map端进行聚合操作的条目数目</p>
<p>​	<code>hive.groupby.mapaggr.checkinterval = 100000</code></p>
<p>（3）有数据倾斜的时候进行负载均衡（默认是false）</p>
<p>​	<code>hive.groupby.skewindata = true</code></p>
<blockquote>
<p>当选项设定为 true，生成的查询计划会有两个MR Job。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。</p>
</blockquote>
<h3 id="3-5-Count-Distinct-去重统计"><a href="#3-5-Count-Distinct-去重统计" class="headerlink" title="3.5 Count(Distinct) 去重统计"></a>3.5 Count(Distinct) 去重统计</h3><blockquote>
<p>数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换,虽然会多用一个Job来完成，但在数据量大的情况下，这个绝对是值得的。</p>
</blockquote>
<h3 id="3-6-笛卡尔积"><a href="#3-6-笛卡尔积" class="headerlink" title="3.6 笛卡尔积"></a>3.6 笛卡尔积</h3><blockquote>
<p>尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。</p>
</blockquote>
<h3 id="3-7-行列过滤"><a href="#3-7-行列过滤" class="headerlink" title="3.7 行列过滤"></a>3.7 行列过滤</h3><blockquote>
<p>列处理：在SELECT中，只拿需要的列，如果有，尽量使用分区过滤，少用SELECT *。</p>
<p>行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤.  所以连接的子表需要过滤时，应尽量现在子表中使用where条件过滤，实在无法再子表中过滤时再考虑在关联之后使用where条件过滤</p>
</blockquote>
<h3 id="3-8-动态分区"><a href="#3-8-动态分区" class="headerlink" title="3.8 动态分区"></a>3.8 动态分区</h3><blockquote>
<p>关系型数据库中，对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中，Hive中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过，使用Hive的动态分区，需要进行相应的配置。</p>
</blockquote>
<p><strong>1．开启动态分区参数设置</strong></p>
<p>（1）开启动态分区功能（默认true，开启）</p>
<p>​	<code>set hive.exec.dynamic.partition=true;</code></p>
<p>（2）设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。）</p>
<p>​	<code>set hive.exec.dynamic.partition.mode=nonstrict;</code></p>
<p>（3）在所有执行MR的节点上，最大一共可以创建多少个动态分区。</p>
<p>​	<code>set hive.exec.max.dynamic.partitions=1000;</code></p>
<p>​    （4）在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</p>
<p>​	<code>set hive.exec.max.dynamic.partitions.pernode=100;</code></p>
<p>（5）整个MR Job中，最大可以创建多少个HDFS文件。</p>
<p>​	<code>set hive.exec.max.created.files=100000;</code></p>
<p>（6）当有空分区生成时，是否抛出异常。一般不需要设置。</p>
<p>​	<code>set hive.error.on.empty.partition=false;</code></p>
<h2 id="4-数据倾斜（MR优化）"><a href="#4-数据倾斜（MR优化）" class="headerlink" title="4. 数据倾斜（MR优化）"></a>4. 数据倾斜（MR优化）</h2><h3 id="4-1-合理设置Map数"><a href="#4-1-合理设置Map数" class="headerlink" title="4.1 合理设置Map数"></a>4.1 合理设置Map数</h3><p><strong>1</strong>）通常情况下，作业会通过input的目录产生一个或者多个map任务。</p>
<p>​	主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。</p>
<p><strong>2</strong>）是不是map数越多越好？</p>
<p>​	答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</p>
<p><strong>3</strong>）是不是保证每个map处理接近128m的文件块，就高枕无忧了？</p>
<p>​	答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。</p>
<p>针对上面的问题2和3，我们需要采取两种方式来解决：即减少map数和增加map数；</p>
<h3 id="4-2-小文件合并"><a href="#4-2-小文件合并" class="headerlink" title="4.2 小文件合并"></a>4.2 小文件合并</h3><p>在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p>
<p>​	<code>set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</code></p>
<h3 id="4-3-复杂文件增加Map数"><a href="#4-3-复杂文件增加Map数" class="headerlink" title="4.3 复杂文件增加Map数"></a>4.3 复杂文件增加Map数</h3><p>当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p>
<p>增加map的方法为：根据computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))&#x3D;blocksize&#x3D;128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</p>
<p>设置最大切片值大小：</p>
<p>​	<code>set mapreduce.input.fileinputformat.split.maxsize=100;</code></p>
<h3 id="4-4-合理设置Reduce数"><a href="#4-4-合理设置Reduce数" class="headerlink" title="4.4 合理设置Reduce数"></a>4.4 合理设置Reduce数</h3><p><strong>1．调整reduce个数方法一</strong>   （通过设置每个Reduce处理的数据量确定Reduce的值）</p>
<p>（1）每个Reduce处理的数据量默认是256MB</p>
<p>​	<code>set hive.exec.reducers.bytes.per.reducer=256000000;</code></p>
<p>（2）每个任务最大的reduce数，默认为1009</p>
<p>​	<code>set hive.exec.reducers.max=1009;</code></p>
<p>（3）计算reducer数的公式</p>
<p>​	<code>	N=min(参数2，总输入数据量/参数1)</code></p>
<p><strong>2．调整reduce个数方法二</strong>	(直接指定reduce的个数)</p>
<p>在hadoop的mapred-default.xml文件中修改</p>
<p>设置每个job的Reduce个数(默认为-1, 按数据在MapReduce之前的大小，以及上面方法一的配置量来分配的)</p>
<p>​	<code>set mapreduce.job.reduces = 15;</code></p>
<p><strong>3．reduce个数并不是越多越好</strong></p>
<p>1）过多的启动和初始化reduce也会消耗时间和资源；</p>
<p>2）另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</p>
<p>在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</p>
<h2 id="5-并行执行"><a href="#5-并行执行" class="headerlink" title="5. 并行执行"></a>5. 并行执行</h2><p>hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。</p>
<p>​    通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p>
<p><code>set hive.exec.parallel=true; </code>      &#x2F;&#x2F;打开任务并行执行</p>
<p><code>set hive.exec.parallel.thread.number=16;</code> &#x2F;&#x2F;同一个sql允许最大并行度，默认为8。</p>
<p>当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。</p>
<h2 id="6-严格模式"><a href="#6-严格模式" class="headerlink" title="6. 严格模式"></a>6. 严格模式</h2><p>Hive提供了一个严格模式，可以防止用户执行那些可能意想不到的不好的影响的查询。</p>
<p>​    通过设置属性hive.mapred.mode值为默认是非严格模式nonstrict 。开启严格模式需要修改hive.mapred.mode值为strict     <code>set hive.mapred.mode=strict;</code></p>
<p>，开启严格模式可以禁止3种类型的查询。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.mapred.mode<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>strict<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      The mode in which the Hive operations are being performed. </span><br><span class="line">      In strict mode, some risky queries are not allowed to run. They include:</span><br><span class="line">        Cartesian Product.</span><br><span class="line">        No partition being picked up for a query.</span><br><span class="line">        Comparing bigints and strings.</span><br><span class="line">        Comparing bigints and doubles.</span><br><span class="line">        Orderby without limit.</span><br><span class="line"><span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li><p>对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p>
</li>
<li><p>对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</p>
</li>
<li><p>限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p>
</li>
</ol>
<h2 id="7-JVM重用"><a href="#7-JVM重用" class="headerlink" title="7. JVM重用"></a>7. JVM重用</h2><p>JVM重用是Hadoop调优参数的内容，其对Hive的性能具有非常大的影响，特别是对于很难避免小文件的场景或task特别多的场景，这类场景大多数执行时间都很短。</p>
<p>Hadoop的默认配置通常是使用派生JVM来执行map和Reduce任务的。这时JVM的启动过程可能会造成相当大的开销，尤其是执行的job包含有成百上千task任务的情况。JVM重用可以使得JVM实例在同一个job中重新使用N次。N的值可以在Hadoop的mapred-site.xml文件中进行配置。通常在10-20之间，具体多少需要根据具体业务场景测试得出。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.jvm.numtasks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">     How many tasks to run per jvm. If set to -1, there is no limit. </span><br><span class="line"> <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>这个功能的缺点是，开启JVM重用将一直占用使用到的task插槽，以便进行重用，直到任务完成后才能释放。如果某个“不平衡的”job中有某几个reduce task执行的时间要比其他Reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。</p>
<h2 id="8-推测执行"><a href="#8-推测执行" class="headerlink" title="8. 推测执行"></a>8. 推测执行</h2><p>在分布式集群环境下，因为程序Bug（包括Hadoop本身的bug），负载不均衡或者资源分布不均等原因，会造成同一个作业的多个任务之间运行速度不一致，有些任务的运行速度可能明显慢于其他任务（比如一个作业的某个任务进度只有50%，而其他所有任务已经运行完毕），则这些任务会拖慢作业的整体执行进度。为了避免这种情况发生，Hadoop采用了推测执行（Speculative Execution）机制，它根据一定的法则推测出“拖后腿”的任务，并为这样的任务启动一个备份任务，让该任务与原始任务同时处理同一份数据，并最终选用最先成功运行完成任务的计算结果作为最终结果。</p>
<p>设置开启推测执行参数：Hadoop的mapred-site.xml文件中进行配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some map tasks </span><br><span class="line">               may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some reduce tasks </span><br><span class="line">               may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>不过hive本身也提供了配置项来控制reduce-side的推测执行：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.mapred.reduce.tasks.speculative.execution<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether speculative execution for reducers should be turned on. <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>关于调优这些推测执行变量，还很难给一个具体的建议。如果用户对于运行时的偏差非常敏感的话，那么可以将这些功能关闭掉。如果用户因为输入数据量很大而需要执行长时间的map或者Reduce task的话，那么启动推测执行造成的浪费是非常巨大大。</p>
<h2 id="10-执行计划（Explain）"><a href="#10-执行计划（Explain）" class="headerlink" title="10. 执行计划（Explain）"></a>10. 执行计划（Explain）</h2><p>1．基本语法</p>
<p>EXPLAIN [EXTENDED | DEPENDENCY | AUTHORIZATION] query</p>
<p>2．案例实操</p>
<p>（1）查看下面这条语句的执行计划</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain <span class="keyword">select</span> deptno, <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno;</span><br></pre></td></tr></table></figure>

<p>（2）查看详细执行计划</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain extended <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line"></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain extended <span class="keyword">select</span> deptno, <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/ETL/ETL%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/ETL/ETL%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/" class="post-title-link" itemprop="url">ETL开发流程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-16 13:48:25" itemprop="dateCreated datePublished" datetime="2023-09-16T13:48:25+08:00">2023-09-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-11-02 19:06:17" itemprop="dateModified" datetime="2023-11-02T19:06:17+08:00">2023-11-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ETL/" itemprop="url" rel="index"><span itemprop="name">ETL</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ETL开发流程"><a href="#ETL开发流程" class="headerlink" title="ETL开发流程"></a>ETL开发流程</h1><h2 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h2><h3 id="1-开发架构确定"><a href="#1-开发架构确定" class="headerlink" title="1. 开发架构确定"></a>1. 开发架构确定</h3><p>​	在接收到需求后，首先要弄清楚业务类型，以及数据源类型。在宏观上，ETL是围绕数据开展的工作，不应局限于某种技术或某种数据处理方式，所以，在条件允许的情况下，应该选取最适合业务的开发架构和方式。以下列举了几种开发架构，笔者经验所限，后续将持续更新新的架构。</p>
<ul>
<li><p>离线开发：Hadoop+ hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">经典的离线开发方式，当需求对数据的实时性要求没那么高时，可以采用此种开发方式。当然该架构对于配置要求较高，需要有Hadoop集群以及数据开发平台。</span><br></pre></td></tr></table></figure>
</li>
<li><p>实时开发：待补充</p>
</li>
<li><p>待补充</p>
</li>
</ul>
<h3 id="2-了解数据源"><a href="#2-了解数据源" class="headerlink" title="2. 了解数据源"></a>2. 了解数据源</h3><p>当拿到一份陌生的数据源&#x2F;数据源表，首先要做的是对该表进行充分的了解：</p>
<ul>
<li>表字段、字段类型、字段注释的了解</li>
<li>表的业务背景、来源、每个字段的含义</li>
<li>表的更新方式（增量&#x2F;全量）、表格结构（普通表&#x2F;分区&#x2F;分桶）、使用方式（只用最新分区&#x2F;使用部分分区&#x2F;使用全量分区）</li>
</ul>
<p>基于对表的这些了解，应该形成文档，对要点做适当的记录，避免下次使用该表时因为疏漏而踩坑。</p>
<p>然后，需要对数据源表进行数据探查，主要是为了大致评估数据量、数据质量、以及一些其他信息。数据探查的逻辑主要根据业务需求来制定，探查过后应该对资源分配、开发方式、数据源是否符合需求等有一个评估结论</p>
<h3 id="2-开发逻辑设计"><a href="#2-开发逻辑设计" class="headerlink" title="2. 开发逻辑设计"></a>2. 开发逻辑设计</h3><h3 id="3-表结构设计"><a href="#3-表结构设计" class="headerlink" title="3. 表结构设计"></a>3. 表结构设计</h3><h3 id="4-数据流梳理"><a href="#4-数据流梳理" class="headerlink" title="4. 数据流梳理"></a>4. 数据流梳理</h3><h2 id="开发阶段"><a href="#开发阶段" class="headerlink" title="开发阶段"></a>开发阶段</h2><h3 id="1-离线开发流程"><a href="#1-离线开发流程" class="headerlink" title="1. 离线开发流程"></a>1. 离线开发流程</h3><h4 id="1-1-数据探查（了解数据源）"><a href="#1-1-数据探查（了解数据源）" class="headerlink" title="1.1 数据探查（了解数据源）"></a>1.1 数据探查（了解数据源）</h4><p>当拿到一份陌生的数据源&#x2F;数据源表，首先要做的是对该表进行充分的了解，主要了解方式为数据探查：</p>
<ul>
<li><p><strong>表的业务背景、来源</strong></p>
<ul>
<li>使用数据前，必须了解数据源的来源及业务背景，这有助于理解业务，了解业务是开发的前提，否则成果将是充满隐患的。</li>
<li>这些知识可以从产品经理处获取，也可以联系数据源的创建者或相关人员，总之，为了理解业务可以联系一切业务相关的人。</li>
</ul>
</li>
<li><p><strong>了解表字段、字段类型、字段注释</strong></p>
<ul>
<li><strong>表字段</strong>：<br>表中总会有一些关键字段（类似于主键的字段）和一些维度字段，这些字段和业务息息相关。<br>① 了解这些字段的业务含义<br>② 关键字段需要探查一下是否有重复值，分析是否符合业务需求，并做好记录。<br>③ 维度字段需要探查一下字段值的组成，分析是否符合业务需求，并做好记录。<br>④ 还要关注这些字段的数据质量，例如是否有脏数据、缺失值等，并做好记录。<br>⑤ 待补充</li>
<li><strong>字段类型</strong>：<br>抽取表的一部分数据，查看各字段值的情况：<br>① 字段值形式上为集合数据类型的（例如数组、map、struct等），需要关注实际类型是否为集合类型，如果不是，则使用的时候大概率需要做类型转换，此处要做好记录。<br>② 字段值为时间或者时间戳的，需要关注一下实际类型，还要记录一下时间格式，以及时间戳的位数（10位 or 13位）。<br>③ 待补充</li>
<li><strong>字段注释</strong>：<br>字段注释是数据开发人员给出的字段简要解释，在某些情况下具有及其重要的解释意义：<br>① 有些字段是标识性的，其取值一般带有标识意义，例如用0， 1表示不同的意义，理解这些字段的关键就在于查看字段注释或者字段名称。<br>② 待补充</li>
</ul>
</li>
<li><p><strong>表的更新方式（增量&#x2F;全量）、表类型（普通表&#x2F;分区&#x2F;分桶）</strong></p>
<ul>
<li><strong>数据更新方式：</strong><br>数据更新方式有两种：增量更新和全量更新。<br>① 增量更新：以分区表为例，增量更新的表，分区内的数据只与该分区有关。例如一个天分区内只存储该天的数据。一般增量更新的表，使用的时候需要跨分区使用多个分区的数据。<br>② 全量更新：以分区表为例，全量更新的表，每个分区内都存储了截止到该分区的全量历史数据，一般全量更新的表，使用的时候只需要取最新分区的数据即可。</li>
<li><strong>表类型：</strong><br>以hive为例，介绍一下表类型：<br>① 内部表（Internal Table）：这是Hive默认创建的表类型，数据存储在Hive的数据仓库中，当删除表时，数据也会被删除。<br>② 外部表（External Table）：这种表类型的数据存储在Hive之外，例如HDFS或本地文件系统。当删除表时，数据不会被删除。③ 索引表（Index Table）：这种表类型是在Hive 0.8.0版本中引入的，它可以加速查询操作。索引表是基于内部表或外部表创建的，它们包含了指向原始表数据的指针。<br>④ 分区表（Partitioned Table）：这种表类型将数据按照指定的列分成不同的分区，可以提高查询效率。分区表可以是内部表或外部表。<br>⑤ 桶表（Bucketed Table）：这种表类型将数据按照指定的列分成不同的桶，每个桶中包含相同数量的数据。桶表可以是内部表或外部表。</li>
</ul>
</li>
</ul>
<ol>
<li><p>数据清洗<br>在充分了解了数据源之后，就需要根据业务需求对数据进行处理了：</p>
<ul>
<li><p><strong>确定业务数据范围</strong>。包括：</p>
<ul>
<li>业务数据范围：<br>在逻辑上对数据源的数据进行截取，例如只需要统计当年的数据，则通过表中的时间字段进行过滤即可。</li>
<li>字段范围：<br>确定关键的字段有哪些，根据业务抽取需要的字段，对于一些明显用不到的字段，可以舍去，对于以后可能会用到的字段予以保留，避免后续迭代对表结构做改动。</li>
<li>特别地，如果后续会经常使用该表，可以考虑只对该表做数据范围上的筛选，而不做字段范围上的限制（保留全部字段），加以清洗后形成一张通用明细表</li>
</ul>
</li>
<li><p><strong>脏数据清洗</strong>。</p>
<ul>
<li><p>字段内容清洗<br>字段内容清洗是最常见的脏数据处理方式</p>
<ul>
<li>某些字段中可能掺杂了一些特殊字符、乱码数据等。这种情况下，一般需要将特殊字符去除，或者将整个值做统一替换处理。处理方式一般为字符串替换、正则表达式替换、或者采用if 、case when 等条件函数进行映射等。</li>
<li>某些字段中可能存在一些不该存在的值，这种情况一般直接做映射处理，将这些不合适的值替换为其他值，可以采用上面的处理方式进行处理。</li>
</ul>
</li>
<li><p>缺失值处理</p>
<ul>
<li><p>缺失值统一转换：<br>对于缺失值，最常规的处理方式就是将缺失值做统一转换，可以转换为某个特定的值，也可以将不同的缺失值统一成一样的缺失值，便于后续处理。处理一般可借助COALESCE、IF、NVL、CASE WHEN等函数。<br>特别地，在处理表时，由于很多字段不能确定是否有缺失值，或者日后是否会产生缺失值，所以在处理时基本可以对所有字段进行缺失值处理，防止出现缺失值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">空值转换:</span><br><span class="line">	NVL(field, 替换后的值)</span><br><span class="line">	IF(field IS NULL, 替换后的值, field)</span><br><span class="line">空字符串转NULL:</span><br><span class="line">	IF(field = &#x27;&#x27;, 替换后的值, field)</span><br><span class="line">判断字段是否为空或者空字符串:</span><br><span class="line">	COALESCE(field, &#x27;&#x27;) = &#x27;&#x27;    --字段为空或者空字符串</span><br><span class="line">	field IS NULL OR field = &#x27;&#x27; --字段为空或者空字符串</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>详细地址解析<br>当表中只有一个长串的详细地址字段，而没有单独的省市地址字段时，需要使用正则表达式进行解析，表达式书写需要根据具体的数据情况来写，考虑到一般的地址书写格式都比较相似，下面总结了一下地址解析的HIVESQL代码，主要是从详细地址中解析出省份名称和市名称，后续会不断优化，注意代码中语句的顺序十分重要：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">CASE</span><br><span class="line">    WHEN install_addr LIKE &#x27;%市%省%&#x27; THEN &#x27;其他&#x27; --异常数据过滤</span><br><span class="line">    WHEN install_addr LIKE &#x27;%北京%&#x27; THEN &#x27;北京市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%天津%&#x27; THEN &#x27;天津市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%上海%&#x27; THEN &#x27;上海市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%重庆%&#x27; THEN &#x27;重庆市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%香港%&#x27; THEN &#x27;香港特别行政区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%澳门%&#x27; THEN &#x27;澳门特别行政区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;.*?自治区&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%省%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;.*?省&#x27;, 0)</span><br><span class="line">    ELSE &#x27;其他&#x27;</span><br><span class="line">END AS province_desc</span><br><span class="line">,CASE</span><br><span class="line">    WHEN install_addr LIKE &#x27;%北京%&#x27; THEN &#x27;北京市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%天津%&#x27; THEN &#x27;天津市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%上海%&#x27; THEN &#x27;上海市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%重庆%&#x27; THEN &#x27;重庆市&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%省%自治州%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?省&#x27;, &#x27;&#x27;), &#x27;^.*?自治州&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%自治州%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?自治州&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%地区%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?地区&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%省%地区%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?省&#x27;, &#x27;&#x27;), &#x27;^.*?地区&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%盟%市%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?盟&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%市%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?市&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%自治区%盟%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?自治区&#x27;, &#x27;&#x27;), &#x27;^.*?盟&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%省%市%&#x27; THEN REGEXP_EXTRACT(REGEXP_REPLACE(REGEXP_REPLACE(install_addr, &#x27;[ \f\n\r\t\v]&#x27;, &#x27;&#x27;), &#x27;^.*?省&#x27;, &#x27;&#x27;), &#x27;^.*?市&#x27;, 0)</span><br><span class="line">    WHEN install_addr LIKE &#x27;%香港%&#x27; THEN &#x27;香港特别行政区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%澳门%&#x27; THEN &#x27;澳门特别行政区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%神农架林区%&#x27; THEN &#x27;神农架林区&#x27;</span><br><span class="line">    WHEN install_addr LIKE &#x27;%平潭综合实验区%&#x27; THEN &#x27;平潭综合实验区&#x27;</span><br><span class="line">    ELSE &#x27;其他&#x27;</span><br><span class="line">END AS city_desc</span><br></pre></td></tr></table></figure>
</li>
<li><p>字段类型转换<br>字段类型转换是一个比较头疼的问题，按规范来说，不同类型的字段应该选取最合适的字段类型。但是在实际开发中，还是推荐尽量在建表时将字段类型都指定为字符串类型，避免因类型转换带来的一系列问题。但一些数字类型的字段例外特别是整形字段，对于需要做数学运算的整形字段，建表时还是指定为整形，因为对字符串数字进行运算，结果常常会出现小数，处理比较麻烦。<br>字段类型转换遵循由简入繁的规则，特别是数值类型的字段，例如，任何整数类型都可以隐式地转换为一个范围更大的类型，TINYINT,SMALLINT,INT,BIGINT,FLOAT,STRING 都可以隐式地转换为DOUBLE，INT类型不能隐式地转换为TINYINT、SMALLINT类型（除非使用cast函数）,BOOLEAN不能转换为任何类型。</p>
</li>
</ul>
</li>
</ul>
</li>
<li></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hackertaizi.github.io/Hadoop/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Taizi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="太子的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 太子的个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Hadoop/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">Hadoop学习笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-02-15 18:09:12" itemprop="dateCreated datePublished" datetime="2023-02-15T18:09:12+08:00">2023-02-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-09-27 18:26:20" itemprop="dateModified" datetime="2023-09-27T18:26:20+08:00">2023-09-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">Hadoop学习笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hadoop学习笔记"><a href="#Hadoop学习笔记" class="headerlink" title="Hadoop学习笔记"></a>Hadoop学习笔记</h1><h3 id="1-一些基本命令"><a href="#1-一些基本命令" class="headerlink" title="1. 一些基本命令"></a>1. 一些基本命令</h3><p>启动hadoop：<br>1)开启SSH传输服务：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ssh start</span><br></pre></td></tr></table></figure>

<p>2)启动hadoop：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">一次启动</span><br><span class="line">[bash] hadoop安装路径/sbin/start-all.sh</span><br><span class="line">也可以手动多次启动</span><br></pre></td></tr></table></figure>

<p>操作HDFS系统：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop 2.x版本</span><br><span class="line">hadoop安装路径/bin/hdfs dfs -命令</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop 3.x版本</span><br><span class="line">hadoop安装路径/bin/hdfs fs -命令</span><br></pre></td></tr></table></figure>

<h3 id="2-mapreduce样例运行时的文件系统切换"><a href="#2-mapreduce样例运行时的文件系统切换" class="headerlink" title="2. mapreduce样例运行时的文件系统切换"></a>2. mapreduce样例运行时的文件系统切换</h3><p>在运行诸如mapreduce样例中的grep、wordcount等功能时，很重要的一点是指定文件的输入文件夹路径和输出文件夹（注意输出文件夹不需要提前创建），此时，我们指定的路径是本地路径还是HDFS中的路径呢？需要在Hadoop的配置文件core-site.xml进行指定，当不配置路径时，默认文件系统的路径是Hadoop的安装文件夹下，此外，可以通过配置将文件系统切换为HDFS，在core-site.xml中添加以下配置指定HDFS中NameNode的地址即可：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>添加此配置后，运行wordcount等案例时，指定的输入输出路径就是HDFS中的路径了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/root/input /user/root/output</span><br></pre></td></tr></table></figure>

<h3 id="3-hadoop50070监控界面中无法下载HDFS中的文件"><a href="#3-hadoop50070监控界面中无法下载HDFS中的文件" class="headerlink" title="3. hadoop50070监控界面中无法下载HDFS中的文件"></a>3. hadoop50070监控界面中无法下载HDFS中的文件</h3><p>添加主机到虚拟机集群的IP映射，将虚拟机hosts文件中的内容添加到windows主机中<br>虚拟机hosts文件路径：<code>/etc/hosts</code><br>windows hosts文件路径：<code>C:\Windows\System32\drivers\etc\hosts</code></p>
<p>添加后重启服务器或虚拟机即可。</p>
<h3 id="4-格式化NameNode（首次启动集群时格式化，不要总格式化）"><a href="#4-格式化NameNode（首次启动集群时格式化，不要总格式化）" class="headerlink" title="4. 格式化NameNode（首次启动集群时格式化，不要总格式化）"></a>4. 格式化NameNode（首次启动集群时格式化，不要总格式化）</h3><p><strong>注意：格式化NameNode，会产生新的集群id,导致NameNode和DataNode的集群id不一致，集群找不到已往数据。所以，格式NameNode时，一定要先删除data数据和log日志，然后再格式化NameNode。(集群id不一致将导致DataNode和NameNode不能同时启动)</strong></p>
<p><strong>提示：NameNode和DataNode的集群id可以在<code>安装路径/data/tmp/dfs/name/current/VERSION</code> <code>安装路径/data/tmp/dfs/data/current/</code>中或者<code>安装路径/tmp/dfs/name/current/VERSION</code> <code>安装路径/tmp/dfs/data/current/VERSION</code>中查看</strong></p>
<p>查看java进程，查看NameNode和DataNode是否关闭(jps是JDK中的命令，非linux自带命令)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure>

<p>将hadoop安装目录下的data文件夹 和 logs文件夹删除</p>
<p>格式化NameNode：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop安装目录下/bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>

<h3 id="5-通过yarn运行MapReduce程序时的问题处理"><a href="#5-通过yarn运行MapReduce程序时的问题处理" class="headerlink" title="5. 通过yarn运行MapReduce程序时的问题处理"></a>5. 通过yarn运行MapReduce程序时的问题处理</h3><ul>
<li>资源监控页面配置</li>
</ul>
<p>yarn资源监控界面需要在yarn-site.xml中配置主机名称，默认名称为0.0.0.0,默认端口号为8088，在启动yarn（ResourceManager和NodeManager）后可以访问资源监控页面，查看MapReduce任务的执行情况和资源使用情况。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;主机名称，自己指定&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>运行失败时classpath配置</li>
</ul>
<p>通过yarn运行MR程序时，可能出现运行失败的情况，可以在hadoop安装目录&#x2F;logs&#x2F;userlogs&#x2F;目录下，根据报错信息找到出错应用日志的位置。如报错信息中显示：<code>Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.</code>，需要将hadoop的classpath信息写入配置。在命令行中执行<code>hadoop classpath</code>,得到路径将其复制，然后写入yarn-site.xml以及mapred-site.xml中:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.application.classpath&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;classpath内容&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>虚拟内存超限配置</li>
</ul>
<p>如果运行任务遇到虚拟内存使用超过限制的报错，可以在yarn-site.xml中添加参数，使程序运行时跳过内存检查：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>由于NameNode开启了安全模式（safe-mode）导致程序运行时DataNode权限不足的问题</li>
</ul>
<p>退出安全模式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -safemode leave</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/5/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/7/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Powered by Hackertaizi</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">225k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">6:49</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
